// Generated file, do not edit.
// Generated by ffigen
// ignore_for_file: camel_case_types, non_constant_identifier_names, unused_element, unused_field, void_checks, annotate_overrides, no_leading_underscores_for_local_identifiers, library_private_types_in_public_api

// AUTO GENERATED FILE, DO NOT EDIT.
//
// Generated by `package:ffigen`.
// ignore_for_file: type=lint
import 'dart:ffi' as ffi;
import 'package:objective_c/objective_c.dart' as objc;
import 'package:ffi/ffi.dart' as pkg_ffi;

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_pfv6jd(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_pfv6jd(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>)>()
external ffi.Pointer<objc.ObjCObject> _DarwinNativeBindings_protocolTrampoline_1mbt9g9(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
);

@ffi.Native<
  ffi.Long Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
  )
>()
external int _DarwinNativeBindings_protocolTrampoline_qz1oen(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_1pl9qdv(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_1pl9qdv(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_jk1ljc(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_jk1ljc(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_xtuoz7(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_xtuoz7(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>()
external void _DarwinNativeBindings_protocolTrampoline_jk1ljc(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_1s56lr9(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_1s56lr9(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_1hznzoi(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_1hznzoi(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'AVAudioSessionCategoryPlayback')
external final ffi.Pointer<objc.ObjCObject> _AVAudioSessionCategoryPlayback;

objc.NSString get AVAudioSessionCategoryPlayback =>
    objc.NSString.castFromPointer(_AVAudioSessionCategoryPlayback, retain: true, release: true);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_hk7n97(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_hk7n97(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'MPMediaItemPropertyTitle')
external ffi.Pointer<objc.ObjCObject> _MPMediaItemPropertyTitle;

objc.NSString get MPMediaItemPropertyTitle =>
    objc.NSString.castFromPointer(_MPMediaItemPropertyTitle, retain: true, release: true);

set MPMediaItemPropertyTitle(objc.NSString value) {
  objc.NSString.castFromPointer(_MPMediaItemPropertyTitle, retain: false, release: true).ref.release();
  _MPMediaItemPropertyTitle = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'MPMediaItemPropertyAlbumTitle')
external ffi.Pointer<objc.ObjCObject> _MPMediaItemPropertyAlbumTitle;

objc.NSString get MPMediaItemPropertyAlbumTitle =>
    objc.NSString.castFromPointer(_MPMediaItemPropertyAlbumTitle, retain: true, release: true);

set MPMediaItemPropertyAlbumTitle(objc.NSString value) {
  objc.NSString.castFromPointer(_MPMediaItemPropertyAlbumTitle, retain: false, release: true).ref.release();
  _MPMediaItemPropertyAlbumTitle = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'MPMediaItemPropertyArtist')
external ffi.Pointer<objc.ObjCObject> _MPMediaItemPropertyArtist;

objc.NSString get MPMediaItemPropertyArtist =>
    objc.NSString.castFromPointer(_MPMediaItemPropertyArtist, retain: true, release: true);

set MPMediaItemPropertyArtist(objc.NSString value) {
  objc.NSString.castFromPointer(_MPMediaItemPropertyArtist, retain: false, release: true).ref.release();
  _MPMediaItemPropertyArtist = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'MPMediaItemPropertyPlaybackDuration')
external ffi.Pointer<objc.ObjCObject> _MPMediaItemPropertyPlaybackDuration;

objc.NSString get MPMediaItemPropertyPlaybackDuration =>
    objc.NSString.castFromPointer(_MPMediaItemPropertyPlaybackDuration, retain: true, release: true);

set MPMediaItemPropertyPlaybackDuration(objc.NSString value) {
  objc.NSString.castFromPointer(_MPMediaItemPropertyPlaybackDuration, retain: false, release: true).ref.release();
  _MPMediaItemPropertyPlaybackDuration = value.ref.retainAndReturnPointer();
}

@ffi.Native<ffi.Pointer<objc.ObjCObject>>(symbol: 'MPMediaItemPropertyArtwork')
external ffi.Pointer<objc.ObjCObject> _MPMediaItemPropertyArtwork;

objc.NSString get MPMediaItemPropertyArtwork =>
    objc.NSString.castFromPointer(_MPMediaItemPropertyArtwork, retain: true, release: true);

set MPMediaItemPropertyArtwork(objc.NSString value) {
  objc.NSString.castFromPointer(_MPMediaItemPropertyArtwork, retain: false, release: true).ref.release();
  _MPMediaItemPropertyArtwork = value.ref.retainAndReturnPointer();
}

@ffi.Native<instancetype Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()
external instancetype _DarwinNativeBindings_protocolTrampoline_xr62hr(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
);

@ffi.Native<ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>)>()
external bool _DarwinNativeBindings_protocolTrampoline_e3qsqz(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
);

@ffi.Native<ffi.Pointer<objc.ObjCBlockImpl> Function(ffi.Pointer<objc.ObjCBlockImpl>)>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapListenerBlock_18v1jvf(
  ffi.Pointer<objc.ObjCBlockImpl> block,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCBlockImpl> Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<objc.DOBJC_Context>,
  )
>(isLeaf: true)
external ffi.Pointer<objc.ObjCBlockImpl> _DarwinNativeBindings_wrapBlockingBlock_18v1jvf(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCBlockImpl> listnerBlock,
  ffi.Pointer<objc.DOBJC_Context> context,
);

@ffi.Native<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()
external void _DarwinNativeBindings_protocolTrampoline_18v1jvf(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
);

@ffi.Native<
  ffi.UnsignedLong Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>()
external int _DarwinNativeBindings_protocolTrampoline_1jypdhr(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCObject> Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>()
external ffi.Pointer<objc.ObjCObject> _DarwinNativeBindings_protocolTrampoline_zi5eed(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
);

@ffi.Native<
  ffi.UnsignedLong Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>()
external int _DarwinNativeBindings_protocolTrampoline_zs9fen(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
);

@ffi.Native<
  instancetype Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
  )
>()
external instancetype _DarwinNativeBindings_protocolTrampoline_10z9f5k(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
);

@ffi.Native<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()
external int _DarwinNativeBindings_protocolTrampoline_1ldqghh(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
);

@ffi.Native<
  ffi.Pointer<objc.ObjCObject> Function(
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>()
external ffi.Pointer<objc.ObjCObject> _DarwinNativeBindings_protocolTrampoline_1q0i84(
  ffi.Pointer<objc.ObjCObject> target,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
);

final class CGAffineTransform extends ffi.Struct {
  @ffi.Double()
  external double a;

  @ffi.Double()
  external double b;

  @ffi.Double()
  external double c;

  @ffi.Double()
  external double d;

  @ffi.Double()
  external double tx;

  @ffi.Double()
  external double ty;
}

/// WARNING: NSBundle is a stub. To generate bindings for this class, include
/// NSBundle in your config's objc-interfaces list.
///
/// NSBundle
class NSBundle extends objc.NSObject {
  NSBundle._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [NSBundle] that points to the same underlying object as [other].
  NSBundle.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSBundle] that wraps the given raw object pointer.
  NSBundle.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

enum NSAttributedStringEnumerationOptions {
  NSAttributedStringEnumerationReverse(2),
  NSAttributedStringEnumerationLongestEffectiveRangeNotRequired(1048576);

  final int value;
  const NSAttributedStringEnumerationOptions(this.value);

  static NSAttributedStringEnumerationOptions fromValue(int value) => switch (value) {
    2 => NSAttributedStringEnumerationReverse,
    1048576 => NSAttributedStringEnumerationLongestEffectiveRangeNotRequired,
    _ => throw ArgumentError('Unknown value for NSAttributedStringEnumerationOptions: $value'),
  };
}

enum NSAttributedStringMarkdownParsingFailurePolicy {
  NSAttributedStringMarkdownParsingFailureReturnError(0),
  NSAttributedStringMarkdownParsingFailureReturnPartiallyParsedIfPossible(1);

  final int value;
  const NSAttributedStringMarkdownParsingFailurePolicy(this.value);

  static NSAttributedStringMarkdownParsingFailurePolicy fromValue(int value) => switch (value) {
    0 => NSAttributedStringMarkdownParsingFailureReturnError,
    1 => NSAttributedStringMarkdownParsingFailureReturnPartiallyParsedIfPossible,
    _ => throw ArgumentError('Unknown value for NSAttributedStringMarkdownParsingFailurePolicy: $value'),
  };
}

enum NSAttributedStringMarkdownInterpretedSyntax {
  NSAttributedStringMarkdownInterpretedSyntaxFull(0),
  NSAttributedStringMarkdownInterpretedSyntaxInlineOnly(1),
  NSAttributedStringMarkdownInterpretedSyntaxInlineOnlyPreservingWhitespace(2);

  final int value;
  const NSAttributedStringMarkdownInterpretedSyntax(this.value);

  static NSAttributedStringMarkdownInterpretedSyntax fromValue(int value) => switch (value) {
    0 => NSAttributedStringMarkdownInterpretedSyntaxFull,
    1 => NSAttributedStringMarkdownInterpretedSyntaxInlineOnly,
    2 => NSAttributedStringMarkdownInterpretedSyntaxInlineOnlyPreservingWhitespace,
    _ => throw ArgumentError('Unknown value for NSAttributedStringMarkdownInterpretedSyntax: $value'),
  };
}

enum NSAttributedStringFormattingOptions {
  NSAttributedStringFormattingInsertArgumentAttributesWithoutMerging(1),
  NSAttributedStringFormattingApplyReplacementIndexAttribute(2);

  final int value;
  const NSAttributedStringFormattingOptions(this.value);

  static NSAttributedStringFormattingOptions fromValue(int value) => switch (value) {
    1 => NSAttributedStringFormattingInsertArgumentAttributesWithoutMerging,
    2 => NSAttributedStringFormattingApplyReplacementIndexAttribute,
    _ => throw ArgumentError('Unknown value for NSAttributedStringFormattingOptions: $value'),
  };
}

final class OpaqueIconRef extends ffi.Opaque {}

enum NSFileWrapperReadingOptions {
  NSFileWrapperReadingImmediate(1),
  NSFileWrapperReadingWithoutMapping(2);

  final int value;
  const NSFileWrapperReadingOptions(this.value);

  static NSFileWrapperReadingOptions fromValue(int value) => switch (value) {
    1 => NSFileWrapperReadingImmediate,
    2 => NSFileWrapperReadingWithoutMapping,
    _ => throw ArgumentError('Unknown value for NSFileWrapperReadingOptions: $value'),
  };
}

enum NSFileWrapperWritingOptions {
  NSFileWrapperWritingAtomic(1),
  NSFileWrapperWritingWithNameUpdating(2);

  final int value;
  const NSFileWrapperWritingOptions(this.value);

  static NSFileWrapperWritingOptions fromValue(int value) => switch (value) {
    1 => NSFileWrapperWritingAtomic,
    2 => NSFileWrapperWritingWithNameUpdating,
    _ => throw ArgumentError('Unknown value for NSFileWrapperWritingOptions: $value'),
  };
}

enum AVKeyValueStatus {
  AVKeyValueStatusUnknown(0),
  AVKeyValueStatusLoading(1),
  AVKeyValueStatusLoaded(2),
  AVKeyValueStatusFailed(3),
  AVKeyValueStatusCancelled(4);

  final int value;
  const AVKeyValueStatus(this.value);

  static AVKeyValueStatus fromValue(int value) => switch (value) {
    0 => AVKeyValueStatusUnknown,
    1 => AVKeyValueStatusLoading,
    2 => AVKeyValueStatusLoaded,
    3 => AVKeyValueStatusFailed,
    4 => AVKeyValueStatusCancelled,
    _ => throw ArgumentError('Unknown value for AVKeyValueStatus: $value'),
  };
}

/// WARNING: AVAsynchronousKeyValueLoading is a stub. To generate bindings for this class, include
/// AVAsynchronousKeyValueLoading in your config's objc-protocols list.
///
/// AVAsynchronousKeyValueLoading
interface class AVAsynchronousKeyValueLoading extends objc.ObjCProtocolBase {
  AVAsynchronousKeyValueLoading._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAsynchronousKeyValueLoading] that points to the same underlying object as [other].
  AVAsynchronousKeyValueLoading.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAsynchronousKeyValueLoading] that wraps the given raw object pointer.
  AVAsynchronousKeyValueLoading.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

enum CMTimeFlags {
  kCMTimeFlags_Valid(1),
  kCMTimeFlags_HasBeenRounded(2),
  kCMTimeFlags_PositiveInfinity(4),
  kCMTimeFlags_NegativeInfinity(8),
  kCMTimeFlags_Indefinite(16),
  kCMTimeFlags_ImpliedValueFlagsMask(28);

  final int value;
  const CMTimeFlags(this.value);

  static CMTimeFlags fromValue(int value) => switch (value) {
    1 => kCMTimeFlags_Valid,
    2 => kCMTimeFlags_HasBeenRounded,
    4 => kCMTimeFlags_PositiveInfinity,
    8 => kCMTimeFlags_NegativeInfinity,
    16 => kCMTimeFlags_Indefinite,
    28 => kCMTimeFlags_ImpliedValueFlagsMask,
    _ => throw ArgumentError('Unknown value for CMTimeFlags: $value'),
  };
}

@ffi.Packed(4)
final class CMTime extends ffi.Struct {
  @ffi.Int64()
  external int value;

  @ffi.Int32()
  external int timescale;

  @ffi.Uint32()
  external int flagsAsInt;

  CMTimeFlags get flags => CMTimeFlags.fromValue(flagsAsInt);

  @ffi.Int64()
  external int epoch;
}

final class AudioStreamBasicDescription extends ffi.Struct {
  @ffi.Double()
  external double mSampleRate;

  @ffi.UnsignedInt()
  external int mFormatID;

  @ffi.UnsignedInt()
  external int mFormatFlags;

  @ffi.UnsignedInt()
  external int mBytesPerPacket;

  @ffi.UnsignedInt()
  external int mFramesPerPacket;

  @ffi.UnsignedInt()
  external int mBytesPerFrame;

  @ffi.UnsignedInt()
  external int mChannelsPerFrame;

  @ffi.UnsignedInt()
  external int mBitsPerChannel;

  @ffi.UnsignedInt()
  external int mReserved;
}

enum AudioChannelBitmap {
  kAudioChannelBit_Left(1),
  kAudioChannelBit_Right(2),
  kAudioChannelBit_Center(4),
  kAudioChannelBit_LFEScreen(8),
  kAudioChannelBit_LeftSurround(16),
  kAudioChannelBit_RightSurround(32),
  kAudioChannelBit_LeftCenter(64),
  kAudioChannelBit_RightCenter(128),
  kAudioChannelBit_CenterSurround(256),
  kAudioChannelBit_LeftSurroundDirect(512),
  kAudioChannelBit_RightSurroundDirect(1024),
  kAudioChannelBit_TopCenterSurround(2048),
  kAudioChannelBit_VerticalHeightLeft(4096),
  kAudioChannelBit_VerticalHeightCenter(8192),
  kAudioChannelBit_VerticalHeightRight(16384),
  kAudioChannelBit_TopBackLeft(32768),
  kAudioChannelBit_TopBackCenter(65536),
  kAudioChannelBit_TopBackRight(131072),
  kAudioChannelBit_LeftTopMiddle(2097152),
  kAudioChannelBit_RightTopMiddle(8388608),
  kAudioChannelBit_LeftTopRear(16777216),
  kAudioChannelBit_CenterTopRear(33554432),
  kAudioChannelBit_RightTopRear(67108864);

  static const kAudioChannelBit_LeftTopFront = kAudioChannelBit_VerticalHeightLeft;
  static const kAudioChannelBit_CenterTopFront = kAudioChannelBit_VerticalHeightCenter;
  static const kAudioChannelBit_RightTopFront = kAudioChannelBit_VerticalHeightRight;
  static const kAudioChannelBit_CenterTopMiddle = kAudioChannelBit_TopCenterSurround;

  final int value;
  const AudioChannelBitmap(this.value);

  static AudioChannelBitmap fromValue(int value) => switch (value) {
    1 => kAudioChannelBit_Left,
    2 => kAudioChannelBit_Right,
    4 => kAudioChannelBit_Center,
    8 => kAudioChannelBit_LFEScreen,
    16 => kAudioChannelBit_LeftSurround,
    32 => kAudioChannelBit_RightSurround,
    64 => kAudioChannelBit_LeftCenter,
    128 => kAudioChannelBit_RightCenter,
    256 => kAudioChannelBit_CenterSurround,
    512 => kAudioChannelBit_LeftSurroundDirect,
    1024 => kAudioChannelBit_RightSurroundDirect,
    2048 => kAudioChannelBit_TopCenterSurround,
    4096 => kAudioChannelBit_VerticalHeightLeft,
    8192 => kAudioChannelBit_VerticalHeightCenter,
    16384 => kAudioChannelBit_VerticalHeightRight,
    32768 => kAudioChannelBit_TopBackLeft,
    65536 => kAudioChannelBit_TopBackCenter,
    131072 => kAudioChannelBit_TopBackRight,
    2097152 => kAudioChannelBit_LeftTopMiddle,
    8388608 => kAudioChannelBit_RightTopMiddle,
    16777216 => kAudioChannelBit_LeftTopRear,
    33554432 => kAudioChannelBit_CenterTopRear,
    67108864 => kAudioChannelBit_RightTopRear,
    _ => throw ArgumentError('Unknown value for AudioChannelBitmap: $value'),
  };

  @override
  String toString() {
    if (this == kAudioChannelBit_TopCenterSurround)
      return "AudioChannelBitmap.kAudioChannelBit_TopCenterSurround, AudioChannelBitmap.kAudioChannelBit_CenterTopMiddle";
    if (this == kAudioChannelBit_VerticalHeightLeft)
      return "AudioChannelBitmap.kAudioChannelBit_VerticalHeightLeft, AudioChannelBitmap.kAudioChannelBit_LeftTopFront";
    if (this == kAudioChannelBit_VerticalHeightCenter)
      return "AudioChannelBitmap.kAudioChannelBit_VerticalHeightCenter, AudioChannelBitmap.kAudioChannelBit_CenterTopFront";
    if (this == kAudioChannelBit_VerticalHeightRight)
      return "AudioChannelBitmap.kAudioChannelBit_VerticalHeightRight, AudioChannelBitmap.kAudioChannelBit_RightTopFront";
    return super.toString();
  }
}

enum AudioChannelFlags {
  kAudioChannelFlags_AllOff(0),
  kAudioChannelFlags_RectangularCoordinates(1),
  kAudioChannelFlags_SphericalCoordinates(2),
  kAudioChannelFlags_Meters(4);

  final int value;
  const AudioChannelFlags(this.value);

  static AudioChannelFlags fromValue(int value) => switch (value) {
    0 => kAudioChannelFlags_AllOff,
    1 => kAudioChannelFlags_RectangularCoordinates,
    2 => kAudioChannelFlags_SphericalCoordinates,
    4 => kAudioChannelFlags_Meters,
    _ => throw ArgumentError('Unknown value for AudioChannelFlags: $value'),
  };
}

final class AudioChannelDescription extends ffi.Struct {
  @ffi.UnsignedInt()
  external int mChannelLabel;

  @ffi.UnsignedInt()
  external int mChannelFlagsAsInt;

  AudioChannelFlags get mChannelFlags => AudioChannelFlags.fromValue(mChannelFlagsAsInt);

  @ffi.Array.multi([3])
  external ffi.Array<ffi.Float> mCoordinates;
}

final class AudioChannelLayout extends ffi.Struct {
  @ffi.UnsignedInt()
  external int mChannelLayoutTag;

  @ffi.UnsignedInt()
  external int mChannelBitmapAsInt;

  AudioChannelBitmap get mChannelBitmap => AudioChannelBitmap.fromValue(mChannelBitmapAsInt);

  @ffi.UnsignedInt()
  external int mNumberChannelDescriptions;

  @ffi.Array.multi([1])
  external ffi.Array<AudioChannelDescription> mChannelDescriptions;
}

final class CGImage extends ffi.Opaque {}

final class opaqueCMFormatDescription extends ffi.Opaque {}

late final _class_AVAsset = objc.getClass("AVAsset");
late final _sel_isKindOfClass_ = objc.registerName("isKindOfClass:");
final _objc_msgSend_19nvye5 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
      >
    >()
    .asFunction<
      bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
    >();
late final _sel_providesPreciseDurationAndTiming = objc.registerName("providesPreciseDurationAndTiming");
final _objc_msgSend_91o635 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_cancelLoading = objc.registerName("cancelLoading");
final _objc_msgSend_1pl9qdv = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetAsynchronousLoading
extension AVAssetAsynchronousLoading on AVAsset {
  /// providesPreciseDurationAndTiming
  bool get providesPreciseDurationAndTiming {
    objc.checkOsVersionInternal(
      'AVAsset.providesPreciseDurationAndTiming',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_providesPreciseDurationAndTiming);
  }

  /// !
  /// @method		cancelLoading
  /// @abstract		Cancels the loading of all values for all observers.
  /// @discussion	Deallocation or finalization of an instance of AVAsset will implicitly cancel loading if any loading requests are still outstanding.
  void cancelLoading() {
    objc.checkOsVersionInternal('AVAsset.cancelLoading', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelLoading);
  }
}

/// !
/// @enum			AVAssetReferenceRestrictions
/// @abstract		These constants can be passed in to AVURLAssetReferenceRestrictionsKey to control the resolution of references to external media data.
///
/// @constant		AVAssetReferenceRestrictionForbidNone
/// Indicates that all types of references should be followed.
/// @constant		AVAssetReferenceRestrictionForbidRemoteReferenceToLocal
/// Indicates that references from a remote asset (e.g. referenced via http URL) to local media data (e.g. stored in a local file) should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidLocalReferenceToRemote
/// Indicates that references from a local asset to remote media data should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidCrossSiteReference
/// Indicates that references from a remote asset to remote media data stored at a different site should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidLocalReferenceToLocal
/// Indicates that references from a local asset to local media data stored outside the asset's container file should not be followed.
/// @constant		AVAssetReferenceRestrictionForbidAll
/// Indicates that only references to media data stored within the asset's container file should be allowed.
enum AVAssetReferenceRestrictions {
  AVAssetReferenceRestrictionForbidNone(0),
  AVAssetReferenceRestrictionForbidRemoteReferenceToLocal(1),
  AVAssetReferenceRestrictionForbidLocalReferenceToRemote(2),
  AVAssetReferenceRestrictionForbidCrossSiteReference(4),
  AVAssetReferenceRestrictionForbidLocalReferenceToLocal(8),
  AVAssetReferenceRestrictionForbidAll(65535);

  static const AVAssetReferenceRestrictionDefaultPolicy = AVAssetReferenceRestrictionForbidLocalReferenceToRemote;

  final int value;
  const AVAssetReferenceRestrictions(this.value);

  static AVAssetReferenceRestrictions fromValue(int value) => switch (value) {
    0 => AVAssetReferenceRestrictionForbidNone,
    1 => AVAssetReferenceRestrictionForbidRemoteReferenceToLocal,
    2 => AVAssetReferenceRestrictionForbidLocalReferenceToRemote,
    4 => AVAssetReferenceRestrictionForbidCrossSiteReference,
    8 => AVAssetReferenceRestrictionForbidLocalReferenceToLocal,
    65535 => AVAssetReferenceRestrictionForbidAll,
    _ => throw ArgumentError('Unknown value for AVAssetReferenceRestrictions: $value'),
  };

  @override
  String toString() {
    if (this == AVAssetReferenceRestrictionForbidLocalReferenceToRemote)
      return "AVAssetReferenceRestrictions.AVAssetReferenceRestrictionForbidLocalReferenceToRemote, AVAssetReferenceRestrictions.AVAssetReferenceRestrictionDefaultPolicy";
    return super.toString();
  }
}

late final _sel_referenceRestrictions = objc.registerName("referenceRestrictions");
final _objc_msgSend_1m7g6j8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetReferenceRestrictions
extension AVAssetReferenceRestrictions$1 on AVAsset {
  /// !
  /// @property		referenceRestrictions
  /// @abstract		Indicates the reference restrictions being used by the receiver.
  /// @discussion
  /// For AVURLAsset, this property reflects the value passed in for AVURLAssetReferenceRestrictionsKey, if any. See AVURLAssetReferenceRestrictionsKey below for a full discussion of reference restrictions. The default value for this property is AVAssetReferenceRestrictionForbidLocalReferenceToRemote.
  AVAssetReferenceRestrictions get referenceRestrictions {
    objc.checkOsVersionInternal('AVAsset.referenceRestrictions', iOS: (false, (5, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1m7g6j8(this.ref.pointer, _sel_referenceRestrictions);
    return AVAssetReferenceRestrictions.fromValue(_ret);
  }
}

late final _sel_tracks = objc.registerName("tracks");
final _objc_msgSend_151sglz = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// WARNING: AVAssetTrack is a stub. To generate bindings for this class, include
/// AVAssetTrack in your config's objc-interfaces list.
///
/// !
/// @class		AVAsset
///
/// @abstract
/// An AVAsset is an abstract class that defines AVFoundation's model for timed audiovisual media.
///
/// Each asset contains a collection of tracks that are intended to be presented or processed together, each of a uniform media type, including but not limited to audio, video, text, closed captions, and subtitles.
///
/// @discussion
/// AVAssets are often instantiated via its concrete subclass AVURLAsset with NSURLs that refer to audiovisual media resources, such as streams (including HTTP live streams), QuickTime movie files, MP3 files, and files of other types.
///
/// They can also be instantiated using other concrete subclasses that extend the basic model for audiovisual media in useful ways, as AVComposition does for temporal editing.
///
/// Properties of assets as a whole are defined by AVAsset. Additionally, references to instances of AVAssetTracks representing tracks of the collection can be obtained, so that each of these can be examined independently.
///
/// Because of the nature of timed audiovisual media, upon successful initialization of an AVAsset some or all of the values for its keys may not be immediately available. The value of any key can be requested at any time, and AVAsset will always return its value synchronously, although it may have to block the calling thread in order to do so.
///
/// In order to avoid blocking, clients can register their interest in particular keys and to become notified when their values become available. For further details, see AVAsynchronousKeyValueLoading.h. For clients who want to examine a subset of the tracks, metadata, and other parts of the asset, asynchronous methods like -loadTracksWithMediaType:completionHandler: can be used to load this information without blocking. When using these asynchronous methods, it is not necessary to load the associated property beforehand. Swift clients can also use the load(:) method to load properties in a type safe manner.
///
/// On platforms other than macOS, it is particularly important to avoid blocking.  To preserve responsiveness, a synchronous request that blocks for too long (eg, a property request on an asset on a slow HTTP server) may lead to media services being reset.
///
/// To play an instance of AVAsset, initialize an instance of AVPlayerItem with it, use the AVPlayerItem to set up its presentation state (such as whether only a limited timeRange of the asset should be played, etc.), and provide the AVPlayerItem to an AVPlayer according to whether the items is to be played by itself or together with a collection of other items. Full details available in AVPlayerItem.h and AVPlayer.h.
///
/// AVAssets can also be inserted into AVMutableCompositions in order to assemble audiovisual constructs from one or more source assets.
class AVAssetTrack extends objc.ObjCObjectBase {
  AVAssetTrack._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAssetTrack] that points to the same underlying object as [other].
  AVAssetTrack.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAssetTrack] that wraps the given raw object pointer.
  AVAssetTrack.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_trackWithTrackID_ = objc.registerName("trackWithTrackID:");
final _objc_msgSend_aclumu = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Int32)
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)
    >();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_AVAssetTrack_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_AVAssetTrack_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> fromFunction(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> listener(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> blocking(
    void Function(AVAssetTrack, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVAssetTrack_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVAssetTrack.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_AVAssetTrack_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> {
  void call(AVAssetTrack arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0.ref.pointer, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadTrackWithTrackID_completionHandler_ = objc.registerName("loadTrackWithTrackID:completionHandler:");
final _objc_msgSend_vhb0ih = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Int32,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int, ffi.Pointer<objc.ObjCBlockImpl>)
    >();
late final _sel_tracksWithMediaType_ = objc.registerName("tracksWithMediaType:");
final _objc_msgSend_1sotr3r = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
void _ObjCBlock_ffiVoid_NSArray_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSArray_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSArray_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSArray_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSArray_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSArray_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSArray_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSArray_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSArray_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSArray_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_NSArray_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_NSArray_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSArray_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> fromFunction(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> listener(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> blocking(
    void Function(objc.NSArray?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSArray_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSArray.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_NSArray_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> {
  void call(objc.NSArray? arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0?.ref.pointer ?? ffi.nullptr, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadTracksWithMediaType_completionHandler_ = objc.registerName(
  "loadTracksWithMediaType:completionHandler:",
);
final _objc_msgSend_o762yo = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_tracksWithMediaCharacteristic_ = objc.registerName("tracksWithMediaCharacteristic:");
late final _sel_loadTracksWithMediaCharacteristic_completionHandler_ = objc.registerName(
  "loadTracksWithMediaCharacteristic:completionHandler:",
);
late final _sel_trackGroups = objc.registerName("trackGroups");

/// AVAssetTrackInspection
extension AVAssetTrackInspection on AVAsset {
  /// !
  /// @property		tracks
  /// @abstract		Provides the array of AVAssetTracks contained by the asset
  objc.NSArray get tracks {
    objc.checkOsVersionInternal('AVAsset.tracks', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_tracks);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		trackWithTrackID:
  /// @abstract		Provides an instance of AVAssetTrack that represents the track of the specified trackID.
  /// @param		trackID
  /// The trackID of the requested AVAssetTrack.
  /// @result		An instance of AVAssetTrack; may be nil if no track of the specified trackID is available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  AVAssetTrack? trackWithTrackID(int trackID) {
    objc.checkOsVersionInternal('AVAsset.trackWithTrackID:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_aclumu(this.ref.pointer, _sel_trackWithTrackID_, trackID);
    return _ret.address == 0 ? null : AVAssetTrack.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTrackWithTrackID:completionHandler:
  /// @abstract		Loads an instance of AVAssetTrack that represents the track of the specified trackID.
  /// @param		trackID
  /// The trackID of the requested AVAssetTrack.
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded track (which may be nil if no track of the specified trackID is available) or an error.
  void loadTrackWithTrackID(
    int trackID, {
    required objc.ObjCBlock<ffi.Void Function(AVAssetTrack, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTrackWithTrackID:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_vhb0ih(
      this.ref.pointer,
      _sel_loadTrackWithTrackID_completionHandler_,
      trackID,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		tracksWithMediaType:
  /// @abstract		Provides an array of AVAssetTracks of the asset that present media of the specified media type.
  /// @param		mediaType
  /// The media type according to which AVAsset filters its AVAssetTracks. (Media types are defined in AVMediaFormat.h.)
  /// @result		An NSArray of AVAssetTracks; may be empty if no tracks of the specified media type are available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  objc.NSArray tracksWithMediaType(objc.NSString mediaType) {
    objc.checkOsVersionInternal('AVAsset.tracksWithMediaType:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_tracksWithMediaType_, mediaType.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTracksWithMediaType:completionHandler:
  /// @abstract		Loads an array of AVAssetTracks of the asset that present media of the specified media type.
  /// @param		mediaType
  /// The media type according to which AVAsset filters its AVAssetTracks. (Media types are defined in AVMediaFormat.h.)
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded tracks (which may be empty if no tracks of the specified media type are available) or an error.
  void loadTracksWithMediaType(
    objc.NSString mediaType, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTracksWithMediaType:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadTracksWithMediaType_completionHandler_,
      mediaType.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		tracksWithMediaCharacteristic:
  /// @abstract		Provides an array of AVAssetTracks of the asset that present media with the specified characteristic.
  /// @param		mediaCharacteristic
  /// The media characteristic according to which AVAsset filters its AVAssetTracks. (Media characteristics are defined in AVMediaFormat.h.)
  /// @result		An NSArray of AVAssetTracks; may be empty if no tracks with the specified characteristic are available.
  /// @discussion	Becomes callable without blocking when the key @"tracks" has been loaded
  objc.NSArray tracksWithMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVAsset.tracksWithMediaCharacteristic:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_tracksWithMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadTracksWithMediaCharacteristic:completionHandler:
  /// @abstract		Loads an array of AVAssetTracks of the asset that present media with the specified characteristic.
  /// @param		mediaCharacteristic
  /// The media characteristic according to which AVAsset filters its AVAssetTracks. (Media characteristics are defined in AVMediaFormat.h.)
  /// @param		completionHandler
  /// A block that is called when the loading is finished, with either the loaded tracks (which may be empty if no tracks with the specified characteristic are available) or an error.
  void loadTracksWithMediaCharacteristic(
    objc.NSString mediaCharacteristic, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadTracksWithMediaCharacteristic:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadTracksWithMediaCharacteristic_completionHandler_,
      mediaCharacteristic.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @property trackGroups
  /// @abstract
  /// All track groups in the receiver.
  ///
  /// @discussion
  /// The value of this property is an NSArray of AVAssetTrackGroups, each representing a different grouping of tracks in the receiver.
  objc.NSArray get trackGroups {
    objc.checkOsVersionInternal('AVAsset.trackGroups', iOS: (false, (7, 0, 0)), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_trackGroups);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVMetadataItem is a stub. To generate bindings for this class, include
/// AVMetadataItem in your config's objc-interfaces list.
///
/// AVMetadataItem
class AVMetadataItem extends objc.ObjCObjectBase {
  AVMetadataItem._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMetadataItem] that points to the same underlying object as [other].
  AVMetadataItem.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMetadataItem] that wraps the given raw object pointer.
  AVMetadataItem.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_creationDate = objc.registerName("creationDate");
late final _sel_lyrics = objc.registerName("lyrics");
late final _sel_commonMetadata = objc.registerName("commonMetadata");
late final _sel_metadata = objc.registerName("metadata");
late final _sel_availableMetadataFormats = objc.registerName("availableMetadataFormats");
late final _sel_metadataForFormat_ = objc.registerName("metadataForFormat:");
late final _sel_loadMetadataForFormat_completionHandler_ = objc.registerName(
  "loadMetadataForFormat:completionHandler:",
);

/// AVAssetMetadataReading
extension AVAssetMetadataReading on AVAsset {
  /// creationDate
  AVMetadataItem? get creationDate {
    objc.checkOsVersionInternal('AVAsset.creationDate', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_creationDate);
    return _ret.address == 0 ? null : AVMetadataItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// lyrics
  objc.NSString? get lyrics {
    objc.checkOsVersionInternal('AVAsset.lyrics', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_lyrics);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// commonMetadata
  objc.NSArray get commonMetadata {
    objc.checkOsVersionInternal('AVAsset.commonMetadata', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_commonMetadata);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// metadata
  objc.NSArray get metadata {
    objc.checkOsVersionInternal('AVAsset.metadata', iOS: (false, (8, 0, 0)), macOS: (false, (10, 10, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_metadata);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// availableMetadataFormats
  objc.NSArray get availableMetadataFormats {
    objc.checkOsVersionInternal(
      'AVAsset.availableMetadataFormats',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableMetadataFormats);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		metadataForFormat:
  /// @abstract		Provides an NSArray of AVMetadataItems, one for each metadata item in the container of the specified format; can subsequently be filtered according to language via +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:], according to locale via +[AVMetadataItem metadataItemsFromArray:withLocale:], or according to key via +[AVMetadataItem metadataItemsFromArray:withKey:keySpace:].
  /// @param		format
  /// The metadata format for which items are requested.
  /// @result		An NSArray containing AVMetadataItems; may be empty if there is no metadata of the specified format.
  /// @discussion	Becomes callable without blocking when the key @"availableMetadataFormats" has been loaded
  objc.NSArray metadataForFormat(objc.NSString format) {
    objc.checkOsVersionInternal('AVAsset.metadataForFormat:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_metadataForFormat_, format.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadMetadataForFormat:completionHandler:
  /// @abstract		Loads an NSArray of AVMetadataItems, one for each metadata item in the container of the specified format; can subsequently be filtered according to language via +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:], according to locale via +[AVMetadataItem metadataItemsFromArray:withLocale:], or according to key via +[AVMetadataItem metadataItemsFromArray:withKey:keySpace:].
  /// @param		format
  /// The metadata format for which items are requested.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending the array of metadata items (which may be empty if there is no metadata of the specified format) or an error.
  void loadMetadataForFormat(
    objc.NSString format, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadMetadataForFormat:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadMetadataForFormat_completionHandler_,
      format.ref.pointer,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_availableChapterLocales = objc.registerName("availableChapterLocales");
late final _sel_chapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_ = objc.registerName(
  "chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:",
);
final _objc_msgSend_15qeuct = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_loadChapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_completionHandler_ = objc
    .registerName("loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:");
final _objc_msgSend_18qun1e = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_chapterMetadataGroupsBestMatchingPreferredLanguages_ = objc.registerName(
  "chapterMetadataGroupsBestMatchingPreferredLanguages:",
);
late final _sel_loadChapterMetadataGroupsBestMatchingPreferredLanguages_completionHandler_ = objc.registerName(
  "loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:",
);

/// AVAssetChapterInspection
extension AVAssetChapterInspection on AVAsset {
  /// availableChapterLocales
  objc.NSArray get availableChapterLocales {
    objc.checkOsVersionInternal('AVAsset.availableChapterLocales', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableChapterLocales);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:
  /// @abstract		Provides an array of chapters.
  /// @param		locale
  /// Locale of the metadata items carrying chapter titles to be returned (supports the IETF BCP 47 specification).
  /// @param		commonKeys
  /// Array of common keys of AVMetadataItem to be included; can be nil.
  /// AVMetadataCommonKeyArtwork is the only supported key for now.
  /// @result		An NSArray of AVTimedMetadataGroup.
  /// @discussion
  /// This method returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// An AVMetadataItem with the specified common key will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and the metadata group overlaps. The locale of items not carrying chapter titles need not match the specified locale parameter.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  objc.NSArray chapterMetadataGroupsWithTitleLocale(
    objc.NSLocale locale, {
    objc.NSArray? containingItemsWithCommonKeys,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.chapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:',
      iOS: (false, (4, 3, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      this.ref.pointer,
      _sel_chapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_,
      locale.ref.pointer,
      containingItemsWithCommonKeys?.ref.pointer ?? ffi.nullptr,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:
  /// @abstract		Loads an array of chapters.
  /// @param		locale
  /// Locale of the metadata items carrying chapter titles to be returned (supports the IETF BCP 47 specification).
  /// @param		commonKeys
  /// Array of common keys of AVMetadataItem to be included; if no common keys are required, send an empty list.
  /// AVMetadataCommonKeyArtwork is the only supported key for now.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending the array of timed metadata groups or an error.
  /// @discussion
  /// This method vends an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// An AVMetadataItem with the specified common key will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and the metadata group overlaps. The locale of items not carrying chapter titles need not match the specified locale parameter.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  void loadChapterMetadataGroupsWithTitleLocale(
    objc.NSLocale locale, {
    required objc.NSArray containingItemsWithCommonKeys,
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadChapterMetadataGroupsWithTitleLocale:containingItemsWithCommonKeys:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_18qun1e(
      this.ref.pointer,
      _sel_loadChapterMetadataGroupsWithTitleLocale_containingItemsWithCommonKeys_completionHandler_,
      locale.ref.pointer,
      containingItemsWithCommonKeys.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method		chapterMetadataGroupsBestMatchingPreferredLanguages:
  /// @abstract		Tests, in order of preference, for a match between language identifiers in the specified array of preferred languages and the available chapter locales, and returns the array of chapters corresponding to the first match that's found.
  /// @param			preferredLanguages
  /// An array of language identifiers in order of preference, each of which is an IETF BCP 47 (RFC 4646) language identifier. Use +[NSLocale preferredLanguages] to obtain the user's list of preferred languages.
  /// @result		An NSArray of AVTimedMetadataGroup.
  /// @discussion
  /// Safe to call without blocking when the AVAsset key availableChapterLocales has status AVKeyValueStatusLoaded.
  ///
  /// Returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// All of the available chapter metadata is included in the metadata groups, including items with the common key AVMetadataCommonKeyArtwork, if such items are present. Items not carrying chapter titles will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and that of the metadata group overlaps. The locale of such items need not match the locale of the chapter titles.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  /// .
  objc.NSArray chapterMetadataGroupsBestMatchingPreferredLanguages(objc.NSArray preferredLanguages) {
    objc.checkOsVersionInternal(
      'AVAsset.chapterMetadataGroupsBestMatchingPreferredLanguages:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_chapterMetadataGroupsBestMatchingPreferredLanguages_,
      preferredLanguages.ref.pointer,
    );
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:
  /// @abstract		Tests, in order of preference, for a match between language identifiers in the specified array of preferred languages and the available chapter locales, and loads the array of chapters corresponding to the first match that's found.
  /// @param			preferredLanguages
  /// An array of language identifiers in order of preference, each of which is an IETF BCP 47 (RFC 4646) language identifier. Use +[NSLocale preferredLanguages] to obtain the user's list of preferred languages.
  /// @param			completionHandler
  /// A block that is invoked when loading is complete, vending the array of timed metadata groups or an error.
  /// @discussion
  /// Returns an array of AVTimedMetadataGroup objects. Each object in the array always contains an AVMetadataItem representing the chapter title; the timeRange property of the AVTimedMetadataGroup object is equal to the time range of the chapter title item.
  ///
  /// All of the available chapter metadata is included in the metadata groups, including items with the common key AVMetadataCommonKeyArtwork, if such items are present. Items not carrying chapter titles will be added to an existing AVTimedMetadataGroup object if the time range (timestamp and duration) of the metadata item and that of the metadata group overlaps. The locale of such items need not match the locale of the chapter titles.
  ///
  /// Further filtering of the metadata items in AVTimedMetadataGroups according to language can be accomplished using +[AVMetadataItem metadataItemsFromArray:filteredAndSortedAccordingToPreferredLanguages:]; filtering of the metadata items according to locale can be accomplished using +[AVMetadataItem metadataItemsFromArray:withLocale:].
  void loadChapterMetadataGroupsBestMatchingPreferredLanguages(
    objc.NSArray preferredLanguages, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSArray?, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadChapterMetadataGroupsBestMatchingPreferredLanguages:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadChapterMetadataGroupsBestMatchingPreferredLanguages_completionHandler_,
      preferredLanguages.ref.pointer,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_availableMediaCharacteristicsWithMediaSelectionOptions = objc.registerName(
  "availableMediaCharacteristicsWithMediaSelectionOptions",
);

/// WARNING: AVMediaSelectionGroup is a stub. To generate bindings for this class, include
/// AVMediaSelectionGroup in your config's objc-interfaces list.
///
/// AVMediaSelectionGroup
class AVMediaSelectionGroup extends objc.ObjCObjectBase {
  AVMediaSelectionGroup._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelectionGroup] that points to the same underlying object as [other].
  AVMediaSelectionGroup.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelectionGroup] that wraps the given raw object pointer.
  AVMediaSelectionGroup.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_mediaSelectionGroupForMediaCharacteristic_ = objc.registerName(
  "mediaSelectionGroupForMediaCharacteristic:",
);
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> fromFunction(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> listener(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> blocking(
    void Function(AVMediaSelectionGroup, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        AVMediaSelectionGroup.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_AVMediaSelectionGroup_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> {
  void call(AVMediaSelectionGroup arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0.ref.pointer, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadMediaSelectionGroupForMediaCharacteristic_completionHandler_ = objc.registerName(
  "loadMediaSelectionGroupForMediaCharacteristic:completionHandler:",
);

/// WARNING: AVMediaSelection is a stub. To generate bindings for this class, include
/// AVMediaSelection in your config's objc-interfaces list.
///
/// AVMediaSelection
class AVMediaSelection extends objc.ObjCObjectBase {
  AVMediaSelection._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelection] that points to the same underlying object as [other].
  AVMediaSelection.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelection] that wraps the given raw object pointer.
  AVMediaSelection.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_preferredMediaSelection = objc.registerName("preferredMediaSelection");
late final _sel_allMediaSelections = objc.registerName("allMediaSelections");

/// AVAssetMediaSelection
extension AVAssetMediaSelection on AVAsset {
  /// availableMediaCharacteristicsWithMediaSelectionOptions
  objc.NSArray get availableMediaCharacteristicsWithMediaSelectionOptions {
    objc.checkOsVersionInternal(
      'AVAsset.availableMediaCharacteristicsWithMediaSelectionOptions',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableMediaCharacteristicsWithMediaSelectionOptions);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		mediaSelectionGroupForMediaCharacteristic:
  /// @abstract		Provides an instance of AVMediaSelectionGroup that contains one or more options with the specified media characteristic.
  /// @param		mediaCharacteristic
  /// A media characteristic for which you wish to obtain the available media selection options. AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual are currently supported.
  ///
  /// Pass AVMediaCharacteristicAudible to obtain the group of available options for audio media in various languages and for various purposes, such as descriptive audio.
  /// Pass AVMediaCharacteristicLegible to obtain the group of available options for subtitles in various languages and for various purposes.
  /// Pass AVMediaCharacteristicVisual to obtain the group of available options for video media.
  /// @result		An instance of AVMediaSelectionGroup. May be nil.
  /// @discussion
  /// Becomes callable without blocking when the key @"availableMediaCharacteristicsWithMediaSelectionOptions" has been loaded.
  ///
  /// If the asset has no AVMediaSelectionGroup containing options with the specified media characteristic, the return value will be nil.
  ///
  /// Filtering of the options in the returned AVMediaSelectionGroup according to playability, locale, and additional media characteristics can be accomplished using the category AVMediaSelectionOptionFiltering defined on AVMediaSelectionGroup.
  AVMediaSelectionGroup? mediaSelectionGroupForMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVAsset.mediaSelectionGroupForMediaCharacteristic:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_mediaSelectionGroupForMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return _ret.address == 0 ? null : AVMediaSelectionGroup.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		loadMediaSelectionGroupForMediaCharacteristic:completionHandler:
  /// @abstract		Loads an instance of AVMediaSelectionGroup that contains one or more options with the specified media characteristic.
  /// @param		mediaCharacteristic
  /// A media characteristic for which you wish to obtain the available media selection options. AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual are currently supported.
  ///
  /// Pass AVMediaCharacteristicAudible to obtain the group of available options for audio media in various languages and for various purposes, such as descriptive audio.
  /// Pass AVMediaCharacteristicLegible to obtain the group of available options for subtitles in various languages and for various purposes.
  /// Pass AVMediaCharacteristicVisual to obtain the group of available options for video media.
  /// @param		completionHandler
  /// A block that is invoked when loading is complete, vending an instance of AVMediaSelectionGroup (which may be nil) or an error.
  /// @discussion
  /// If the asset has no AVMediaSelectionGroup containing options with the specified media characteristic, the return value will be nil.
  ///
  /// Filtering of the options in the returned AVMediaSelectionGroup according to playability, locale, and additional media characteristics can be accomplished using the category AVMediaSelectionOptionFiltering defined on AVMediaSelectionGroup.
  void loadMediaSelectionGroupForMediaCharacteristic(
    objc.NSString mediaCharacteristic, {
    required objc.ObjCBlock<ffi.Void Function(AVMediaSelectionGroup, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAsset.loadMediaSelectionGroupForMediaCharacteristic:completionHandler:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadMediaSelectionGroupForMediaCharacteristic_completionHandler_,
      mediaCharacteristic.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @property		preferredMediaSelection
  /// @abstract		Provides an instance of AVMediaSelection with default selections for each of the receiver's media selection groups.
  AVMediaSelection get preferredMediaSelection {
    objc.checkOsVersionInternal(
      'AVAsset.preferredMediaSelection',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_preferredMediaSelection);
    return AVMediaSelection.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property		allMediaSelections
  /// @abstract		Provides an array of all permutations of AVMediaSelection for this asset.
  objc.NSArray get allMediaSelections {
    objc.checkOsVersionInternal('AVAsset.allMediaSelections', iOS: (false, (11, 0, 0)), macOS: (false, (10, 13, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_allMediaSelections);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_hasProtectedContent = objc.registerName("hasProtectedContent");

/// AVAssetProtectedContent
extension AVAssetProtectedContent on AVAsset {
  /// !
  /// @property		hasProtectedContent
  /// @abstract		Indicates whether or not the asset has protected content.
  /// @discussion	Assets containing protected content may not be playable without successful authorization, even if the value of the "playable" property is YES.  See the properties in the AVAssetUsability category for details on how such an asset may be used.  On macOS, clients can use the interfaces in AVPlayerItemProtectedContentAdditions.h to request authorization to play the asset.
  bool get hasProtectedContent {
    objc.checkOsVersionInternal('AVAsset.hasProtectedContent', iOS: (false, (4, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_hasProtectedContent);
  }
}

late final _sel_canContainFragments = objc.registerName("canContainFragments");
late final _sel_containsFragments = objc.registerName("containsFragments");
late final _sel_overallDurationHint = objc.registerName("overallDurationHint");
final _objc_msgSend_1f8hvjs = objc.msgSendPointer
    .cast<ffi.NativeFunction<CMTime Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<CMTime Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1f8hvjsStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<CMTime>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<void Function(ffi.Pointer<CMTime>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAssetFragments
extension AVAssetFragments on AVAsset {
  /// !
  /// @property		canContainFragments
  /// @abstract		Indicates whether the asset is capable of being extended by fragments.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of canContainFragments is YES if an 'mvex' box is present in the 'moov' box. For those types, the 'mvex' box signals the possible presence of later 'moof' boxes.
  bool get canContainFragments {
    objc.checkOsVersionInternal('AVAsset.canContainFragments', iOS: (false, (9, 0, 0)), macOS: (false, (10, 11, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canContainFragments);
  }

  /// !
  /// @property		containsFragments
  /// @abstract		Indicates whether the asset is extended by at least one fragment.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of this property is YES if canContainFragments is YES and at least one 'moof' box is present after the 'moov' box.
  bool get containsFragments {
    objc.checkOsVersionInternal('AVAsset.containsFragments', iOS: (false, (9, 0, 0)), macOS: (false, (10, 11, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_containsFragments);
  }

  /// !
  /// @property		overallDurationHint
  /// @abstract		Indicates the total duration of fragments that either exist now or may be appended in the future in order to extend the duration of the asset.
  /// @discussion	For QuickTime movie files and MPEG-4 files, the value of this property is obtained from the 'mehd' box of the 'mvex' box, if present. If no total fragment duration hint is available, the value of this property is kCMTimeInvalid.
  CMTime get overallDurationHint {
    objc.checkOsVersionInternal('AVAsset.overallDurationHint', iOS: (false, (10, 2, 0)), macOS: (false, (10, 12, 2)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_overallDurationHint)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_overallDurationHint);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }
}

late final _sel_isPlayable = objc.registerName("isPlayable");
late final _sel_isExportable = objc.registerName("isExportable");
late final _sel_isReadable = objc.registerName("isReadable");
late final _sel_isComposable = objc.registerName("isComposable");
late final _sel_isCompatibleWithSavedPhotosAlbum = objc.registerName("isCompatibleWithSavedPhotosAlbum");
late final _sel_isCompatibleWithAirPlayVideo = objc.registerName("isCompatibleWithAirPlayVideo");

/// AVAssetUsability
extension AVAssetUsability on AVAsset {
  /// !
  /// @property		playable
  /// @abstract		Indicates whether an AVPlayer can play the contents of the asset in a manner that meets user expectations.
  /// @discussion	A client can attempt playback when playable is NO, this however may lead to a substandard playback experience.
  bool get playable {
    objc.checkOsVersionInternal('AVAsset.isPlayable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlayable);
  }

  /// isExportable
  bool get exportable {
    objc.checkOsVersionInternal('AVAsset.isExportable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isExportable);
  }

  /// isReadable
  bool get readable {
    objc.checkOsVersionInternal('AVAsset.isReadable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isReadable);
  }

  /// isComposable
  bool get composable {
    objc.checkOsVersionInternal('AVAsset.isComposable', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isComposable);
  }

  /// isCompatibleWithSavedPhotosAlbum
  bool get compatibleWithSavedPhotosAlbum {
    objc.checkOsVersionInternal(
      'AVAsset.isCompatibleWithSavedPhotosAlbum',
      iOS: (false, (5, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isCompatibleWithSavedPhotosAlbum);
  }

  /// !
  /// @property		compatibleWithAirPlayVideo
  /// @abstract		Indicates whether the asset is compatible with AirPlay Video.
  /// @discussion	YES if an AVPlayerItem initialized with the receiver can be played by an external device via AirPlay Video.
  bool get compatibleWithAirPlayVideo {
    objc.checkOsVersionInternal(
      'AVAsset.isCompatibleWithAirPlayVideo',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isCompatibleWithAirPlayVideo);
  }
}

typedef instancetype = ffi.Pointer<objc.ObjCObject>;
typedef Dartinstancetype = objc.ObjCObjectBase;
late final _sel_assetWithURL_ = objc.registerName("assetWithURL:");
late final _sel_duration = objc.registerName("duration");
late final _sel_preferredRate = objc.registerName("preferredRate");
final _objc_msgSend_2cgrxl = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_2cgrxlFpret = objc.msgSendFpretPointer
    .cast<ffi.NativeFunction<ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_preferredVolume = objc.registerName("preferredVolume");
late final _sel_preferredTransform = objc.registerName("preferredTransform");
final _objc_msgSend_5qswvj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<CGAffineTransform Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>
    >()
    .asFunction<CGAffineTransform Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_5qswvjStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<CGAffineTransform>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<CGAffineTransform>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();
late final _sel_naturalSize = objc.registerName("naturalSize");
final _objc_msgSend_1vdfken = objc.msgSendPointer
    .cast<ffi.NativeFunction<objc.CGSize Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<objc.CGSize Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1vdfkenStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.CGSize>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.CGSize>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();

/// WARNING: AVDisplayCriteria is a stub. To generate bindings for this class, include
/// AVDisplayCriteria in your config's objc-interfaces list.
///
/// AVDisplayCriteria
class AVDisplayCriteria extends objc.ObjCObjectBase {
  AVDisplayCriteria._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVDisplayCriteria] that points to the same underlying object as [other].
  AVDisplayCriteria.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVDisplayCriteria] that wraps the given raw object pointer.
  AVDisplayCriteria.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_preferredDisplayCriteria = objc.registerName("preferredDisplayCriteria");
late final _sel_minimumTimeOffsetFromLive = objc.registerName("minimumTimeOffsetFromLive");
late final _sel_init = objc.registerName("init");
late final _sel_new = objc.registerName("new");
late final _sel_allocWithZone_ = objc.registerName("allocWithZone:");
final _objc_msgSend_1cwp428 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.NSZone>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.NSZone>,
      )
    >();
late final _sel_alloc = objc.registerName("alloc");
late final _sel_self = objc.registerName("self");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>>()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_objcObjCObject_ffiVoid_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => (objc.getBlockClosure(block) as ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_objcObjCObject_ffiVoid_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>`.
abstract final class ObjCBlock_objcObjCObject_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    objc.newPointerBlock(_ObjCBlock_objcObjCObject_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> fromFunction(
    objc.ObjCObjectBase Function(ffi.Pointer<ffi.Void>) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>(
    objc.newClosureBlock(
      _ObjCBlock_objcObjCObject_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0) => fn(arg0).ref.retainAndAutorelease(),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>`.
extension ObjCBlock_objcObjCObject_ffiVoid_CallExtension
    on objc.ObjCBlock<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)> {
  objc.ObjCObjectBase call(ffi.Pointer<ffi.Void> arg0) => objc.ObjCObjectBase(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>()(
      ref.pointer,
      arg0,
    ),
    retain: true,
    release: true,
  );
}

late final _sel_retain = objc.registerName("retain");
late final _sel_autorelease = objc.registerName("autorelease");
late final _sel_statusOfValueForKey_error_ = objc.registerName("statusOfValueForKey:error:");
final _objc_msgSend_n4q2pj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      int Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
int _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
        )
      >
    >()
    .asFunction<
      int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrTrampoline, 0)
        .cast();
int _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
) =>
    (objc.getBlockClosure(block)
        as int Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        ))(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureTrampoline, 0)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
abstract final class ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Long Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
        )
      >
    >
    ptr,
  ) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(
        objc.newPointerBlock(_ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_fnPtrCallable, ptr.cast()),
        retain: false,
        release: true,
      );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<
    ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
  >
  fromFunction(
    AVKeyValueStatus Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>) fn, {
    bool keepIsolateAlive = true,
  }) =>
      objc.ObjCBlock<
        ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
      >(
        objc.newClosureBlock(
          _ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_closureCallable,
          (
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
          ) => fn(arg0, objc.NSString.castFromPointer(arg1, retain: true, release: true), arg2).value,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
extension ObjCBlock_AVKeyValueStatus_ffiVoid_NSString_NSError_CallExtension
    on
        objc.ObjCBlock<
          ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)
        > {
  AVKeyValueStatus call(
    ffi.Pointer<ffi.Void> arg0,
    objc.NSString arg1,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
  ) => AVKeyValueStatus.fromValue(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Long Function(
              ffi.Pointer<objc.ObjCBlockImpl> block,
              ffi.Pointer<ffi.Void> arg0,
              ffi.Pointer<objc.ObjCObject> arg1,
              ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg2,
            )
          >
        >()
        .asFunction<
          int Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >()(ref.pointer, arg0, arg1.ref.pointer, arg2),
  );
}

void _ObjCBlock_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) => block.ref.target.cast<ffi.NativeFunction<ffi.Void Function()>>().asFunction<void Function()>()();
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>(
      _ObjCBlock_ffiVoid_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) => (objc.getBlockClosure(block) as void Function())();
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>(
      _ObjCBlock_ffiVoid_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
) {
  (objc.getBlockClosure(block) as void Function())();
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)> _ObjCBlock_ffiVoid_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>)>.listener(
      _ObjCBlock_ffiVoid_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_blockingTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> waiter) {
  try {
    (objc.getBlockClosure(block) as void Function())();
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>
_ObjCBlock_ffiVoid_blockingCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>.isolateLocal(
      _ObjCBlock_ffiVoid_blockingTrampoline,
    )..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>
_ObjCBlock_ffiVoid_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>.listener(
      _ObjCBlock_ffiVoid_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function()>`.
abstract final class ObjCBlock_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function()> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function()>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function()> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function()>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function()>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function()> fromFunction(void Function() fn, {bool keepIsolateAlive = true}) =>
      objc.ObjCBlock<ffi.Void Function()>(
        objc.newClosureBlock(_ObjCBlock_ffiVoid_closureCallable, () => fn(), keepIsolateAlive),
        retain: false,
        release: true,
      );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function()> listener(void Function() fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_listenerCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_1pl9qdv(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function()>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function()> blocking(void Function() fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_blockingCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_blockingListenerCallable.nativeFunction.cast(),
      () => fn(),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_1pl9qdv(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function()>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function()>`.
extension ObjCBlock_ffiVoid_CallExtension on objc.ObjCBlock<ffi.Void Function()> {
  void call() =>
      ref.pointer.ref.invoke
          .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block)>>()
          .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>)>()(
        ref.pointer,
      );
}

late final _sel_loadValuesAsynchronouslyForKeys_completionHandler_ = objc.registerName(
  "loadValuesAsynchronouslyForKeys:completionHandler:",
);
void _ObjCBlock_ffiVoid_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSError_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSError_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_ffiVoid_NSError_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_NSError_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>.listener(
      _ObjCBlock_ffiVoid_NSError_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.isolateLocal(_ObjCBlock_ffiVoid_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> fromFunction(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> listener(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_xtuoz7(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSError?)> blocking(
    void Function(objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(arg0.address == 0 ? null : objc.NSError.castFromPointer(arg0, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_xtuoz7(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSError?)>`.
extension ObjCBlock_ffiVoid_NSError_CallExtension on objc.ObjCBlock<ffi.Void Function(objc.NSError?)> {
  void call(objc.NSError? arg0) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<objc.ObjCObject> arg0)>
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0?.ref.pointer ?? ffi.nullptr);
}

void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>)
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) =>
    (objc.getBlockClosure(block)
        as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) {
  (objc.getBlockClosure(block)
      as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
    arg0,
    arg1,
    arg2,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) {
  try {
    (objc.getBlockClosure(block)
        as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCBlockImpl>))(
      arg0,
      arg1,
      arg2,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCBlockImpl>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>`.
abstract final class ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
        pointer,
        retain: retain,
        release: release,
      );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  fromFunction(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: true, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  listener(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_jk1ljc(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>
  blocking(
    void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) => fn(
        arg0,
        objc.NSArray.castFromPointer(arg1, retain: false, release: true),
        arg2.address == 0 ? null : ObjCBlock_ffiVoid.castFromPointer(arg2, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_jk1ljc(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>(
      wrapper,
      retain: false,
      release: true,
    );
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)>`.
extension ObjCBlock_ffiVoid_ffiVoid_NSArray_ffiVoid_CallExtension
    on objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSArray, objc.ObjCBlock<ffi.Void Function()>?)> {
  void call(ffi.Pointer<ffi.Void> arg0, objc.NSArray arg1, objc.ObjCBlock<ffi.Void Function()>? arg2) => ref
      .pointer
      .ref
      .invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
            ffi.Pointer<objc.ObjCBlockImpl> arg2,
          )
        >
      >()
      .asFunction<
        void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >()(ref.pointer, arg0, arg1.ref.pointer, arg2?.ref.pointer ?? ffi.nullptr);
}

/// AVAsset
class AVAsset extends objc.NSObject implements objc.NSCopying, AVAsynchronousKeyValueLoading {
  AVAsset._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAsset', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVAsset] that points to the same underlying object as [other].
  AVAsset.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAsset] that wraps the given raw object pointer.
  AVAsset.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVAsset].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVAsset);
  }

  /// !
  /// @method		assetWithURL:
  /// @abstract		Returns an instance of AVAsset for inspection of a media resource.
  /// @param		URL
  /// An instance of NSURL that references a media resource.
  /// @result		An instance of AVAsset.
  /// @discussion	Returns a newly allocated instance of a subclass of AVAsset initialized with the specified URL.
  static AVAsset assetWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVAsset.assetWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVAsset, _sel_assetWithURL_, URL.ref.pointer);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// duration
  CMTime get duration {
    objc.checkOsVersionInternal('AVAsset.duration', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_duration)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_duration);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// preferredRate
  double get preferredRate {
    objc.checkOsVersionInternal('AVAsset.preferredRate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_preferredRate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_preferredRate);
  }

  /// preferredVolume
  double get preferredVolume {
    objc.checkOsVersionInternal('AVAsset.preferredVolume', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_preferredVolume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_preferredVolume);
  }

  /// preferredTransform
  CGAffineTransform get preferredTransform {
    objc.checkOsVersionInternal('AVAsset.preferredTransform', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CGAffineTransform>();
    objc.useMsgSendVariants
        ? _objc_msgSend_5qswvjStret(_ptr, this.ref.pointer, _sel_preferredTransform)
        : _ptr.ref = _objc_msgSend_5qswvj(this.ref.pointer, _sel_preferredTransform);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<CGAffineTransform>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<CGAffineTransform>(_finalizable);
  }

  /// naturalSize
  objc.CGSize get naturalSize {
    objc.checkOsVersionInternal('AVAsset.naturalSize', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_naturalSize)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_naturalSize);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property	preferredDisplayCriteria
  /// @abstract	Guides to a display mode that is optimal for playing this particular asset.
  AVDisplayCriteria get preferredDisplayCriteria {
    objc.checkOsVersionInternal('AVAsset.preferredDisplayCriteria', iOS: (true, null), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_preferredDisplayCriteria);
    return AVDisplayCriteria.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property		minimumTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback can be sustained.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get minimumTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVAsset.minimumTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_minimumTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_minimumTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// init
  AVAsset init() {
    objc.checkOsVersionInternal('AVAsset.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVAsset new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVAsset, _sel_new);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVAsset allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVAsset, _sel_allocWithZone_, zone);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVAsset alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVAsset, _sel_alloc);
    return AVAsset.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVAsset self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVAsset retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVAsset autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// statusOfValueForKey:error:
  AVKeyValueStatus statusOfValueForKey(objc.NSString key, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    final _ret = _objc_msgSend_n4q2pj(this.ref.pointer, _sel_statusOfValueForKey_error_, key.ref.pointer, error);
    return AVKeyValueStatus.fromValue(_ret);
  }

  /// loadValuesAsynchronouslyForKeys:completionHandler:
  void loadValuesAsynchronouslyForKeys(objc.NSArray keys, {objc.ObjCBlock<ffi.Void Function()>? completionHandler}) {
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_loadValuesAsynchronouslyForKeys_completionHandler_,
      keys.ref.pointer,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// Returns a new instance of AVAsset constructed with the default `new` method.
  factory AVAsset() => new$();
}

final class OpaqueCMClock extends ffi.Opaque {}

final class OpaqueCMTimebase extends ffi.Opaque {}

/// !
/// @enum AVPlayerStatus
/// @abstract
/// These constants are returned by the AVPlayer status property to indicate whether it can successfully play items.
///
/// @constant	 AVPlayerStatusUnknown
/// Indicates that the status of the player is not yet known because it has not tried to load new media resources for
/// playback.
/// @constant	 AVPlayerStatusReadyToPlay
/// Indicates that the player is ready to play AVPlayerItem instances.
/// @constant	 AVPlayerStatusFailed
/// Indicates that the player can no longer play AVPlayerItem instances because of an error. The error is described by
/// the value of the player's error property.
enum AVPlayerStatus {
  AVPlayerStatusUnknown(0),
  AVPlayerStatusReadyToPlay(1),
  AVPlayerStatusFailed(2);

  final int value;
  const AVPlayerStatus(this.value);

  static AVPlayerStatus fromValue(int value) => switch (value) {
    0 => AVPlayerStatusUnknown,
    1 => AVPlayerStatusReadyToPlay,
    2 => AVPlayerStatusFailed,
    _ => throw ArgumentError('Unknown value for AVPlayerStatus: $value'),
  };
}

late final _class_AVPlayer = objc.getClass("AVPlayer");
late final _sel_rate = objc.registerName("rate");
late final _sel_setRate_ = objc.registerName("setRate:");
final _objc_msgSend_v5hmet = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Float)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();
late final _sel_defaultRate = objc.registerName("defaultRate");
late final _sel_setDefaultRate_ = objc.registerName("setDefaultRate:");
late final _sel_play = objc.registerName("play");
late final _sel_pause = objc.registerName("pause");

/// !
/// @enum AVPlayerTimeControlStatus
/// @abstract
/// These constants are the allowable values of AVPlayer's timeControlStatus property. This discussion pertains when automaticallyWaitsToMinimizeStalling is YES, the default setting, and exceptions are discussed in connection with automaticallyWaitsToMinimizeStalling.
///
/// @constant	 AVPlayerTimeControlStatusPaused
/// This state is entered upon receipt of a -pause message, an invocation of -setRate: with a value of 0.0, when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession.
/// In this state, playback is paused indefinitely and will not resume until 1) a subsequent -play message is received or 2) a -setRate: or -playImmediatelyAtRate: message with a non-zero value for rate is received and sufficient media data has been buffered for playback to proceed.
/// @constant	 AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate
/// This state is entered when 1) the playback buffer becomes empty and playback stalls in AVPlayerTimeControlStatusPlaying, 2) when rate is set from zero to non-zero in AVPlayerTimeControlStatusPaused and insufficient media data has been buffered for playback to occur, or 3) when the player has no item to play, i.e. when the receiver's currentItem is nil.
/// In this state, the value of the rate property is not currently effective but instead indicates the rate at which playback will start or resume. Refer to the value of reasonForWaitingToPlay for details about why the receiver is waiting and the conditions that allow waitStatus to change to AVPlayerWaitStatusPlaying.
/// While waiting for buffering, you can attempt to start playback of any available media data via -playImmediatelyAtRate:.
/// @constant	 AVPlayerTimeControlStatusPlaying
/// In this state, playback is currently progressing and rate changes will take effect immediately. Should playback stall because of insufficient media data, timeControlStatus will change to AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate.
enum AVPlayerTimeControlStatus {
  AVPlayerTimeControlStatusPaused(0),
  AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate(1),
  AVPlayerTimeControlStatusPlaying(2);

  final int value;
  const AVPlayerTimeControlStatus(this.value);

  static AVPlayerTimeControlStatus fromValue(int value) => switch (value) {
    0 => AVPlayerTimeControlStatusPaused,
    1 => AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate,
    2 => AVPlayerTimeControlStatusPlaying,
    _ => throw ArgumentError('Unknown value for AVPlayerTimeControlStatus: $value'),
  };
}

late final _sel_timeControlStatus = objc.registerName("timeControlStatus");
final _objc_msgSend_hoknzl = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_reasonForWaitingToPlay = objc.registerName("reasonForWaitingToPlay");
late final _sel_playImmediatelyAtRate_ = objc.registerName("playImmediatelyAtRate:");

/// AVPlayerPlaybackControl
extension AVPlayerPlaybackControl on AVPlayer {
  /// !
  /// @property		rate
  /// @abstract		Indicates the desired rate of playback; 0.0 means "paused", 1.0 indicates a desire to play at the natural rate of the current item.
  /// @discussion
  /// Setting the value of rate to 0.0 pauses playback, causing the value of timeControlStatus to change to AVPlayerTimeControlStatusPaused.
  /// Setting the rate to a non-zero value causes the value of timeControlStatus to become either AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate or AVPlayerTimeControlStatusPlaying, depending on whether sufficient media data has been buffered for playback to occur and whether the player's default behavior of waiting in order to minimize stalling is permitted. See discussion of AVPlayerTimeControlStatus for more details.
  ///
  /// AVPlayer can reset the desired rate to 0.0 when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession, or when the playback buffer becomes empty and playback stalls while automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// The effective rate of playback may differ from the desired rate even while timeControlStatus is AVPlayerTimeControlStatusPlaying, if the processing algorithm in use for managing audio pitch requires quantization of playback rate. For information about quantization of rates for audio processing, see AVAudioProcessingSettings.h. You can always obtain the effective rate of playback from the currentItem's timebase; see the timebase property of AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  double get rate {
    objc.checkOsVersionInternal('AVPlayer.rate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_rate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_rate);
  }

  /// !
  /// @property		rate
  /// @abstract		Indicates the desired rate of playback; 0.0 means "paused", 1.0 indicates a desire to play at the natural rate of the current item.
  /// @discussion
  /// Setting the value of rate to 0.0 pauses playback, causing the value of timeControlStatus to change to AVPlayerTimeControlStatusPaused.
  /// Setting the rate to a non-zero value causes the value of timeControlStatus to become either AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate or AVPlayerTimeControlStatusPlaying, depending on whether sufficient media data has been buffered for playback to occur and whether the player's default behavior of waiting in order to minimize stalling is permitted. See discussion of AVPlayerTimeControlStatus for more details.
  ///
  /// AVPlayer can reset the desired rate to 0.0 when a change in overall state requires playback to be halted, such as when an interruption occurs on iOS, as announced by AVAudioSession, or when the playback buffer becomes empty and playback stalls while automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// The effective rate of playback may differ from the desired rate even while timeControlStatus is AVPlayerTimeControlStatusPlaying, if the processing algorithm in use for managing audio pitch requires quantization of playback rate. For information about quantization of rates for audio processing, see AVAudioProcessingSettings.h. You can always obtain the effective rate of playback from the currentItem's timebase; see the timebase property of AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set rate(double value) {
    objc.checkOsVersionInternal('AVPlayer.setRate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setRate_, value);
  }

  /// !
  /// @property      defaultRate
  /// @abstract      Indicates the rate at which to start playback when play is called; defaults to 1.0.
  /// @discussion
  /// Setting this property does not imply playback starts automatically at this rate. Clients still have to kick off playback using `play`. Note that using setRate to start playback will skip using the value in this property nor would it update this property. Therefore, `setRate:1.0` is no longer recommended as a means to start playback. Use `play` instead. Use `setRate` for operations like scanning where the rate is to be updated instantaneously. Invoking `play` again would restore playback at the rate set in this property.
  ///
  /// The effective rate of playback may still differ from the default rate subject to restrictions imposed by the system. See documentation for the rate property for a discussion on when the desired rate does not translate to effective rate.
  double get defaultRate {
    objc.checkOsVersionInternal('AVPlayer.defaultRate', iOS: (false, (16, 0, 0)), macOS: (false, (13, 0, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_defaultRate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_defaultRate);
  }

  /// !
  /// @property      defaultRate
  /// @abstract      Indicates the rate at which to start playback when play is called; defaults to 1.0.
  /// @discussion
  /// Setting this property does not imply playback starts automatically at this rate. Clients still have to kick off playback using `play`. Note that using setRate to start playback will skip using the value in this property nor would it update this property. Therefore, `setRate:1.0` is no longer recommended as a means to start playback. Use `play` instead. Use `setRate` for operations like scanning where the rate is to be updated instantaneously. Invoking `play` again would restore playback at the rate set in this property.
  ///
  /// The effective rate of playback may still differ from the default rate subject to restrictions imposed by the system. See documentation for the rate property for a discussion on when the desired rate does not translate to effective rate.
  set defaultRate(double value) {
    objc.checkOsVersionInternal('AVPlayer.setDefaultRate:', iOS: (false, (16, 0, 0)), macOS: (false, (13, 0, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setDefaultRate_, value);
  }

  /// !
  /// @method        play
  /// @abstract      Signals the desire to begin playback at the rate set in the defaultRate.
  /// @discussion    For releases up to iOS version 16.0, macOS versions 13.0, tvOS 16.0 and watchOS 9.0, this is equivalent to setting the value of rate to `1.0`. Starting from iOS version 16.0, macOS versions 13.0, tvOS 16.0 and watchOS 9.0, this will attempt to use the rate set in the `defaultRate` property. The effective rate of playback may differ from the `defaultRate` due to the reasons mentioned in the documentation of the `rate` property. Clients interested in knowing the effective rate can listen for `AVPlayerRateDidChangeNotification` notification.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void play() {
    objc.checkOsVersionInternal('AVPlayer.play', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_play);
  }

  /// !
  /// @method		pause
  /// @abstract		Pauses playback.
  /// @discussion	Equivalent to setting the value of rate to 0.0.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void pause() {
    objc.checkOsVersionInternal('AVPlayer.pause', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_pause);
  }

  /// !
  /// @property		timeControlStatus
  /// @abstract		Indicates whether playback is currently paused indefinitely, suspended while waiting for appropriate conditions, or in progress.
  /// @discussion    For possible values and discussion, see AVPlayerTimeControlStatus.
  ///
  /// When automaticallyWaitsToMinimizeStalling is YES, absent intervention in the form of invocations of -setRate: or -pause or, on iOS, an interruption that requires user intervention before playback can resume, the value of the property timeControlStatus automatically changes between AVPlayerTimeControlStatusPlaying and AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate depending on whether sufficient media data is available to continue playback. This property is key value observable.
  AVPlayerTimeControlStatus get timeControlStatus {
    objc.checkOsVersionInternal('AVPlayer.timeControlStatus', iOS: (false, (10, 0, 0)), macOS: (false, (10, 12, 0)));
    final _ret = _objc_msgSend_hoknzl(this.ref.pointer, _sel_timeControlStatus);
    return AVPlayerTimeControlStatus.fromValue(_ret);
  }

  /// !
  /// @property		reasonForWaitingToPlay
  /// @abstract		Indicates the reason for waiting when the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate
  /// @discussion
  /// When the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate, this property describes why the player is currently waiting. It is nil otherwise.
  /// You can use the value of reasonForWaitingToPlay to show UI indicating the player's waiting state conditionally.
  /// This property is key value observable.
  /// Possible values are AVPlayerWaitingWithNoItemToPlayReason, AVPlayerWaitingWhileEvaluatingBufferingRateReason, and AVPlayerWaitingToMinimizeStallsReason.
  objc.NSString? get reasonForWaitingToPlay {
    objc.checkOsVersionInternal(
      'AVPlayer.reasonForWaitingToPlay',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_reasonForWaitingToPlay);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playImmediatelyAtRate:
  /// @abstract		Immediately plays the available media data at the specified rate.
  /// @discussion
  /// When the player's currentItem has a value of NO for playbackBufferEmpty, this method causes the value of rate to change to the specified rate, the value of timeControlStatus to change to AVPlayerTimeControlStatusPlaying, and the receiver to play the available media immediately, whether or not prior buffering of media data is sufficient to ensure smooth playback.
  /// If insufficient media data is buffered for playback to start (e.g. if the current item has a value of YES for playbackBufferEmpty), the receiver will act as if the buffer became empty during playback, except that no AVPlayerItemPlaybackStalledNotification will be posted.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void playImmediatelyAtRate(double rate$1) {
    objc.checkOsVersionInternal(
      'AVPlayer.playImmediatelyAtRate:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_playImmediatelyAtRate_, rate$1);
  }
}

late final _class_AVPlayerItem = objc.getClass("AVPlayerItem");
late final _sel_asset = objc.registerName("asset");
late final _sel_presentationSize = objc.registerName("presentationSize");
late final _sel_timedMetadata = objc.registerName("timedMetadata");
late final _sel_automaticallyLoadedAssetKeys = objc.registerName("automaticallyLoadedAssetKeys");

/// AVPlayerItemInspection
extension AVPlayerItemInspection on AVPlayerItem {
  /// !
  /// @property asset
  /// @abstract Accessor for underlying AVAsset.
  AVAsset get asset {
    objc.checkOsVersionInternal('AVPlayerItem.asset', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_asset);
    return AVAsset.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property tracks
  /// @abstract Provides array of AVPlayerItem tracks. Observable (can change dynamically during playback).
  ///
  /// @discussion
  /// The value of this property will accord with the properties of the underlying media resource when the receiver becomes ready to play.
  /// Before the underlying media resource has been sufficiently loaded, its value is an empty NSArray. Use key-value observation to obtain
  /// a valid array of tracks as soon as it becomes available.
  objc.NSArray get tracks {
    objc.checkOsVersionInternal('AVPlayerItem.tracks', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_tracks);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property duration
  /// @abstract Indicates the duration of the item, not considering either its forwardPlaybackEndTime or reversePlaybackEndTime.
  ///
  /// @discussion
  /// This property is observable. The duration of an item can change dynamically during playback.
  ///
  /// Unless you omit @"duration" from the array of asset keys you pass to +playerItemWithAsset:automaticallyLoadedAssetKeys: or
  /// -initWithAsset:automaticallyLoadedAssetKeys:, the value of this property will accord with the properties of the underlying
  /// AVAsset and the current state of playback once the receiver becomes ready to play.
  ///
  /// Before the underlying duration has been loaded, the value of this property is kCMTimeIndefinite. Use key-value observation to
  /// obtain a valid duration as soon as it becomes available. (Note that the value of duration may remain kCMTimeIndefinite,
  /// e.g. for live streams.)
  CMTime get duration {
    objc.checkOsVersionInternal('AVPlayerItem.duration', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_duration)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_duration);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property presentationSize
  /// @abstract The size of the receiver as presented by the player.
  ///
  /// @discussion
  /// Indicates the size at which the visual portion of the item is presented by the player; can be scaled from this
  /// size to fit within the bounds of an AVPlayerLayer via its videoGravity property. Can be scaled arbitrarily for presentation
  /// via the frame property of an AVPlayerLayer.
  ///
  /// The value of this property will accord with the properties of the underlying media resource when the receiver becomes ready to play.
  /// Before the underlying media resource is sufficiently loaded, its value is CGSizeZero. Use key-value observation to obtain a valid
  /// presentationSize as soon as it becomes available. (Note that the value of presentationSize may remain CGSizeZero, e.g. for audio-only items.)
  objc.CGSize get presentationSize {
    objc.checkOsVersionInternal('AVPlayerItem.presentationSize', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_presentationSize)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_presentationSize);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property timedMetadata
  /// @abstract Provides an NSArray of AVMetadataItems representing the timed metadata encountered most recently within the media as it plays. May be nil.
  /// @discussion
  /// Notifications of changes are available via key-value observation.
  /// As an optimization for playback, AVPlayerItem may omit the processing of timed metadata when no observer of this property is registered. Therefore, when no such observer is registered, the value of the timedMetadata property may remain nil regardless of the contents of the underlying media.
  ///
  /// This property must be accessed on the main thread/queue.
  objc.NSArray? get timedMetadata {
    objc.checkOsVersionInternal('AVPlayerItem.timedMetadata', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_timedMetadata);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property automaticallyLoadedAssetKeys
  /// @abstract An array of property keys defined on AVAsset. The value of each key in the array is automatically loaded while the receiver is being made ready to play.
  /// @discussion
  /// The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be AVKeyValueStatusLoaded. If loading of any of the values fails, the status of the AVPlayerItem will change instead to AVPlayerItemStatusFailed..
  objc.NSArray get automaticallyLoadedAssetKeys {
    objc.checkOsVersionInternal(
      'AVPlayerItem.automaticallyLoadedAssetKeys',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_automaticallyLoadedAssetKeys);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_canPlayFastForward = objc.registerName("canPlayFastForward");
late final _sel_canPlaySlowForward = objc.registerName("canPlaySlowForward");
late final _sel_canPlayReverse = objc.registerName("canPlayReverse");
late final _sel_canPlaySlowReverse = objc.registerName("canPlaySlowReverse");
late final _sel_canPlayFastReverse = objc.registerName("canPlayFastReverse");
late final _sel_canStepForward = objc.registerName("canStepForward");
late final _sel_canStepBackward = objc.registerName("canStepBackward");
late final _sel_configuredTimeOffsetFromLive = objc.registerName("configuredTimeOffsetFromLive");
late final _sel_setConfiguredTimeOffsetFromLive_ = objc.registerName("setConfiguredTimeOffsetFromLive:");
final _objc_msgSend_1hznzoi = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime)>();
late final _sel_recommendedTimeOffsetFromLive = objc.registerName("recommendedTimeOffsetFromLive");
late final _sel_automaticallyPreservesTimeOffsetFromLive = objc.registerName(
  "automaticallyPreservesTimeOffsetFromLive",
);
late final _sel_setAutomaticallyPreservesTimeOffsetFromLive_ = objc.registerName(
  "setAutomaticallyPreservesTimeOffsetFromLive:",
);
final _objc_msgSend_1s56lr9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Bool)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, bool)>();

/// AVPlayerItemRateAndSteppingSupport
extension AVPlayerItemRateAndSteppingSupport on AVPlayerItem {
  /// canPlayFastForward
  bool get canPlayFastForward {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayFastForward', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayFastForward);
  }

  /// canPlaySlowForward
  bool get canPlaySlowForward {
    objc.checkOsVersionInternal('AVPlayerItem.canPlaySlowForward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlaySlowForward);
  }

  /// canPlayReverse
  bool get canPlayReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayReverse', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayReverse);
  }

  /// canPlaySlowReverse
  bool get canPlaySlowReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlaySlowReverse', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlaySlowReverse);
  }

  /// canPlayFastReverse
  bool get canPlayFastReverse {
    objc.checkOsVersionInternal('AVPlayerItem.canPlayFastReverse', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canPlayFastReverse);
  }

  /// canStepForward
  bool get canStepForward {
    objc.checkOsVersionInternal('AVPlayerItem.canStepForward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canStepForward);
  }

  /// canStepBackward
  bool get canStepBackward {
    objc.checkOsVersionInternal('AVPlayerItem.canStepBackward', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canStepBackward);
  }

  /// !
  /// @property		configuredTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback will begin after a live start or a seek to kCMTimePositiveInfinity.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get configuredTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.configuredTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_configuredTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_configuredTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property		configuredTimeOffsetFromLive
  /// @abstract		Indicates how close to the latest content in a live stream playback will begin after a live start or a seek to kCMTimePositiveInfinity.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  set configuredTimeOffsetFromLive(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setConfiguredTimeOffsetFromLive:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setConfiguredTimeOffsetFromLive_, value);
  }

  /// !
  /// @property		recommendedTimeOffsetFromLive
  /// @abstract		A recommended value for configuredTimeOffsetFromLive, based on observed network conditions.
  /// @discussion	For non-live assets this value is kCMTimeInvalid.
  CMTime get recommendedTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.recommendedTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_recommendedTimeOffsetFromLive)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_recommendedTimeOffsetFromLive);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property		automaticallyPreservesTimeOffsetFromLive
  /// @abstract		Indicates that after the player spends a period of time buffering media, it will skip forward if necessary to restore the playhead's distance from the live edge of the presentation to what it was when buffering began.
  /// @discussion
  /// If the value of this property is YES and the player must buffer media from the network in order to resume playback, the player will seek forward if necessary before resuming playback to restore the position that the playhead had when rebuffering began, relative to the end of the current AVPlayerItem's seekableTimeRange.
  ///
  /// This behavior applies to media buffering that occurs as a consequence of starting playback, seeking, and recovering from a playback stall.
  ///
  /// Note that if the network cannot deliver media quickly enough to maintain the playback rate, playback may stall interminably.
  ///
  /// This property value has no effect if the asset is not a live stream. The default value of this property is NO.
  bool get automaticallyPreservesTimeOffsetFromLive {
    objc.checkOsVersionInternal(
      'AVPlayerItem.automaticallyPreservesTimeOffsetFromLive',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_automaticallyPreservesTimeOffsetFromLive);
  }

  /// !
  /// @property		automaticallyPreservesTimeOffsetFromLive
  /// @abstract		Indicates that after the player spends a period of time buffering media, it will skip forward if necessary to restore the playhead's distance from the live edge of the presentation to what it was when buffering began.
  /// @discussion
  /// If the value of this property is YES and the player must buffer media from the network in order to resume playback, the player will seek forward if necessary before resuming playback to restore the position that the playhead had when rebuffering began, relative to the end of the current AVPlayerItem's seekableTimeRange.
  ///
  /// This behavior applies to media buffering that occurs as a consequence of starting playback, seeking, and recovering from a playback stall.
  ///
  /// Note that if the network cannot deliver media quickly enough to maintain the playback rate, playback may stall interminably.
  ///
  /// This property value has no effect if the asset is not a live stream. The default value of this property is NO.
  set automaticallyPreservesTimeOffsetFromLive(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAutomaticallyPreservesTimeOffsetFromLive:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAutomaticallyPreservesTimeOffsetFromLive_, value);
  }
}

late final _sel_currentTime = objc.registerName("currentTime");
late final _sel_forwardPlaybackEndTime = objc.registerName("forwardPlaybackEndTime");
late final _sel_setForwardPlaybackEndTime_ = objc.registerName("setForwardPlaybackEndTime:");
late final _sel_reversePlaybackEndTime = objc.registerName("reversePlaybackEndTime");
late final _sel_setReversePlaybackEndTime_ = objc.registerName("setReversePlaybackEndTime:");
late final _sel_seekableTimeRanges = objc.registerName("seekableTimeRanges");
void _ObjCBlock_ffiVoid_bool_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0)>>()
    .asFunction<void Function(bool)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>(
      _ObjCBlock_ffiVoid_bool_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_bool_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) =>
    (objc.getBlockClosure(block) as void Function(bool))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>(
      _ObjCBlock_ffiVoid_bool_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_bool_listenerTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, bool arg0) {
  (objc.getBlockClosure(block) as void Function(bool))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool)>.listener(
      _ObjCBlock_ffiVoid_bool_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_bool_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  bool arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(bool))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)
      >.isolateLocal(_ObjCBlock_ffiVoid_bool_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>
_ObjCBlock_ffiVoid_bool_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool)>.listener(
      _ObjCBlock_ffiVoid_bool_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Bool)>`.
abstract final class ObjCBlock_ffiVoid_bool {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_bool_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> fromFunction(
    void Function(bool) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(
    objc.newClosureBlock(_ObjCBlock_ffiVoid_bool_closureCallable, (bool arg0) => fn(arg0), keepIsolateAlive),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> listener(void Function(bool) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_listenerCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_1s56lr9(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool)> blocking(void Function(bool) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_blockingCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_blockingListenerCallable.nativeFunction.cast(),
      (bool arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_1s56lr9(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Bool)>`.
extension ObjCBlock_ffiVoid_bool_CallExtension on objc.ObjCBlock<ffi.Void Function(ffi.Bool)> {
  void call(bool arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Bool arg0)>>()
      .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, bool)>()(ref.pointer, arg0);
}

late final _sel_seekToTime_completionHandler_ = objc.registerName("seekToTime:completionHandler:");
final _objc_msgSend_1pt0wih = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_ = objc.registerName(
  "seekToTime:toleranceBefore:toleranceAfter:completionHandler:",
);
final _objc_msgSend_4xu1ph = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          CMTime,
          CMTime,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        CMTime,
        CMTime,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_cancelPendingSeeks = objc.registerName("cancelPendingSeeks");
late final _sel_currentDate = objc.registerName("currentDate");
late final _sel_seekToDate_completionHandler_ = objc.registerName("seekToDate:completionHandler:");
final _objc_msgSend_1wskeji = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_stepByCount_ = objc.registerName("stepByCount:");
final _objc_msgSend_4sp4xj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
late final _sel_timebase = objc.registerName("timebase");
final _objc_msgSend_93ekp9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<OpaqueCMTimebase> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<OpaqueCMTimebase> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVPlayerItemTimeControl
extension AVPlayerItemTimeControl on AVPlayerItem {
  /// !
  /// @method			currentTime
  /// @abstract			Returns the current time of the item.
  /// @result			A CMTime
  /// @discussion		Returns the current time of the item. Not key-value observable; use -[AVPlayer addPeriodicTimeObserverForInterval:queue:usingBlock:] instead.
  CMTime currentTime() {
    objc.checkOsVersionInternal('AVPlayerItem.currentTime', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_currentTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_currentTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property forwardPlaybackEndTime
  /// @abstract
  /// The end time for forward playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is positive (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for forward playback is specified.
  /// In this case, the effective end time for forward playback is the receiver's duration.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is negative.
  CMTime get forwardPlaybackEndTime {
    objc.checkOsVersionInternal(
      'AVPlayerItem.forwardPlaybackEndTime',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_forwardPlaybackEndTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_forwardPlaybackEndTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property forwardPlaybackEndTime
  /// @abstract
  /// The end time for forward playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is positive (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for forward playback is specified.
  /// In this case, the effective end time for forward playback is the receiver's duration.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is negative.
  set forwardPlaybackEndTime(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setForwardPlaybackEndTime:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setForwardPlaybackEndTime_, value);
  }

  /// !
  /// @property reversePlaybackEndTime
  /// @abstract
  /// The end time for reverse playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is negative (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for reverse playback is specified.
  /// In this case, the effective end time for reverse playback is kCMTimeZero.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is positive.
  CMTime get reversePlaybackEndTime {
    objc.checkOsVersionInternal(
      'AVPlayerItem.reversePlaybackEndTime',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_reversePlaybackEndTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_reversePlaybackEndTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @property reversePlaybackEndTime
  /// @abstract
  /// The end time for reverse playback.
  ///
  /// @discussion
  /// Specifies the time at which playback should end when the playback rate is negative (see AVPlayer's rate property).
  /// The default value is kCMTimeInvalid, which indicates that no end time for reverse playback is specified.
  /// In this case, the effective end time for reverse playback is kCMTimeZero.
  ///
  /// When the end time is reached, the receiver will post AVPlayerItemDidPlayToEndTimeNotification and the AVPlayer will take
  /// the action indicated by the value of its actionAtItemEnd property (see AVPlayerActionAtItemEnd in AVPlayer.h).
  ///
  /// The value of this property has no effect on playback when the rate is positive.
  set reversePlaybackEndTime(CMTime value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setReversePlaybackEndTime:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_setReversePlaybackEndTime_, value);
  }

  /// !
  /// @property seekableTimeRanges
  /// @abstract This property provides a collection of time ranges that the player item can seek to. The ranges provided might be discontinous.
  /// @discussion Returns an NSArray of NSValues containing CMTimeRanges.
  objc.NSArray get seekableTimeRanges {
    objc.checkOsVersionInternal('AVPlayerItem.seekableTimeRanges', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_seekableTimeRanges);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			seekToTime:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled and the completion handler will be invoked with the finished parameter set to NO.
  ///
  /// This method throws an exception if time is invalid or indefinite.
  void seekToTime(CMTime time, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1pt0wih(
      this.ref.pointer,
      _sel_seekToTime_completionHandler_,
      time,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:completionHandler:
  /// @abstract			Moves the playback cursor within a specified time bound and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the item and to be notified when the seek operation is complete.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter set to NO. If the new
  /// request completes without being interrupted by another seek request or by any other operation the specified completion handler will be invoked with the
  /// finished parameter set to YES.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled and the completion handler will be invoked with the finished parameter set to NO.
  ///
  /// This method throws an exception if time is invalid or indefinite or if tolerance before or tolerance after is invalid or negative.
  void seekToTime$1(
    CMTime time, {
    required CMTime toleranceBefore,
    required CMTime toleranceAfter,
    objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:toleranceBefore:toleranceAfter:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_4xu1ph(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_,
      time,
      toleranceBefore,
      toleranceAfter,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			cancelPendingSeeks
  /// @abstract			Cancel any pending seek requests and invoke the corresponding completion handlers if present.
  /// @discussion		Use this method to cancel and release the completion handlers of pending seeks. The finished parameter of the completion handlers will
  /// be set to NO.
  void cancelPendingSeeks() {
    objc.checkOsVersionInternal('AVPlayerItem.cancelPendingSeeks', iOS: (false, (5, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelPendingSeeks);
  }

  /// !
  /// @method	currentDate
  /// @abstract	If currentTime is mapped to a particular (real-time) date, return that date.
  /// @result		Returns the date of current playback, or nil if playback is not mapped to any date.
  objc.NSDate? currentDate() {
    objc.checkOsVersionInternal('AVPlayerItem.currentDate', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentDate);
    return _ret.address == 0 ? null : objc.NSDate.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		seekToDate:completionHandler:
  /// @abstract		move playhead to a point corresponding to a particular date, and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @discussion
  /// For playback content that is associated with a range of dates, move the
  /// playhead to point within that range and invokes the completion handler when the seek operation is complete.
  /// Will fail if the supplied date is outside the range or if the content is not associated with a range of dates.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation, the specified
  /// completion handler will be invoked with the finished parameter set to YES.
  /// @param			date				The new position for the playhead.
  /// @param			completionHandler	The block to invoke when seek operation is complete
  /// @result		Returns true if the playhead was moved to the supplied date.
  bool seekToDate(objc.NSDate date, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToDate:completionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_1wskeji(
      this.ref.pointer,
      _sel_seekToDate_completionHandler_,
      date.ref.pointer,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method		stepByCount:
  /// @abstract		Moves player's current item's current time forward or backward by the specified number of steps.
  /// @param 		stepCount
  /// The number of steps by which to move. A positive number results in stepping forward, a negative number in stepping backward.
  /// @discussion
  /// The size of each step depends on the enabled AVPlayerItemTracks of the AVPlayerItem.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void stepByCount(int stepCount) {
    objc.checkOsVersionInternal('AVPlayerItem.stepByCount:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_4sp4xj(this.ref.pointer, _sel_stepByCount_, stepCount);
  }

  /// !
  /// @property		timebase
  /// @abstract		The item's timebase.
  /// @discussion
  /// You can examine the timebase to discover the relationship between the item's time and the source clock used for drift synchronization.
  /// This timebase is read-only; you cannot set its time or rate to affect playback.
  ffi.Pointer<OpaqueCMTimebase> get timebase {
    objc.checkOsVersionInternal('AVPlayerItem.timebase', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_93ekp9(this.ref.pointer, _sel_timebase);
  }
}

/// WARNING: AVVideoComposition is a stub. To generate bindings for this class, include
/// AVVideoComposition in your config's objc-interfaces list.
///
/// AVVideoComposition
class AVVideoComposition extends objc.ObjCObjectBase {
  AVVideoComposition._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVVideoComposition] that points to the same underlying object as [other].
  AVVideoComposition.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVVideoComposition] that wraps the given raw object pointer.
  AVVideoComposition.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_videoComposition = objc.registerName("videoComposition");
late final _sel_setVideoComposition_ = objc.registerName("setVideoComposition:");
final _objc_msgSend_xtuoz7 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
    >();

/// WARNING: AVVideoCompositing is a stub. To generate bindings for this class, include
/// AVVideoCompositing in your config's objc-protocols list.
///
/// AVVideoCompositing
interface class AVVideoCompositing extends objc.ObjCProtocolBase {
  AVVideoCompositing._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVVideoCompositing] that points to the same underlying object as [other].
  AVVideoCompositing.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVVideoCompositing] that wraps the given raw object pointer.
  AVVideoCompositing.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_customVideoCompositor = objc.registerName("customVideoCompositor");
late final _sel_seekingWaitsForVideoCompositionRendering = objc.registerName(
  "seekingWaitsForVideoCompositionRendering",
);
late final _sel_setSeekingWaitsForVideoCompositionRendering_ = objc.registerName(
  "setSeekingWaitsForVideoCompositionRendering:",
);
late final _sel_textStyleRules = objc.registerName("textStyleRules");
late final _sel_setTextStyleRules_ = objc.registerName("setTextStyleRules:");
late final _sel_videoApertureMode = objc.registerName("videoApertureMode");
late final _sel_setVideoApertureMode_ = objc.registerName("setVideoApertureMode:");
late final _sel_appliesPerFrameHDRDisplayMetadata = objc.registerName("appliesPerFrameHDRDisplayMetadata");
late final _sel_setAppliesPerFrameHDRDisplayMetadata_ = objc.registerName("setAppliesPerFrameHDRDisplayMetadata:");

/// AVPlayerItemVisualPresentation
extension AVPlayerItemVisualPresentation on AVPlayerItem {
  /// !
  /// @property 		videoComposition
  /// @abstract 		Indicates the video composition settings to be applied during playback.
  /// @discussion	Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  ///
  /// This property throws an exception if a video composition is set with any of the following values:
  /// - renderSize, renderScale, or frameDuration is less than or equal to zero
  /// - sourceTrackIDForFrameTiming is less than or equal to zero
  /// - uses AVVideoCompositionCoreAnimationTool (works for offline rendering only)
  AVVideoComposition? get videoComposition {
    objc.checkOsVersionInternal('AVPlayerItem.videoComposition', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoComposition);
    return _ret.address == 0 ? null : AVVideoComposition.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property 		videoComposition
  /// @abstract 		Indicates the video composition settings to be applied during playback.
  /// @discussion	Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  ///
  /// This property throws an exception if a video composition is set with any of the following values:
  /// - renderSize, renderScale, or frameDuration is less than or equal to zero
  /// - sourceTrackIDForFrameTiming is less than or equal to zero
  /// - uses AVVideoCompositionCoreAnimationTool (works for offline rendering only)
  set videoComposition(AVVideoComposition? value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVideoComposition:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoComposition_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property customVideoCompositor
  /// @abstract Indicates the custom video compositor instance.
  /// @discussion
  /// This property is nil if there is no video compositor, or if the internal video compositor is in use. This reference can be used to provide extra context to the custom video compositor instance if required.  The value of this property can change as a result of setting the `videoComposition` property.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  AVVideoCompositing? get customVideoCompositor {
    objc.checkOsVersionInternal(
      'AVPlayerItem.customVideoCompositor',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_customVideoCompositor);
    return _ret.address == 0 ? null : AVVideoCompositing.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property seekingWaitsForVideoCompositionRendering
  /// @abstract Indicates whether the item's timing follows the displayed video frame when seeking with a video composition
  /// @discussion
  /// By default, item timing is updated as quickly as possible, not waiting for media at new times to be rendered when seeking or
  /// during normal playback. The latency that occurs, for example, between the completion of a seek operation and the display of a
  /// video frame at a new time is negligible in most situations. However, when video compositions are in use, the processing of
  /// video for any particular time may introduce noticeable latency. Therefore it may be desirable when a video composition is in
  /// use for the item's timing be updated only after the video frame for a time has been displayed. This allows, for instance, an
  /// AVSynchronizedLayer associated with an AVPlayerItem to remain in synchronization with the displayed video and for the
  /// currentTime property to return the time of the displayed video.
  ///
  /// This property has no effect on items for which videoComposition is nil.
  bool get seekingWaitsForVideoCompositionRendering {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekingWaitsForVideoCompositionRendering',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_seekingWaitsForVideoCompositionRendering);
  }

  /// !
  /// @property seekingWaitsForVideoCompositionRendering
  /// @abstract Indicates whether the item's timing follows the displayed video frame when seeking with a video composition
  /// @discussion
  /// By default, item timing is updated as quickly as possible, not waiting for media at new times to be rendered when seeking or
  /// during normal playback. The latency that occurs, for example, between the completion of a seek operation and the display of a
  /// video frame at a new time is negligible in most situations. However, when video compositions are in use, the processing of
  /// video for any particular time may introduce noticeable latency. Therefore it may be desirable when a video composition is in
  /// use for the item's timing be updated only after the video frame for a time has been displayed. This allows, for instance, an
  /// AVSynchronizedLayer associated with an AVPlayerItem to remain in synchronization with the displayed video and for the
  /// currentTime property to return the time of the displayed video.
  ///
  /// This property has no effect on items for which videoComposition is nil.
  set seekingWaitsForVideoCompositionRendering(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setSeekingWaitsForVideoCompositionRendering:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setSeekingWaitsForVideoCompositionRendering_, value);
  }

  /// !
  /// @property textStyleRules
  /// @abstract An array of AVTextStyleRules representing text styling that can be applied to subtitles and other legible media.
  /// @discussion
  /// The styling information contained in each AVTextStyleRule object in the array is used only when no equivalent styling information is provided by the media resource being played.  For example, if the text style rules specify Courier font but the media resource specifies Helvetica font, the text will be drawn using Helvetica font.
  ///
  /// This property has an effect only for tracks with media subtype kCMSubtitleFormatType_WebVTT.
  objc.NSArray? get textStyleRules {
    objc.checkOsVersionInternal('AVPlayerItem.textStyleRules', iOS: (false, (6, 0, 0)), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_textStyleRules);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property textStyleRules
  /// @abstract An array of AVTextStyleRules representing text styling that can be applied to subtitles and other legible media.
  /// @discussion
  /// The styling information contained in each AVTextStyleRule object in the array is used only when no equivalent styling information is provided by the media resource being played.  For example, if the text style rules specify Courier font but the media resource specifies Helvetica font, the text will be drawn using Helvetica font.
  ///
  /// This property has an effect only for tracks with media subtype kCMSubtitleFormatType_WebVTT.
  set textStyleRules(objc.NSArray? value) {
    objc.checkOsVersionInternal('AVPlayerItem.setTextStyleRules:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 9, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setTextStyleRules_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property	videoApertureMode
  /// @abstract	Specifies the video aperture mode to apply during playback.
  /// @discussion
  /// See AVVideoApertureMode constants defined in AVVideoSettings.h. Default is AVVideoApertureModeCleanAperture.
  objc.NSString get videoApertureMode {
    objc.checkOsVersionInternal(
      'AVPlayerItem.videoApertureMode',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoApertureMode);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	videoApertureMode
  /// @abstract	Specifies the video aperture mode to apply during playback.
  /// @discussion
  /// See AVVideoApertureMode constants defined in AVVideoSettings.h. Default is AVVideoApertureModeCleanAperture.
  set videoApertureMode(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVideoApertureMode:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoApertureMode_, value.ref.pointer);
  }

  /// !
  /// @property	appliesPerFrameHDRDisplayMetadata
  /// @abstract	Controls whether or not to apply the per frame HDR display metadata of the source during playback.
  /// @discussion
  bool get appliesPerFrameHDRDisplayMetadata {
    objc.checkOsVersionInternal(
      'AVPlayerItem.appliesPerFrameHDRDisplayMetadata',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_appliesPerFrameHDRDisplayMetadata);
  }

  /// !
  /// @property	appliesPerFrameHDRDisplayMetadata
  /// @abstract	Controls whether or not to apply the per frame HDR display metadata of the source during playback.
  /// @discussion
  set appliesPerFrameHDRDisplayMetadata(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAppliesPerFrameHDRDisplayMetadata:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAppliesPerFrameHDRDisplayMetadata_, value);
  }
}

late final _sel_audioTimePitchAlgorithm = objc.registerName("audioTimePitchAlgorithm");
late final _sel_setAudioTimePitchAlgorithm_ = objc.registerName("setAudioTimePitchAlgorithm:");
late final _sel_isAudioSpatializationAllowed = objc.registerName("isAudioSpatializationAllowed");
late final _sel_setAudioSpatializationAllowed_ = objc.registerName("setAudioSpatializationAllowed:");

enum AVAudioSpatializationFormats {
  AVAudioSpatializationFormatNone(0),
  AVAudioSpatializationFormatMonoAndStereo(3),
  AVAudioSpatializationFormatMultichannel(4),
  AVAudioSpatializationFormatMonoStereoAndMultichannel(7);

  final int value;
  const AVAudioSpatializationFormats(this.value);

  static AVAudioSpatializationFormats fromValue(int value) => switch (value) {
    0 => AVAudioSpatializationFormatNone,
    3 => AVAudioSpatializationFormatMonoAndStereo,
    4 => AVAudioSpatializationFormatMultichannel,
    7 => AVAudioSpatializationFormatMonoStereoAndMultichannel,
    _ => throw ArgumentError('Unknown value for AVAudioSpatializationFormats: $value'),
  };
}

late final _sel_allowedAudioSpatializationFormats = objc.registerName("allowedAudioSpatializationFormats");
final _objc_msgSend_2s2a50 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setAllowedAudioSpatializationFormats_ = objc.registerName("setAllowedAudioSpatializationFormats:");
final _objc_msgSend_12f6ne = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// WARNING: AVAudioMix is a stub. To generate bindings for this class, include
/// AVAudioMix in your config's objc-interfaces list.
///
/// AVAudioMix
class AVAudioMix extends objc.ObjCObjectBase {
  AVAudioMix._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAudioMix] that points to the same underlying object as [other].
  AVAudioMix.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioMix] that wraps the given raw object pointer.
  AVAudioMix.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_audioMix = objc.registerName("audioMix");
late final _sel_setAudioMix_ = objc.registerName("setAudioMix:");

/// AVPlayerItemAudioProcessing
extension AVPlayerItemAudioProcessing on AVPlayerItem {
  /// !
  /// @property	audioTimePitchAlgorithm
  /// @abstract	Indicates the processing algorithm used to manage audio pitch at varying rates and for scaled audio edits.
  /// @discussion
  /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchSpectral, are defined in AVAudioProcessingSettings.h.
  /// The default value for applications linked on or after iOS 15.0 or macOS 12.0 is AVAudioTimePitchAlgorithmTimeDomain. For iOS versions prior to 15.0 the default value is AVAudioTimePitchAlgorithmLowQualityZeroLatency.
  /// For macOS versions prior to 12.0 the default value is AVAudioTimePitchAlgorithmSpectral.
  objc.NSString get audioTimePitchAlgorithm {
    objc.checkOsVersionInternal(
      'AVPlayerItem.audioTimePitchAlgorithm',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioTimePitchAlgorithm);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	audioTimePitchAlgorithm
  /// @abstract	Indicates the processing algorithm used to manage audio pitch at varying rates and for scaled audio edits.
  /// @discussion
  /// Constants for various time pitch algorithms, e.g. AVAudioTimePitchSpectral, are defined in AVAudioProcessingSettings.h.
  /// The default value for applications linked on or after iOS 15.0 or macOS 12.0 is AVAudioTimePitchAlgorithmTimeDomain. For iOS versions prior to 15.0 the default value is AVAudioTimePitchAlgorithmLowQualityZeroLatency.
  /// For macOS versions prior to 12.0 the default value is AVAudioTimePitchAlgorithmSpectral.
  set audioTimePitchAlgorithm(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAudioTimePitchAlgorithm:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioTimePitchAlgorithm_, value.ref.pointer);
  }

  /// !
  /// @property audioSpatializationAllowed
  /// @abstract Indicates whether audio spatialization is allowed
  /// @discussion
  /// When audio spatialization is allowed for an AVPlayerItem, the AVPlayer may render multichannel audio if available even if the output device doesn't support multichannel audio on its own, via use of a synthetic channel layout. When audio spatialization is not allowed, the AVPlayer must render audio with a channel layout that best matches the capabilities of the output device. This property is not observable. Defaults to YES.
  bool get audioSpatializationAllowed {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isAudioSpatializationAllowed',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isAudioSpatializationAllowed);
  }

  /// !
  /// @property audioSpatializationAllowed
  /// @abstract Indicates whether audio spatialization is allowed
  /// @discussion
  /// When audio spatialization is allowed for an AVPlayerItem, the AVPlayer may render multichannel audio if available even if the output device doesn't support multichannel audio on its own, via use of a synthetic channel layout. When audio spatialization is not allowed, the AVPlayer must render audio with a channel layout that best matches the capabilities of the output device. This property is not observable. Defaults to YES.
  set audioSpatializationAllowed(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAudioSpatializationAllowed:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 15, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAudioSpatializationAllowed_, value);
  }

  /// !
  /// @property allowedAudioSpatializationFormats
  /// @abstract Indicates the source audio channel layouts allowed by the receiver for spatialization.
  /// @discussion
  /// Spatialization uses psychoacoustic methods to create a more immersive audio rendering when the content is played on specialized headphones and speaker arrangements. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMonoAndStereo the AVPlayer will attempt to spatialize content tagged with a stereo channel layout, two-channel content with no layout specified as well as mono. It is considered incorrect to render a binaural recording with spatialization. A binaural recording is captured using two carefully placed microphones at each ear where the intent, when played on headphones, is to reproduce a naturally occurring spatial effect. Content tagged with a binaural channel layout will ignore this property value. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMultichannel the AVPlayer will attempt to spatialize any decodable multichannel layout. Setting this property to AVAudioSpatializationFormatMonoStereoAndMultichannel indicates that the sender allows the AVPlayer to spatialize any decodable mono, stereo or multichannel layout. This property is not observable. The default value for this property with video content is AVAudioSpatializationFormatMonoStereoAndMultichannel. Otherwise, audio only content default value is AVAudioSpatializationFormatMultichannel.
  AVAudioSpatializationFormats get allowedAudioSpatializationFormats {
    objc.checkOsVersionInternal(
      'AVPlayerItem.allowedAudioSpatializationFormats',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    final _ret = _objc_msgSend_2s2a50(this.ref.pointer, _sel_allowedAudioSpatializationFormats);
    return AVAudioSpatializationFormats.fromValue(_ret);
  }

  /// !
  /// @property allowedAudioSpatializationFormats
  /// @abstract Indicates the source audio channel layouts allowed by the receiver for spatialization.
  /// @discussion
  /// Spatialization uses psychoacoustic methods to create a more immersive audio rendering when the content is played on specialized headphones and speaker arrangements. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMonoAndStereo the AVPlayer will attempt to spatialize content tagged with a stereo channel layout, two-channel content with no layout specified as well as mono. It is considered incorrect to render a binaural recording with spatialization. A binaural recording is captured using two carefully placed microphones at each ear where the intent, when played on headphones, is to reproduce a naturally occurring spatial effect. Content tagged with a binaural channel layout will ignore this property value. When an AVPlayerItem's allowedAudioSpatializationFormats property is set to AVAudioSpatializationFormatMultichannel the AVPlayer will attempt to spatialize any decodable multichannel layout. Setting this property to AVAudioSpatializationFormatMonoStereoAndMultichannel indicates that the sender allows the AVPlayer to spatialize any decodable mono, stereo or multichannel layout. This property is not observable. The default value for this property with video content is AVAudioSpatializationFormatMonoStereoAndMultichannel. Otherwise, audio only content default value is AVAudioSpatializationFormatMultichannel.
  set allowedAudioSpatializationFormats(AVAudioSpatializationFormats value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setAllowedAudioSpatializationFormats:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_12f6ne(this.ref.pointer, _sel_setAllowedAudioSpatializationFormats_, value.value);
  }

  /// !
  /// @property audioMix
  /// @abstract Indicates the audio mix parameters to be applied during playback
  /// @discussion
  /// The inputParameters of the AVAudioMix must have trackIDs that correspond to a track of the receiver's asset. Otherwise they will be ignored. (See AVAudioMix.h for the declaration of AVAudioMixInputParameters and AVPlayerItem's asset property.)
  AVAudioMix? get audioMix {
    objc.checkOsVersionInternal('AVPlayerItem.audioMix', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioMix);
    return _ret.address == 0 ? null : AVAudioMix.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property audioMix
  /// @abstract Indicates the audio mix parameters to be applied during playback
  /// @discussion
  /// The inputParameters of the AVAudioMix must have trackIDs that correspond to a track of the receiver's asset. Otherwise they will be ignored. (See AVAudioMix.h for the declaration of AVAudioMixInputParameters and AVPlayerItem's asset property.)
  set audioMix(AVAudioMix? value) {
    objc.checkOsVersionInternal('AVPlayerItem.setAudioMix:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioMix_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_loadedTimeRanges = objc.registerName("loadedTimeRanges");
late final _sel_isPlaybackLikelyToKeepUp = objc.registerName("isPlaybackLikelyToKeepUp");
late final _sel_isPlaybackBufferFull = objc.registerName("isPlaybackBufferFull");
late final _sel_isPlaybackBufferEmpty = objc.registerName("isPlaybackBufferEmpty");
late final _sel_canUseNetworkResourcesForLiveStreamingWhilePaused = objc.registerName(
  "canUseNetworkResourcesForLiveStreamingWhilePaused",
);
late final _sel_setCanUseNetworkResourcesForLiveStreamingWhilePaused_ = objc.registerName(
  "setCanUseNetworkResourcesForLiveStreamingWhilePaused:",
);
late final _sel_preferredForwardBufferDuration = objc.registerName("preferredForwardBufferDuration");
final _objc_msgSend_1ukqyt8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_1ukqyt8Fpret = objc.msgSendFpretPointer
    .cast<ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPreferredForwardBufferDuration_ = objc.registerName("setPreferredForwardBufferDuration:");
final _objc_msgSend_hwm8nu = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();

/// AVPlayerItemPlayability
extension AVPlayerItemPlayability on AVPlayerItem {
  /// !
  /// @property loadedTimeRanges
  /// @abstract This property provides a collection of time ranges for which the player has the media data readily available. The ranges provided might be discontinuous.
  /// @discussion Returns an NSArray of NSValues containing CMTimeRanges.
  objc.NSArray get loadedTimeRanges {
    objc.checkOsVersionInternal('AVPlayerItem.loadedTimeRanges', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_loadedTimeRanges);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property playbackLikelyToKeepUp
  /// @abstract Indicates whether the item will likely play through without stalling.
  /// @discussion This property communicates a prediction of playability. Factors considered in this prediction
  /// include I/O throughput and media decode performance. It is possible for playbackLikelyToKeepUp to
  /// indicate NO while the property playbackBufferFull indicates YES. In this event the playback buffer has
  /// reached capacity but there isn't the statistical data to support a prediction that playback is likely to
  /// keep up. It is left to the application programmer to decide to continue media playback or not.
  /// See playbackBufferFull below.
  bool get playbackLikelyToKeepUp {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackLikelyToKeepUp',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackLikelyToKeepUp);
  }

  /// !
  /// @property playbackBufferFull
  /// @abstract Indicates that the internal media buffer is full and that further I/O is suspended.
  /// @discussion This property reports that the data buffer used for playback has reach capacity.
  /// Despite the playback buffer reaching capacity there might not exist sufficient statistical
  /// data to support a playbackLikelyToKeepUp prediction of YES. See playbackLikelyToKeepUp above.
  bool get playbackBufferFull {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackBufferFull',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackBufferFull);
  }

  /// isPlaybackBufferEmpty
  bool get playbackBufferEmpty {
    objc.checkOsVersionInternal(
      'AVPlayerItem.isPlaybackBufferEmpty',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaybackBufferEmpty);
  }

  /// !
  /// @property canUseNetworkResourcesForLiveStreamingWhilePaused
  /// @abstract Indicates whether the player item can use network resources to keep playback state up to date while paused
  /// @discussion
  /// For live streaming content, the player item may need to use extra networking and power resources to keep playback state up to date when paused.  For example, when this property is set to YES, the seekableTimeRanges property will be periodically updated to reflect the current state of the live stream.
  ///
  /// For clients linked on or after macOS 10.11 or iOS 9.0, the default value is NO.  To minimize power usage, avoid setting this property to YES when you do not need playback state to stay up to date while paused.
  bool get canUseNetworkResourcesForLiveStreamingWhilePaused {
    objc.checkOsVersionInternal(
      'AVPlayerItem.canUseNetworkResourcesForLiveStreamingWhilePaused',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_canUseNetworkResourcesForLiveStreamingWhilePaused);
  }

  /// !
  /// @property canUseNetworkResourcesForLiveStreamingWhilePaused
  /// @abstract Indicates whether the player item can use network resources to keep playback state up to date while paused
  /// @discussion
  /// For live streaming content, the player item may need to use extra networking and power resources to keep playback state up to date when paused.  For example, when this property is set to YES, the seekableTimeRanges property will be periodically updated to reflect the current state of the live stream.
  ///
  /// For clients linked on or after macOS 10.11 or iOS 9.0, the default value is NO.  To minimize power usage, avoid setting this property to YES when you do not need playback state to stay up to date while paused.
  set canUseNetworkResourcesForLiveStreamingWhilePaused(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setCanUseNetworkResourcesForLiveStreamingWhilePaused:',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setCanUseNetworkResourcesForLiveStreamingWhilePaused_, value);
  }

  /// !
  /// @property	preferredForwardBufferDuration
  /// @abstract	Indicates the media duration the caller prefers the player to buffer from the network ahead of the playhead to guard against playback disruption.
  /// @discussion	The value is in seconds. If it is set to 0, the player will choose an appropriate level of buffering for most use cases.
  /// Note that setting this property to a low value will increase the chance that playback will stall and re-buffer, while setting it to a high value will increase demand on system resources.
  /// Note that the system may buffer less than the value of this property in order to manage resource consumption.
  double get preferredForwardBufferDuration {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredForwardBufferDuration',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredForwardBufferDuration)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredForwardBufferDuration);
  }

  /// !
  /// @property	preferredForwardBufferDuration
  /// @abstract	Indicates the media duration the caller prefers the player to buffer from the network ahead of the playhead to guard against playback disruption.
  /// @discussion	The value is in seconds. If it is set to 0, the player will choose an appropriate level of buffering for most use cases.
  /// Note that setting this property to a low value will increase the chance that playback will stall and re-buffer, while setting it to a high value will increase demand on system resources.
  /// Note that the system may buffer less than the value of this property in order to manage resource consumption.
  set preferredForwardBufferDuration(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredForwardBufferDuration:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredForwardBufferDuration_, value);
  }
}

late final _sel_preferredPeakBitRate = objc.registerName("preferredPeakBitRate");
late final _sel_setPreferredPeakBitRate_ = objc.registerName("setPreferredPeakBitRate:");
late final _sel_preferredPeakBitRateForExpensiveNetworks = objc.registerName(
  "preferredPeakBitRateForExpensiveNetworks",
);
late final _sel_setPreferredPeakBitRateForExpensiveNetworks_ = objc.registerName(
  "setPreferredPeakBitRateForExpensiveNetworks:",
);
late final _sel_preferredMaximumResolution = objc.registerName("preferredMaximumResolution");
late final _sel_setPreferredMaximumResolution_ = objc.registerName("setPreferredMaximumResolution:");
final _objc_msgSend_13lgpwz = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)>();
late final _sel_preferredMaximumResolutionForExpensiveNetworks = objc.registerName(
  "preferredMaximumResolutionForExpensiveNetworks",
);
late final _sel_setPreferredMaximumResolutionForExpensiveNetworks_ = objc.registerName(
  "setPreferredMaximumResolutionForExpensiveNetworks:",
);
late final _sel_startsOnFirstEligibleVariant = objc.registerName("startsOnFirstEligibleVariant");
late final _sel_setStartsOnFirstEligibleVariant_ = objc.registerName("setStartsOnFirstEligibleVariant:");

/// !
/// @enum			AVVariantPreferences
/// @abstract		These constants can be used in any combination as the value of variantPreferences.
///
/// @constant		AVVariantPreferenceNone
/// Indicates that only the basic behaviors of the player for choosing among variants should be applied, including considerations of available bandwidth, compatibility of the indicated codec or codecs, the dimensions of visual output, and the number of available audio output channels.
/// @constant		AVVariantPreferenceScalabilityToLosslessAudio
/// Directs the item to permit the use of variants with lossless audio encodings, if sufficient bandwidth is available for their use.
enum AVVariantPreferences {
  AVVariantPreferenceNone(0),
  AVVariantPreferenceScalabilityToLosslessAudio(1);

  final int value;
  const AVVariantPreferences(this.value);

  static AVVariantPreferences fromValue(int value) => switch (value) {
    0 => AVVariantPreferenceNone,
    1 => AVVariantPreferenceScalabilityToLosslessAudio,
    _ => throw ArgumentError('Unknown value for AVVariantPreferences: $value'),
  };
}

late final _sel_variantPreferences = objc.registerName("variantPreferences");
final _objc_msgSend_2o73ov = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setVariantPreferences_ = objc.registerName("setVariantPreferences:");
final _objc_msgSend_1o3ak8z = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerItemVariantControl
extension AVPlayerItemVariantControl on AVPlayerItem {
  /// !
  /// @property preferredPeakBitRate
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item.
  ///
  /// @discussion
  /// Set preferredPeakBitRate to non-zero to indicate that the player should attempt to limit item playback to that bit rate, expressed in bits per second.
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRate, it will be reduced as much as possible while continuing to play the item.
  double get preferredPeakBitRate {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredPeakBitRate',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredPeakBitRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredPeakBitRate);
  }

  /// !
  /// @property preferredPeakBitRate
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item.
  ///
  /// @discussion
  /// Set preferredPeakBitRate to non-zero to indicate that the player should attempt to limit item playback to that bit rate, expressed in bits per second.
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRate, it will be reduced as much as possible while continuing to play the item.
  set preferredPeakBitRate(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredPeakBitRate:',
      iOS: (false, (8, 0, 0)),
      macOS: (false, (10, 10, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredPeakBitRate_, value);
  }

  /// !
  /// @property preferredPeakBitRateForExpensiveNetworks
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item over expensive networks.
  ///
  /// @discussion
  /// When preferredPeakBitRateForExpensiveNetworks is set to non-zero, the player will attempt to limit item playback to that bit rate
  /// when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRateForExpensiveNetworks, it will be reduced as much as possible while continuing to play the item.
  ///
  /// Note that preferredPeakBitRate still applies unconditionally.  If preferredPeakBitRateForExpensiveNetworks is less restrictive (greater) than preferredPeakBitRate,
  /// preferredPeakBitRateForExpensiveNetworks has no practical effect.
  double get preferredPeakBitRateForExpensiveNetworks {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredPeakBitRateForExpensiveNetworks',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredPeakBitRateForExpensiveNetworks)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredPeakBitRateForExpensiveNetworks);
  }

  /// !
  /// @property preferredPeakBitRateForExpensiveNetworks
  /// @abstract Indicates the desired limit of network bandwidth consumption for this item over expensive networks.
  ///
  /// @discussion
  /// When preferredPeakBitRateForExpensiveNetworks is set to non-zero, the player will attempt to limit item playback to that bit rate
  /// when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// If network bandwidth consumption cannot be lowered to meet the preferredPeakBitRateForExpensiveNetworks, it will be reduced as much as possible while continuing to play the item.
  ///
  /// Note that preferredPeakBitRate still applies unconditionally.  If preferredPeakBitRateForExpensiveNetworks is less restrictive (greater) than preferredPeakBitRate,
  /// preferredPeakBitRateForExpensiveNetworks has no practical effect.
  set preferredPeakBitRateForExpensiveNetworks(double value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredPeakBitRateForExpensiveNetworks:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setPreferredPeakBitRateForExpensiveNetworks_, value);
  }

  /// !
  /// @property preferredMaximumResolution
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded (or otherwise transferred) and rendered by the player.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// It only applies to HTTP Live Streaming asset.
  objc.CGSize get preferredMaximumResolution {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredMaximumResolution',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_preferredMaximumResolution)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_preferredMaximumResolution);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property preferredMaximumResolution
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded (or otherwise transferred) and rendered by the player.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// It only applies to HTTP Live Streaming asset.
  set preferredMaximumResolution(objc.CGSize value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredMaximumResolution:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_13lgpwz(this.ref.pointer, _sel_setPreferredMaximumResolution_, value);
  }

  /// !
  /// @property preferredMaximumResolutionForExpensiveNetworks
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded that applies only when the download occurs over expensive networks.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// This limit applies only when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// It only applies to HTTP Live Streaming asset.
  ///
  /// Note that preferredMaximumResolution still applies unconditionally.  If preferredMaximumResolutionForExpensiveNetworks is less restrictive (higher resolution)
  /// than preferredMaximumResolution, preferredMaximumResolutionForExpensiveNetworks has no practical effect.
  objc.CGSize get preferredMaximumResolutionForExpensiveNetworks {
    objc.checkOsVersionInternal(
      'AVPlayerItem.preferredMaximumResolutionForExpensiveNetworks',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_preferredMaximumResolutionForExpensiveNetworks)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_preferredMaximumResolutionForExpensiveNetworks);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// !
  /// @property preferredMaximumResolutionForExpensiveNetworks
  /// @abstract Indicates a preferred upper limit on the resolution of the video to be downloaded that applies only when the download occurs over expensive networks.
  /// @discussion
  /// The default value is CGSizeZero, which indicates that the client enforces no limit on video resolution. Other values indicate a preferred maximum video resolution.
  /// This limit applies only when streaming over an expensive network, such as when using a cellular data plan.  (See -[NWPath isExpensive])
  ///
  /// It only applies to HTTP Live Streaming asset.
  ///
  /// Note that preferredMaximumResolution still applies unconditionally.  If preferredMaximumResolutionForExpensiveNetworks is less restrictive (higher resolution)
  /// than preferredMaximumResolution, preferredMaximumResolutionForExpensiveNetworks has no practical effect.
  set preferredMaximumResolutionForExpensiveNetworks(objc.CGSize value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setPreferredMaximumResolutionForExpensiveNetworks:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_13lgpwz(this.ref.pointer, _sel_setPreferredMaximumResolutionForExpensiveNetworks_, value);
  }

  /// !
  /// @property		startsOnFirstEligibleVariant
  /// @abstract		Directs the player to start playback with the first eligible variant  that appears in the stream's master playlist.
  /// @discussion
  /// This property influences AVPlayer's algorithm for selecting which of the eligible variant streams in an HTTP Live Streaming master playlist is selected when playback first begins.
  /// In all cases, AVPlayer may switch to other variants during playback.
  ///
  /// On releases prior to macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback with the first eligible variant in the master playlist.
  /// On releases starting with macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback by choosing an initial variant that optimizes the startup experience.
  /// On releases starting with macOS 11.0, iOS 14, tvOS 14 and watchOS 7, applications may set this property to YES to request that AVPlayer use the previous behaviour of using the first eligible variant in the master playlist. This would be appropriate, for example, for applications which wish to control initial variant selection by ordering the variants in the master playlist.
  ///
  /// Note that changing this property may impact stream startup performance and quality. In order to be effective this property must be set before initial variant selection occurs.
  /// This property only applies to HTTP Live Streaming assets. The default value of this property is NO.
  bool get startsOnFirstEligibleVariant {
    objc.checkOsVersionInternal(
      'AVPlayerItem.startsOnFirstEligibleVariant',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_startsOnFirstEligibleVariant);
  }

  /// !
  /// @property		startsOnFirstEligibleVariant
  /// @abstract		Directs the player to start playback with the first eligible variant  that appears in the stream's master playlist.
  /// @discussion
  /// This property influences AVPlayer's algorithm for selecting which of the eligible variant streams in an HTTP Live Streaming master playlist is selected when playback first begins.
  /// In all cases, AVPlayer may switch to other variants during playback.
  ///
  /// On releases prior to macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback with the first eligible variant in the master playlist.
  /// On releases starting with macOS 10.15, iOS 13, tvOS 13 and watchOS 6, AVPlayer starts HLS playback by choosing an initial variant that optimizes the startup experience.
  /// On releases starting with macOS 11.0, iOS 14, tvOS 14 and watchOS 7, applications may set this property to YES to request that AVPlayer use the previous behaviour of using the first eligible variant in the master playlist. This would be appropriate, for example, for applications which wish to control initial variant selection by ordering the variants in the master playlist.
  ///
  /// Note that changing this property may impact stream startup performance and quality. In order to be effective this property must be set before initial variant selection occurs.
  /// This property only applies to HTTP Live Streaming assets. The default value of this property is NO.
  set startsOnFirstEligibleVariant(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setStartsOnFirstEligibleVariant:',
      iOS: (false, (14, 0, 0)),
      macOS: (false, (11, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setStartsOnFirstEligibleVariant_, value);
  }

  /// !
  /// @property		variantPreferences
  /// @abstract		Indicates preferences for variant switching.
  /// @discussion
  /// Changing variant preferences during playback may result in a variant switch.
  /// The default value is AVVariantPreferenceNone.
  AVVariantPreferences get variantPreferences {
    objc.checkOsVersionInternal(
      'AVPlayerItem.variantPreferences',
      iOS: (false, (14, 5, 0)),
      macOS: (false, (11, 3, 0)),
    );
    final _ret = _objc_msgSend_2o73ov(this.ref.pointer, _sel_variantPreferences);
    return AVVariantPreferences.fromValue(_ret);
  }

  /// !
  /// @property		variantPreferences
  /// @abstract		Indicates preferences for variant switching.
  /// @discussion
  /// Changing variant preferences during playback may result in a variant switch.
  /// The default value is AVVariantPreferenceNone.
  set variantPreferences(AVVariantPreferences value) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.setVariantPreferences:',
      iOS: (false, (14, 5, 0)),
      macOS: (false, (11, 3, 0)),
    );
    _objc_msgSend_1o3ak8z(this.ref.pointer, _sel_setVariantPreferences_, value.value);
  }
}

/// WARNING: AVMediaSelectionOption is a stub. To generate bindings for this class, include
/// AVMediaSelectionOption in your config's objc-interfaces list.
///
/// AVMediaSelectionOption
class AVMediaSelectionOption extends objc.ObjCObjectBase {
  AVMediaSelectionOption._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMediaSelectionOption] that points to the same underlying object as [other].
  AVMediaSelectionOption.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMediaSelectionOption] that wraps the given raw object pointer.
  AVMediaSelectionOption.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_selectMediaOption_inMediaSelectionGroup_ = objc.registerName(
  "selectMediaOption:inMediaSelectionGroup:",
);
final _objc_msgSend_pfv6jd = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_selectMediaOptionAutomaticallyInMediaSelectionGroup_ = objc.registerName(
  "selectMediaOptionAutomaticallyInMediaSelectionGroup:",
);
late final _sel_currentMediaSelection = objc.registerName("currentMediaSelection");

/// AVPlayerItemMediaSelection
extension AVPlayerItemMediaSelection on AVPlayerItem {
  /// !
  /// @method		selectMediaOption:inMediaSelectionGroup:
  /// @abstract
  /// Selects the media option described by the specified instance of AVMediaSelectionOption in the specified AVMediaSelectionGroup and deselects all other options in that group.
  /// @param 		mediaSelectionOption	The option to select.
  /// @param 		mediaSelectionGroup		The media selection group, obtained from the receiver's asset, that contains the specified option.
  /// @discussion
  /// If the specified media selection option isn't a member of the specified media selection group, no change in presentation state will result.
  /// If the value of the property allowsEmptySelection of the AVMediaSelectionGroup is YES, you can pass nil for mediaSelectionOption to deselect
  /// all media selection options in the group.
  /// Note that if multiple options within a group meet your criteria for selection according to locale or other considerations, and if these options are otherwise indistinguishable to you according to media characteristics that are meaningful for your application, content is typically authored so that the first available option that meets your criteria is appropriate for selection.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void selectMediaOption(
    AVMediaSelectionOption? mediaSelectionOption, {
    required AVMediaSelectionGroup inMediaSelectionGroup,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectMediaOption:inMediaSelectionGroup:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_pfv6jd(
      this.ref.pointer,
      _sel_selectMediaOption_inMediaSelectionGroup_,
      mediaSelectionOption?.ref.pointer ?? ffi.nullptr,
      inMediaSelectionGroup.ref.pointer,
    );
  }

  /// !
  /// @method		selectMediaOptionAutomaticallyInMediaSelectionGroup:
  /// @abstract
  /// Selects the media option in the specified media selection group that best matches the AVPlayer's current automatic selection criteria. Also allows automatic selection to be re-applied to the specified group subsequently if the relevant criteria are changed.
  /// @param 		mediaSelectionGroup		The media selection group, obtained from the receiver's asset, that contains the specified option.
  /// @discussion
  /// Has no effect unless the appliesMediaSelectionCriteriaAutomatically property of the associated AVPlayer is YES and unless automatic media selection has previously been overridden via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void selectMediaOptionAutomaticallyInMediaSelectionGroup(AVMediaSelectionGroup mediaSelectionGroup) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectMediaOptionAutomaticallyInMediaSelectionGroup:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(
      this.ref.pointer,
      _sel_selectMediaOptionAutomaticallyInMediaSelectionGroup_,
      mediaSelectionGroup.ref.pointer,
    );
  }

  /// !
  /// @property		currentMediaSelection
  /// @abstract		Provides an instance of AVMediaSelection carrying current selections for each of the receiver's media selection groups.
  AVMediaSelection get currentMediaSelection {
    objc.checkOsVersionInternal(
      'AVPlayerItem.currentMediaSelection',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentMediaSelection);
    return AVMediaSelection.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemAccessLog is a stub. To generate bindings for this class, include
/// AVPlayerItemAccessLog in your config's objc-interfaces list.
///
/// !
/// @class			AVPlayerItemAccessLog
/// @abstract		An AVPlayerItemAccessLog provides methods to retrieve the access log in a format suitable for serialization.
/// @discussion	An AVPlayerItemAccessLog acculumulates key metrics about network playback and presents them as a collection
/// of AVPlayerItemAccessLogEvent instances. Each AVPlayerItemAccessLogEvent instance collates the data
/// that relates to each uninterrupted period of playback.
///
/// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
class AVPlayerItemAccessLog extends objc.NSObject implements objc.NSCopying {
  AVPlayerItemAccessLog._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayerItemAccessLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayerItemAccessLog] that points to the same underlying object as [other].
  AVPlayerItemAccessLog.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemAccessLog] that wraps the given raw object pointer.
  AVPlayerItemAccessLog.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_accessLog = objc.registerName("accessLog");

/// WARNING: AVPlayerItemErrorLog is a stub. To generate bindings for this class, include
/// AVPlayerItemErrorLog in your config's objc-interfaces list.
///
/// !
/// @class			AVPlayerItemErrorLog
/// @abstract		An AVPlayerItemErrorLog provides methods to retrieve the error log in a format suitable for serialization.
/// @discussion	An AVPlayerItemErrorLog provides data to identify if, and when, network resource playback failures occured.
///
/// Subclasses of this type that are used from Swift must fulfill the requirements of a Sendable type.
class AVPlayerItemErrorLog extends objc.NSObject implements objc.NSCopying {
  AVPlayerItemErrorLog._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayerItemErrorLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayerItemErrorLog] that points to the same underlying object as [other].
  AVPlayerItemErrorLog.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemErrorLog] that wraps the given raw object pointer.
  AVPlayerItemErrorLog.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_errorLog = objc.registerName("errorLog");

/// AVPlayerItemLogging
extension AVPlayerItemLogging on AVPlayerItem {
  /// !
  /// @method		accessLog
  /// @abstract		Returns an object that represents a snapshot of the network access log. Can be nil.
  /// @discussion	An AVPlayerItemAccessLog provides methods to retrieve the network access log in a format suitable for serialization.
  /// If nil is returned then there is no logging information currently available for this AVPlayerItem.
  /// An AVPlayerItemNewAccessLogEntryNotification will be posted when new logging information becomes available. However, accessLog might already return a non-nil value even before the first notification is posted.
  /// @result		An autoreleased AVPlayerItemAccessLog instance.
  AVPlayerItemAccessLog? accessLog() {
    objc.checkOsVersionInternal('AVPlayerItem.accessLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_accessLog);
    return _ret.address == 0 ? null : AVPlayerItemAccessLog.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		errorLog
  /// @abstract		Returns an object that represents a snapshot of the error log. Can be nil.
  /// @discussion	An AVPlayerItemErrorLog provides methods to retrieve the error log in a format suitable for serialization.
  /// If nil is returned then there is no logging information currently available for this AVPlayerItem.
  /// @result		An autoreleased AVPlayerItemErrorLog instance.
  AVPlayerItemErrorLog? errorLog() {
    objc.checkOsVersionInternal('AVPlayerItem.errorLog', iOS: (false, (4, 3, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_errorLog);
    return _ret.address == 0 ? null : AVPlayerItemErrorLog.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemOutput is a stub. To generate bindings for this class, include
/// AVPlayerItemOutput in your config's objc-interfaces list.
///
/// AVPlayerItemOutput
class AVPlayerItemOutput extends objc.ObjCObjectBase {
  AVPlayerItemOutput._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItemOutput] that points to the same underlying object as [other].
  AVPlayerItemOutput.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemOutput] that wraps the given raw object pointer.
  AVPlayerItemOutput.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_addOutput_ = objc.registerName("addOutput:");
late final _sel_removeOutput_ = objc.registerName("removeOutput:");
late final _sel_outputs = objc.registerName("outputs");

/// AVPlayerItemOutputs
extension AVPlayerItemOutputs on AVPlayerItem {
  /// !
  /// @method		addOutput:
  /// @abstract		Adds the specified instance of AVPlayerItemOutput to the receiver's collection of outputs.
  /// @discussion
  /// The class of AVPlayerItemOutput provided dictates the data structure that decoded samples are vended in.
  ///
  /// When an AVPlayerItemOutput is associated with an AVPlayerItem, samples are provided for a media type in accordance with the rules for mixing, composition, or exclusion that the AVPlayer honors among multiple enabled tracks of that media type for its own rendering purposes. For example, video media will be composed according to the instructions provided via AVPlayerItem.videoComposition, if present. Audio media will be mixed according to the parameters provided via AVPlayerItem.audioMix, if present.
  /// @param			output
  /// An instance of AVPlayerItemOutput
  void addOutput(AVPlayerItemOutput output) {
    objc.checkOsVersionInternal('AVPlayerItem.addOutput:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addOutput_, output.ref.pointer);
  }

  /// !
  /// @method		removeOutput:
  /// @abstract		Removes the specified instance of AVPlayerItemOutput from the receiver's collection of outputs.
  /// @param			output
  /// An instance of AVPlayerItemOutput
  void removeOutput(AVPlayerItemOutput output) {
    objc.checkOsVersionInternal('AVPlayerItem.removeOutput:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeOutput_, output.ref.pointer);
  }

  /// !
  /// @property		outputs
  /// @abstract		The collection of associated outputs.
  objc.NSArray get outputs {
    objc.checkOsVersionInternal('AVPlayerItem.outputs', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputs);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerItemMediaDataCollector is a stub. To generate bindings for this class, include
/// AVPlayerItemMediaDataCollector in your config's objc-interfaces list.
///
/// AVPlayerItemMediaDataCollector
class AVPlayerItemMediaDataCollector extends objc.ObjCObjectBase {
  AVPlayerItemMediaDataCollector._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItemMediaDataCollector] that points to the same underlying object as [other].
  AVPlayerItemMediaDataCollector.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItemMediaDataCollector] that wraps the given raw object pointer.
  AVPlayerItemMediaDataCollector.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_addMediaDataCollector_ = objc.registerName("addMediaDataCollector:");
late final _sel_removeMediaDataCollector_ = objc.registerName("removeMediaDataCollector:");
late final _sel_mediaDataCollectors = objc.registerName("mediaDataCollectors");

/// AVPlayerItemMediaDataCollectors
extension AVPlayerItemMediaDataCollectors on AVPlayerItem {
  /// !
  /// @method		addMediaDataCollector:
  /// @abstract		Adds the specified instance of AVPlayerItemMediaDataCollector to the receiver's collection of mediaDataCollectors.
  /// @discussion
  /// This method may incur additional I/O to collect the requested media data asynchronously.
  /// @param			collector
  /// An instance of AVPlayerItemMediaDataCollector
  void addMediaDataCollector(AVPlayerItemMediaDataCollector collector) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.addMediaDataCollector:',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addMediaDataCollector_, collector.ref.pointer);
  }

  /// !
  /// @method		removeMediaDataCollector:
  /// @abstract		Removes the specified instance of AVPlayerItemMediaDataCollector from the receiver's collection of mediaDataCollectors.
  /// @param			collector
  /// An instance of AVPlayerItemMediaDataCollector
  void removeMediaDataCollector(AVPlayerItemMediaDataCollector collector) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.removeMediaDataCollector:',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeMediaDataCollector_, collector.ref.pointer);
  }

  /// !
  /// @property		mediaDataCollectors
  /// @abstract		The collection of associated mediaDataCollectors.
  objc.NSArray get mediaDataCollectors {
    objc.checkOsVersionInternal(
      'AVPlayerItem.mediaDataCollectors',
      iOS: (false, (9, 3, 0)),
      macOS: (false, (10, 11, 3)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_mediaDataCollectors);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_seekToTime_ = objc.registerName("seekToTime:");
late final _sel_seekToTime_toleranceBefore_toleranceAfter_ = objc.registerName(
  "seekToTime:toleranceBefore:toleranceAfter:",
);
final _objc_msgSend_1up52l2 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime, CMTime, CMTime)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, CMTime, CMTime, CMTime)>();
late final _sel_seekToDate_ = objc.registerName("seekToDate:");
late final _sel_selectedMediaOptionInMediaSelectionGroup_ = objc.registerName(
  "selectedMediaOptionInMediaSelectionGroup:",
);

/// AVPlayerItemDeprecated
extension AVPlayerItemDeprecated on AVPlayerItem {
  /// !
  /// @method			seekToTime:
  /// @abstract			Moves the playback cursor.
  /// @param				time
  /// @discussion		Use this method to seek to a specified time for the item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled.
  void seekToTime(CMTime time) {
    objc.checkOsVersionInternal('AVPlayerItem.seekToTime:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_seekToTime_, time);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:
  /// @abstract			Moves the playback cursor within a specified time bound.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the item.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// Seeking is constrained by the collection of seekable time ranges. If you seek to a time outside all of the seekable ranges the seek will result in a currentTime
  /// within the seekable ranges.
  /// If the seek time is outside of seekable time ranges as indicated by seekableTimeRanges property, the seek request will be cancelled.
  void seekToTime$1(CMTime time, {required CMTime toleranceBefore, required CMTime toleranceAfter}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.seekToTime:toleranceBefore:toleranceAfter:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1up52l2(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_,
      time,
      toleranceBefore,
      toleranceAfter,
    );
  }

  /// !
  /// @method		seekToDate
  /// @abstract		move playhead to a point corresponding to a particular date.
  /// @discussion
  /// For playback content that is associated with a range of dates, move the
  /// playhead to point within that range. Will fail if the supplied date is outside
  /// the range or if the content is not associated with a range of dates.
  /// @param			date	The new position for the playhead.
  /// @result		Returns true if the playhead was moved to the supplied date.
  bool seekToDate(objc.NSDate date) {
    objc.checkOsVersionInternal('AVPlayerItem.seekToDate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_19nvye5(this.ref.pointer, _sel_seekToDate_, date.ref.pointer);
  }

  /// !
  /// @method		selectedMediaOptionInMediaSelectionGroup:
  /// @abstract		Indicates the media selection option that's currently selected from the specified group. May be nil.
  /// @param 		mediaSelectionGroup		A media selection group obtained from the receiver's asset.
  /// @result		An instance of AVMediaSelectionOption that describes the currently selection option in the group.
  /// @discussion
  /// If the value of the property allowsEmptySelection of the AVMediaSelectionGroup is YES, the currently selected option in the group may be nil.
  AVMediaSelectionOption? selectedMediaOptionInMediaSelectionGroup(AVMediaSelectionGroup mediaSelectionGroup) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.selectedMediaOptionInMediaSelectionGroup:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_selectedMediaOptionInMediaSelectionGroup_,
      mediaSelectionGroup.ref.pointer,
    );
    return _ret.address == 0 ? null : AVMediaSelectionOption.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVMetricEventStreamPublisher is a stub. To generate bindings for this class, include
/// AVMetricEventStreamPublisher in your config's objc-protocols list.
///
/// AVMetricEventStreamPublisher
interface class AVMetricEventStreamPublisher extends objc.ObjCProtocolBase {
  AVMetricEventStreamPublisher._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVMetricEventStreamPublisher] that points to the same underlying object as [other].
  AVMetricEventStreamPublisher.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVMetricEventStreamPublisher] that wraps the given raw object pointer.
  AVMetricEventStreamPublisher.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

/// AVMetricEventStreamPublisher
extension AVMetricEventStreamPublisher$1 on AVPlayerItem {}

late final _sel_playerItemWithURL_ = objc.registerName("playerItemWithURL:");
late final _sel_playerItemWithAsset_ = objc.registerName("playerItemWithAsset:");
late final _sel_playerItemWithAsset_automaticallyLoadedAssetKeys_ = objc.registerName(
  "playerItemWithAsset:automaticallyLoadedAssetKeys:",
);
late final _sel_initWithURL_ = objc.registerName("initWithURL:");
late final _sel_initWithAsset_ = objc.registerName("initWithAsset:");
late final _sel_initWithAsset_automaticallyLoadedAssetKeys_ = objc.registerName(
  "initWithAsset:automaticallyLoadedAssetKeys:",
);
late final _sel_copyWithZone_ = objc.registerName("copyWithZone:");
late final _sel_copy = objc.registerName("copy");

/// !
/// @enum AVPlayerItemStatus
/// @abstract
/// These constants are returned by the AVPlayerItem status property to indicate whether it can successfully be played.
///
/// @constant	 AVPlayerItemStatusUnknown
/// Indicates that the status of the player item is not yet known because it has not tried to load new media resources
/// for playback.
/// @constant	 AVPlayerItemStatusReadyToPlay
/// Indicates that the player item is ready to be played.
/// @constant	 AVPlayerItemStatusFailed
/// Indicates that the player item can no longer be played because of an error. The error is described by the value of
/// the player item's error property.
enum AVPlayerItemStatus {
  AVPlayerItemStatusUnknown(0),
  AVPlayerItemStatusReadyToPlay(1),
  AVPlayerItemStatusFailed(2);

  final int value;
  const AVPlayerItemStatus(this.value);

  static AVPlayerItemStatus fromValue(int value) => switch (value) {
    0 => AVPlayerItemStatusUnknown,
    1 => AVPlayerItemStatusReadyToPlay,
    2 => AVPlayerItemStatusFailed,
    _ => throw ArgumentError('Unknown value for AVPlayerItemStatus: $value'),
  };
}

late final _sel_status = objc.registerName("status");
final _objc_msgSend_fmekku = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_error = objc.registerName("error");

/// AVPlayerItem
class AVPlayerItem extends objc.NSObject implements objc.NSCopying {
  AVPlayerItem._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerItem] that points to the same underlying object as [other].
  AVPlayerItem.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerItem] that wraps the given raw object pointer.
  AVPlayerItem.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVPlayerItem].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVPlayerItem);
  }

  /// init
  AVPlayerItem init() {
    objc.checkOsVersionInternal('AVPlayerItem.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVPlayerItem new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayerItem, _sel_new);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		playerItemWithURL:
  /// @abstract		Returns an instance of AVPlayerItem for playing a resource at the specified location.
  /// @param			URL
  /// @result		An instance of AVPlayerItem.
  /// @discussion	Equivalent to +playerItemWithAsset:, passing [AVAsset assetWithURL:URL] as the value of asset.
  static AVPlayerItem playerItemWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayerItem.playerItemWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayerItem, _sel_playerItemWithURL_, URL.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playerItemWithAsset:
  /// @abstract		Returns an instance of AVPlayerItem for playing an AVAsset.
  /// @param			asset
  /// @result		An instance of AVPlayerItem.
  /// @discussion	Equivalent to +playerItemWithAsset:automaticallyLoadedAssetKeys:, passing @[ @"duration" ] as the value of automaticallyLoadedAssetKeys.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, an overload of this initializer will be chosen automatically to allow you to initialize an AVPlayerItem while not running on the main actor.
  static AVPlayerItem playerItemWithAsset(AVAsset asset) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.playerItemWithAsset:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayerItem, _sel_playerItemWithAsset_, asset.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		playerItemWithAsset:automaticallyLoadedAssetKeys:
  /// @abstract		Returns an instance of AVPlayerItem for playing an AVAsset.
  /// @param			asset
  /// @param			automaticallyLoadedAssetKeys
  /// An NSArray of NSStrings, each representing a property key defined by AVAsset. See AVAsset.h for property keys, e.g. duration.
  /// @result		An instance of AVPlayerItem.
  /// @discussion	The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be one of the terminal status values greater than AVKeyValueStatusLoading.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, you can use `init(asset:automaticallyLoadedAssetKeys:)` to initialize an AVPlayerItem while not running on the main actor.
  static AVPlayerItem playerItemWithAsset$1(AVAsset asset, {objc.NSArray? automaticallyLoadedAssetKeys}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.playerItemWithAsset:automaticallyLoadedAssetKeys:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      _class_AVPlayerItem,
      _sel_playerItemWithAsset_automaticallyLoadedAssetKeys_,
      asset.ref.pointer,
      automaticallyLoadedAssetKeys?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method		initWithURL:
  /// @abstract		Initializes an AVPlayerItem with an NSURL.
  /// @param			URL
  /// @result		An instance of AVPlayerItem
  /// @discussion	Equivalent to -initWithAsset:, passing [AVAsset assetWithURL:URL] as the value of asset.
  AVPlayerItem initWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayerItem.initWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithURL_, URL.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		initWithAsset:
  /// @abstract		Initializes an AVPlayerItem with an AVAsset.
  /// @param			asset
  /// @result		An instance of AVPlayerItem
  /// @discussion	Equivalent to -initWithAsset:automaticallyLoadedAssetKeys:, passing @[ @"duration" ] as the value of automaticallyLoadedAssetKeys.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, an overload of this initializer will be chosen automatically to allow you to initialize an AVPlayerItem while not running on the main actor.
  AVPlayerItem initWithAsset(AVAsset asset) {
    objc.checkOsVersionInternal('AVPlayerItem.initWithAsset:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithAsset_, asset.ref.pointer);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method		initWithAsset:automaticallyLoadedAssetKeys:
  /// @abstract		Initializes an AVPlayerItem with an AVAsset.
  /// @param			asset
  /// An instance of AVAsset.
  /// @param			automaticallyLoadedAssetKeys
  /// An NSArray of NSStrings, each representing a property key defined by AVAsset. See AVAsset.h for property keys, e.g. duration.
  /// @result		An instance of AVPlayerItem
  /// @discussion	The value of each key in automaticallyLoadedAssetKeys will be automatically be loaded by the underlying AVAsset before the receiver achieves the status AVPlayerItemStatusReadyToPlay; i.e. when the item is ready to play, the value of -[[AVPlayerItem asset] statusOfValueForKey:error:] will be one of the terminal status values greater than AVKeyValueStatusLoading.
  ///
  /// This method, along with the companion `asset` property, is MainActor-isolated for Swift clients because AVAsset is not Sendable.  If you are using a Sendable subclass of AVAsset, such as AVURLAsset, you can use `init(asset:automaticallyLoadedAssetKeys:)` to initialize an AVPlayerItem while not running on the main actor.
  AVPlayerItem initWithAsset$1(AVAsset asset, {objc.NSArray? automaticallyLoadedAssetKeys}) {
    objc.checkOsVersionInternal(
      'AVPlayerItem.initWithAsset:automaticallyLoadedAssetKeys:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      this.ref.retainAndReturnPointer(),
      _sel_initWithAsset_automaticallyLoadedAssetKeys_,
      asset.ref.pointer,
      automaticallyLoadedAssetKeys?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// copyWithZone:
  objc.ObjCObjectBase copyWithZone(ffi.Pointer<objc.NSZone> zone) {
    objc.checkOsVersionInternal('AVPlayerItem.copyWithZone:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1cwp428(this.ref.pointer, _sel_copyWithZone_, zone);
    return objc.ObjCObjectBase(_ret, retain: false, release: true);
  }

  /// copy
  objc.ObjCObjectBase copy() {
    objc.checkOsVersionInternal('AVPlayerItem.copy', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_copy);
    return objc.ObjCObjectBase(_ret, retain: false, release: true);
  }

  /// !
  /// @property status
  /// @abstract
  /// The ability of the receiver to be used for playback.
  ///
  /// @discussion
  /// The value of this property is an AVPlayerItemStatus that indicates whether the receiver can be used for playback.
  /// When the value of this property is AVPlayerItemStatusFailed, the receiver can no longer be used for playback and
  /// a new instance needs to be created in its place. When this happens, clients can check the value of the error
  /// property to determine the nature of the failure. The value of this property will not be updated after the receiver
  /// is removed from an AVPlayer. This property is key value observable.
  AVPlayerItemStatus get status {
    objc.checkOsVersionInternal('AVPlayerItem.status', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_fmekku(this.ref.pointer, _sel_status);
    return AVPlayerItemStatus.fromValue(_ret);
  }

  /// !
  /// @property error
  /// @abstract
  /// If the receiver's status is AVPlayerItemStatusFailed, this describes the error that caused the failure.
  ///
  /// @discussion
  /// The value of this property is an NSError that describes what caused the receiver to no longer be able to be played.
  /// If the receiver's status is not AVPlayerItemStatusFailed, the value of this property is nil.
  objc.NSError? get error {
    objc.checkOsVersionInternal('AVPlayerItem.error', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_error);
    return _ret.address == 0 ? null : objc.NSError.castFromPointer(_ret, retain: true, release: true);
  }

  /// allocWithZone:
  static AVPlayerItem allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVPlayerItem, _sel_allocWithZone_, zone);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVPlayerItem alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayerItem, _sel_alloc);
    return AVPlayerItem.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVPlayerItem self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVPlayerItem retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVPlayerItem autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVPlayerItem constructed with the default `new` method.
  factory AVPlayerItem() => new$();
}

late final _sel_currentItem = objc.registerName("currentItem");
late final _sel_replaceCurrentItemWithPlayerItem_ = objc.registerName("replaceCurrentItemWithPlayerItem:");

/// !
/// @enum AVPlayerActionAtItemEnd
/// @abstract
/// These constants are the allowable values of AVPlayer's actionAtItemEnd property.
///
/// @constant	 AVPlayerActionAtItemEndAdvance
/// Indicates that when an AVPlayerItem reaches its end time the player will automatically advance to the next item in its queue.
/// This value is supported only for players of class AVQueuePlayer. An AVPlayer that's not an AVQueuePlayer will raise an NSInvalidArgumentException if an attempt is made to set its actionAtItemEnd to AVPlayerActionAtItemEndAdvance.
/// @constant	 AVPlayerActionAtItemEndPause
/// Indicates that when an AVPlayerItem reaches its end time the player will automatically pause (which is to say, the player's
/// rate will automatically be set to 0).
/// @constant	 AVPlayerActionAtItemEndNone
/// Indicates that when an AVPlayerItem reaches its end time the player will take no action (which is to say, the player's rate
/// will not change, its currentItem will not change, and its currentTime will continue to be incremented or decremented as time
/// elapses, according to its rate). After this, if the player's actionAtItemEnd is set to a value other than AVPlayerActionAtItemEndNone,
/// the player will immediately take the action appropriate to that value.
enum AVPlayerActionAtItemEnd {
  AVPlayerActionAtItemEndAdvance(0),
  AVPlayerActionAtItemEndPause(1),
  AVPlayerActionAtItemEndNone(2);

  final int value;
  const AVPlayerActionAtItemEnd(this.value);

  static AVPlayerActionAtItemEnd fromValue(int value) => switch (value) {
    0 => AVPlayerActionAtItemEndAdvance,
    1 => AVPlayerActionAtItemEndPause,
    2 => AVPlayerActionAtItemEndNone,
    _ => throw ArgumentError('Unknown value for AVPlayerActionAtItemEnd: $value'),
  };
}

late final _sel_actionAtItemEnd = objc.registerName("actionAtItemEnd");
final _objc_msgSend_1x7j5o8 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setActionAtItemEnd_ = objc.registerName("setActionAtItemEnd:");
final _objc_msgSend_1pn4puq = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerItemControl
extension AVPlayerItemControl on AVPlayer {
  /// currentItem
  AVPlayerItem? get currentItem {
    objc.checkOsVersionInternal('AVPlayer.currentItem', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentItem);
    return _ret.address == 0 ? null : AVPlayerItem.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			replaceCurrentItemWithPlayerItem:
  /// @abstract		Replaces the player's current item with the specified player item.
  /// @param			item
  /// The AVPlayerItem that will become the player's current item.
  /// @discussion
  /// In all releases of iOS 4, invoking replaceCurrentItemWithPlayerItem: with an AVPlayerItem that's already the receiver's currentItem results in an exception being raised. Starting with iOS 5, it's a no-op.
  /// This method throws an exception if the item already exists in the play queue.
  void replaceCurrentItemWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal(
      'AVPlayer.replaceCurrentItemWithPlayerItem:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_replaceCurrentItemWithPlayerItem_, item?.ref.pointer ?? ffi.nullptr);
  }

  /// !
  /// @property		actionAtItemEnd
  /// @abstract		Indicates the action that the player should perform when playback of an item reaches its end time.
  /// @discussion	This property throws an exception if set to AVPlayerActionAtItemEndAdvance on an AVPlayer which is not an AVQueuePlayer.
  AVPlayerActionAtItemEnd get actionAtItemEnd {
    objc.checkOsVersionInternal('AVPlayer.actionAtItemEnd', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1x7j5o8(this.ref.pointer, _sel_actionAtItemEnd);
    return AVPlayerActionAtItemEnd.fromValue(_ret);
  }

  /// !
  /// @property		actionAtItemEnd
  /// @abstract		Indicates the action that the player should perform when playback of an item reaches its end time.
  /// @discussion	This property throws an exception if set to AVPlayerActionAtItemEndAdvance on an AVPlayer which is not an AVQueuePlayer.
  set actionAtItemEnd(AVPlayerActionAtItemEnd value) {
    objc.checkOsVersionInternal('AVPlayer.setActionAtItemEnd:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pn4puq(this.ref.pointer, _sel_setActionAtItemEnd_, value.value);
  }
}

/// AVPlayerTimeControl
extension AVPlayerTimeControl on AVPlayer {
  /// !
  /// @method			currentTime
  /// @abstract			Returns the current time of the current item.
  /// @result			A CMTime
  /// @discussion		Returns the current time of the current item. Not key-value observable; use -addPeriodicTimeObserverForInterval:queue:usingBlock: instead.
  CMTime currentTime() {
    objc.checkOsVersionInternal('AVPlayer.currentTime', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ptr = pkg_ffi.calloc<CMTime>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1f8hvjsStret(_ptr, this.ref.pointer, _sel_currentTime)
        : _ptr.ref = _objc_msgSend_1f8hvjs(this.ref.pointer, _sel_currentTime);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(ffi.sizeOf<CMTime>(), finalizer: pkg_ffi.calloc.nativeFree);
    return ffi.Struct.create<CMTime>(_finalizable);
  }

  /// !
  /// @method			seekToDate:
  /// @abstract			Moves the playback cursor.
  /// @param				date
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  void seekToDate(objc.NSDate date) {
    objc.checkOsVersionInternal('AVPlayer.seekToDate:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_seekToDate_, date.ref.pointer);
  }

  /// !
  /// @method			seekToDate:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				date
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.  If no item is attached, the completion handler will be
  /// invoked immediately with the finished parameter set to NO.
  void seekToDate$1(objc.NSDate date, {required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToDate:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_o762yo(
      this.ref.pointer,
      _sel_seekToDate_completionHandler_,
      date.ref.pointer,
      completionHandler.ref.pointer,
    );
  }

  /// !
  /// @method			seekToTime:
  /// @abstract			Moves the playback cursor.
  /// @param				time
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to may differ from the specified time for efficiency. For sample accurate seeking see seekToTime:toleranceBefore:toleranceAfter:.
  void seekToTime(CMTime time) {
    objc.checkOsVersionInternal('AVPlayer.seekToTime:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1hznzoi(this.ref.pointer, _sel_seekToTime_, time);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:
  /// @abstract			Moves the playback cursor within a specified time bound.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the current player item.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  void seekToTime$1(CMTime time, {required CMTime toleranceBefore, required CMTime toleranceAfter}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:toleranceBefore:toleranceAfter:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1up52l2(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_,
      time,
      toleranceBefore,
      toleranceAfter,
    );
  }

  /// !
  /// @method			seekToTime:completionHandler:
  /// @abstract			Moves the playback cursor and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				completionHandler
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter
  /// set to NO. If the new request completes without being interrupted by another seek request or by any other operation the specified
  /// completion handler will be invoked with the finished parameter set to YES.  If no item is attached, the completion handler will be
  /// invoked immediately with the finished parameter set to NO.
  void seekToTime$2(CMTime time, {required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1pt0wih(this.ref.pointer, _sel_seekToTime_completionHandler_, time, completionHandler.ref.pointer);
  }

  /// !
  /// @method			seekToTime:toleranceBefore:toleranceAfter:completionHandler:
  /// @abstract			Moves the playback cursor within a specified time bound and invokes the specified block when the seek operation has either been completed or been interrupted.
  /// @param				time
  /// @param				toleranceBefore
  /// @param				toleranceAfter
  /// @discussion		Use this method to seek to a specified time for the current player item and to be notified when the seek operation is complete.
  /// The time seeked to will be within the range [time-toleranceBefore, time+toleranceAfter] and may differ from the specified time for efficiency.
  /// Pass kCMTimeZero for both toleranceBefore and toleranceAfter to request sample accurate seeking which may incur additional decoding delay.
  /// Messaging this method with beforeTolerance:kCMTimePositiveInfinity and afterTolerance:kCMTimePositiveInfinity is the same as messaging seekToTime: directly.
  /// The completion handler for any prior seek request that is still in process will be invoked immediately with the finished parameter set to NO. If the new
  /// request completes without being interrupted by another seek request or by any other operation the specified completion handler will be invoked with the
  /// finished parameter set to YES.  If no item is attached, the completion handler will be invoked immediately with the finished parameter set to NO.
  void seekToTime$3(
    CMTime time, {
    required CMTime toleranceBefore,
    required CMTime toleranceAfter,
    required objc.ObjCBlock<ffi.Void Function(ffi.Bool)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.seekToTime:toleranceBefore:toleranceAfter:completionHandler:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_4xu1ph(
      this.ref.pointer,
      _sel_seekToTime_toleranceBefore_toleranceAfter_completionHandler_,
      time,
      toleranceBefore,
      toleranceAfter,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_automaticallyWaitsToMinimizeStalling = objc.registerName("automaticallyWaitsToMinimizeStalling");
late final _sel_setAutomaticallyWaitsToMinimizeStalling_ = objc.registerName(
  "setAutomaticallyWaitsToMinimizeStalling:",
);
late final _sel_setRate_time_atHostTime_ = objc.registerName("setRate:time:atHostTime:");
final _objc_msgSend_qhsl75 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Float, CMTime, CMTime)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double, CMTime, CMTime)>();
late final _sel_prerollAtRate_completionHandler_ = objc.registerName("prerollAtRate:completionHandler:");
final _objc_msgSend_1blh1va = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Float,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        double,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_cancelPendingPrerolls = objc.registerName("cancelPendingPrerolls");
late final _sel_sourceClock = objc.registerName("sourceClock");
final _objc_msgSend_1lamzyt = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<OpaqueCMClock> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<ffi.Pointer<OpaqueCMClock> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setSourceClock_ = objc.registerName("setSourceClock:");
final _objc_msgSend_1samav9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<OpaqueCMClock>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<OpaqueCMClock>)
    >();

/// AVPlayerAdvancedRateControl
extension AVPlayerAdvancedRateControl on AVPlayer {
  /// !
  /// @property		automaticallyWaitsToMinimizeStalling
  /// @abstract		Indicates that the player is allowed to delay playback at the specified rate in order to minimize stalling
  /// @discussion
  ///
  /// When this property is YES, whenever 1) the rate is set from zero to non-zero or 2) the playback buffer becomes empty and playback stalls, the player will attempt to determine if, at the specified rate, its currentItem will play to the end without interruptions. Should it determine that such interruptions would occur and these interruptions can be avoided by delaying the start or resumption of playback, the value of timeControlStatus will become AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate and playback will start automatically when the likelihood of stalling has been minimized.
  ///
  /// You may want to set this property to NO when you need precise control over playback start times, e.g., when synchronizing multiple instances of AVPlayer, and you should set it to NO if you use an AVAssetResourceLoader delegate to load media data (more on this below). If the value of this property is NO, reasonForWaitingToPlay cannot assume a value of AVPlayerWaitingToMinimizeStallsReason.
  /// This implies that setting rate to a non-zero value in AVPlayerTimeControlStatusPaused will cause playback to start immediately as long as the playback buffer is not empty. When the playback buffer becomes empty during AVPlayerTimeControlStatusPlaying and playback stalls, playback state will switch to AVPlayerTimeControlStatusPaused and the rate will become 0.0.
  ///
  /// Changing the value of this property to NO while the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate with a reasonForWaitingToPlay of AVPlayerWaitingToMinimizeStallsReason will cause the player to attempt playback at the specified rate immediately.
  ///
  /// For clients linked against iOS 10.0 and running on that version or later or linked against macOS 10.12 and running on that version or later, the default value of this property is YES.
  /// In versions of iOS prior to iOS 10.0 and versions of macOS prior to 10.12, this property is unavailable, and the behavior of the AVPlayer corresponds to the type of content being played. For streaming content, including HTTP Live Streaming, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is YES. For file-based content, including file-based content accessed via progressive http download, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// If you employ an AVAssetResourceLoader delegate that loads media data for playback, you should set the value of your AVPlayers automaticallyWaitsToMinimizeStalling property to NO. Allowing the value of automaticallyWaitsToMinimizeStalling to remain YES when an AVAssetResourceLoader delegate is used for the loading of media data can result in poor start-up times for playback and poor recovery from stalls, because the behaviors provided by AVPlayer when automaticallyWaitsToMinimizeStalling has a value of YES depend on predictions of the future availability of media data that that do not function as expected when data is loaded via a client-controlled means, using the AVAssetResourceLoader delegate interface.
  ///
  /// You can allow the value of automaticallyWaitsToMinimizeStalling to remain YES if you use an AVAssetResourceLoader delegate to manage content keys for FairPlay Streaming, to provide dynamically-generated master playlists for HTTP Live Streaming, or to respond to authentication challenges, but not to load media data for playback.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  bool get automaticallyWaitsToMinimizeStalling {
    objc.checkOsVersionInternal(
      'AVPlayer.automaticallyWaitsToMinimizeStalling',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_automaticallyWaitsToMinimizeStalling);
  }

  /// !
  /// @property		automaticallyWaitsToMinimizeStalling
  /// @abstract		Indicates that the player is allowed to delay playback at the specified rate in order to minimize stalling
  /// @discussion
  ///
  /// When this property is YES, whenever 1) the rate is set from zero to non-zero or 2) the playback buffer becomes empty and playback stalls, the player will attempt to determine if, at the specified rate, its currentItem will play to the end without interruptions. Should it determine that such interruptions would occur and these interruptions can be avoided by delaying the start or resumption of playback, the value of timeControlStatus will become AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate and playback will start automatically when the likelihood of stalling has been minimized.
  ///
  /// You may want to set this property to NO when you need precise control over playback start times, e.g., when synchronizing multiple instances of AVPlayer, and you should set it to NO if you use an AVAssetResourceLoader delegate to load media data (more on this below). If the value of this property is NO, reasonForWaitingToPlay cannot assume a value of AVPlayerWaitingToMinimizeStallsReason.
  /// This implies that setting rate to a non-zero value in AVPlayerTimeControlStatusPaused will cause playback to start immediately as long as the playback buffer is not empty. When the playback buffer becomes empty during AVPlayerTimeControlStatusPlaying and playback stalls, playback state will switch to AVPlayerTimeControlStatusPaused and the rate will become 0.0.
  ///
  /// Changing the value of this property to NO while the value of timeControlStatus is AVPlayerTimeControlStatusWaitingToPlayAtSpecifiedRate with a reasonForWaitingToPlay of AVPlayerWaitingToMinimizeStallsReason will cause the player to attempt playback at the specified rate immediately.
  ///
  /// For clients linked against iOS 10.0 and running on that version or later or linked against macOS 10.12 and running on that version or later, the default value of this property is YES.
  /// In versions of iOS prior to iOS 10.0 and versions of macOS prior to 10.12, this property is unavailable, and the behavior of the AVPlayer corresponds to the type of content being played. For streaming content, including HTTP Live Streaming, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is YES. For file-based content, including file-based content accessed via progressive http download, the AVPlayer acts as if automaticallyWaitsToMinimizeStalling is NO.
  ///
  /// If you employ an AVAssetResourceLoader delegate that loads media data for playback, you should set the value of your AVPlayers automaticallyWaitsToMinimizeStalling property to NO. Allowing the value of automaticallyWaitsToMinimizeStalling to remain YES when an AVAssetResourceLoader delegate is used for the loading of media data can result in poor start-up times for playback and poor recovery from stalls, because the behaviors provided by AVPlayer when automaticallyWaitsToMinimizeStalling has a value of YES depend on predictions of the future availability of media data that that do not function as expected when data is loaded via a client-controlled means, using the AVAssetResourceLoader delegate interface.
  ///
  /// You can allow the value of automaticallyWaitsToMinimizeStalling to remain YES if you use an AVAssetResourceLoader delegate to manage content keys for FairPlay Streaming, to provide dynamically-generated master playlists for HTTP Live Streaming, or to respond to authentication challenges, but not to load media data for playback.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set automaticallyWaitsToMinimizeStalling(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAutomaticallyWaitsToMinimizeStalling:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAutomaticallyWaitsToMinimizeStalling_, value);
  }

  /// !
  /// @method			setRate:time:atHostTime:
  /// @abstract		Simultaneously sets the playback rate and the relationship between the current item's current time and host time.
  /// @discussion		You can use this function to synchronize playback with an external activity.
  ///
  /// The current item's timebase is adjusted so that its time will be (or was) itemTime when host time is (or was) hostClockTime.
  /// In other words: if hostClockTime is in the past, the timebase's time will be interpolated as though the timebase has been running at the requested rate since that time.  If hostClockTime is in the future, the timebase will immediately start running at the requested rate from an earlier time so that it will reach the requested itemTime at the requested hostClockTime.  (Note that the item's time will not jump backwards, but instead will sit at itemTime until the timebase reaches that time.)
  ///
  /// Note that setRate:time:atHostTime: is not supported when automaticallyWaitsToMinimizeStalling is YES. For clients linked against iOS 10.0 and later or macOS 12.0 and later, invoking setRate:time:atHostTime: when automaticallyWaitsToMinimizeStalling is YES will raise an NSInvalidArgument exception. Support for HTTP Live Streaming content requires iOS 11, tvOS 11, macOS 10.13 or later.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  ///
  /// @param itemTime	The time to start playback from, specified precisely (i.e., with zero tolerance).
  /// Pass kCMTimeInvalid to use the current item's current time.
  /// @param hostClockTime
  /// The host time at which to start playback.
  /// If hostClockTime is specified, the player will not ensure that media data is loaded before the timebase starts moving.
  /// If hostClockTime is kCMTimeInvalid, the rate and time will be set together, but without external synchronization;
  /// a host time in the near future will be used, allowing some time for media data loading.
  void setRate(double rate, {required CMTime time, required CMTime atHostTime}) {
    objc.checkOsVersionInternal(
      'AVPlayer.setRate:time:atHostTime:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_qhsl75(this.ref.pointer, _sel_setRate_time_atHostTime_, rate, time, atHostTime);
  }

  /// !
  /// @method			prerollAtRate:completionHandler:
  /// @abstract		Begins loading media data to prime the render pipelines for playback from the current time with the given rate.
  /// @discussion		Once the completion handler is called with YES, the player's rate can be set with minimal latency.
  /// The completion handler will be called with NO if the preroll is interrupted by a time change or incompatible rate change, or if preroll is not possible for some other reason.
  /// Call this method only when the rate is currently zero and only after the AVPlayer's status has become AVPlayerStatusReadyToPlay.
  /// This method throws an exception if the status is not AVPlayerStatusReadyToPlay.
  /// @param rate		The intended rate for subsequent playback.
  /// @param completionHandler
  /// The block that will be called when the preroll is either completed or is interrupted.
  void prerollAtRate(double rate, {objc.ObjCBlock<ffi.Void Function(ffi.Bool)>? completionHandler}) {
    objc.checkOsVersionInternal(
      'AVPlayer.prerollAtRate:completionHandler:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 8, 0)),
    );
    _objc_msgSend_1blh1va(
      this.ref.pointer,
      _sel_prerollAtRate_completionHandler_,
      rate,
      completionHandler?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method			cancelPendingPrerolls
  /// @abstract		Cancel any pending preroll requests and invoke the corresponding completion handlers if present.
  /// @discussion		Use this method to cancel and release the completion handlers for pending prerolls. The finished parameter of the completion handlers will be set to NO.
  void cancelPendingPrerolls() {
    objc.checkOsVersionInternal('AVPlayer.cancelPendingPrerolls', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelPendingPrerolls);
  }

  /// !
  /// @property		sourceClock
  /// @abstract		Set to override the automatic choice of source clock for item timebases.
  /// @discussion		NULL by default. This is most useful for synchronizing video-only movies with audio played via other means. IMPORTANT NOTE: If you specify a source clock other than the appropriate audio device clock, audio may drift out of sync.
  ffi.Pointer<OpaqueCMClock> get sourceClock {
    objc.checkOsVersionInternal('AVPlayer.sourceClock', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    return _objc_msgSend_1lamzyt(this.ref.pointer, _sel_sourceClock);
  }

  /// !
  /// @property		sourceClock
  /// @abstract		Set to override the automatic choice of source clock for item timebases.
  /// @discussion		NULL by default. This is most useful for synchronizing video-only movies with audio played via other means. IMPORTANT NOTE: If you specify a source clock other than the appropriate audio device clock, audio may drift out of sync.
  set sourceClock(ffi.Pointer<OpaqueCMClock> value) {
    objc.checkOsVersionInternal('AVPlayer.setSourceClock:', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    _objc_msgSend_1samav9(this.ref.pointer, _sel_setSourceClock_, value);
  }
}

void _ObjCBlock_ffiVoid_CMTime_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(CMTime arg0)>>()
    .asFunction<void Function(CMTime)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>(
      _ObjCBlock_ffiVoid_CMTime_fnPtrTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) =>
    (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_CMTime_closureCallable =
    ffi.Pointer.fromFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>(
      _ObjCBlock_ffiVoid_CMTime_closureTrampoline,
    ).cast();
void _ObjCBlock_ffiVoid_CMTime_listenerTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0) {
  (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_listenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>.listener(
      _ObjCBlock_ffiVoid_CMTime_listenerTrampoline,
    )..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_CMTime_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  CMTime arg0,
) {
  try {
    (objc.getBlockClosure(block) as void Function(CMTime))(arg0);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_blockingCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>.isolateLocal(
      _ObjCBlock_ffiVoid_CMTime_blockingTrampoline,
    )..keepIsolateAlive = false;
ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>
_ObjCBlock_ffiVoid_CMTime_blockingListenerCallable =
    ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, CMTime)>.listener(
      _ObjCBlock_ffiVoid_CMTime_blockingTrampoline,
    )..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(CMTime)>`.
abstract final class ObjCBlock_ffiVoid_CMTime {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(CMTime arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(CMTime)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_CMTime_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> fromFunction(
    void Function(CMTime) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(CMTime)>(
    objc.newClosureBlock(_ObjCBlock_ffiVoid_CMTime_closureCallable, (CMTime arg0) => fn(arg0), keepIsolateAlive),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> listener(void Function(CMTime) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_listenerCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_1hznzoi(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(CMTime)> blocking(void Function(CMTime) fn, {bool keepIsolateAlive = true}) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_blockingCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_CMTime_blockingListenerCallable.nativeFunction.cast(),
      (CMTime arg0) => fn(arg0),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_1hznzoi(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(CMTime)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(CMTime)>`.
extension ObjCBlock_ffiVoid_CMTime_CallExtension on objc.ObjCBlock<ffi.Void Function(CMTime)> {
  void call(CMTime arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, CMTime arg0)>>()
      .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, CMTime)>()(ref.pointer, arg0);
}

late final _sel_addPeriodicTimeObserverForInterval_queue_usingBlock_ = objc.registerName(
  "addPeriodicTimeObserverForInterval:queue:usingBlock:",
);
final _objc_msgSend_15um7tj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          CMTime,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        CMTime,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_addBoundaryTimeObserverForTimes_queue_usingBlock_ = objc.registerName(
  "addBoundaryTimeObserverForTimes:queue:usingBlock:",
);
final _objc_msgSend_2wiv66 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_removeTimeObserver_ = objc.registerName("removeTimeObserver:");

/// AVPlayerTimeObservation
extension AVPlayerTimeObservation on AVPlayer {
  /// !
  /// @method			addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// @abstract		Requests invocation of a block during playback to report changing time.
  /// @param			interval
  /// The interval of invocation of the block during normal playback, according to progress of the current time of the player.
  /// @param			queue
  /// The serial queue onto which block should be enqueued.  If you pass NULL, the main queue (obtained using dispatch_get_main_queue()) will be used.  Passing a
  /// concurrent queue to this method will result in undefined behavior.
  /// @param			block
  /// The block to be invoked periodically.
  /// @result
  /// An object conforming to the NSObject protocol.  You must retain this returned value as long as you want the time observer to be invoked by the player.
  /// Pass this object to -removeTimeObserver: to cancel time observation.
  /// @discussion		The block is invoked periodically at the interval specified, interpreted according to the timeline of the current item.
  /// The block is also invoked whenever time jumps and whenever playback starts or stops.
  /// If the interval corresponds to a very short interval in real time, the player may invoke the block less frequently
  /// than requested. Even so, the player will invoke the block sufficiently often for the client to update indications
  /// of the current time appropriately in its end-user interface.
  /// Each call to -addPeriodicTimeObserverForInterval:queue:usingBlock: should be paired with a corresponding call to -removeTimeObserver:.
  /// Releasing the observer object without a call to -removeTimeObserver: will result in undefined behavior.
  objc.ObjCObjectBase addPeriodicTimeObserverForInterval(
    CMTime interval, {
    objc.NSObject? queue,
    required objc.ObjCBlock<ffi.Void Function(CMTime)> usingBlock,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.addPeriodicTimeObserverForInterval:queue:usingBlock:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_15um7tj(
      this.ref.pointer,
      _sel_addPeriodicTimeObserverForInterval_queue_usingBlock_,
      interval,
      queue?.ref.pointer ?? ffi.nullptr,
      usingBlock.ref.pointer,
    );
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// !
  /// @method			addBoundaryTimeObserverForTimes:queue:usingBlock:
  /// @abstract		Requests invocation of a block when specified times are traversed during normal playback.
  /// @param			times
  /// The times for which the observer requests notification, supplied as an array of NSValues carrying CMTimes.
  /// @param			queue
  /// The serial queue onto which block should be enqueued.  If you pass NULL, the main queue (obtained using dispatch_get_main_queue()) will be used.  Passing a
  /// concurrent queue to this method will result in undefined behavior.
  /// @param			block
  /// The block to be invoked when any of the specified times is crossed during normal playback.
  /// @result
  /// An object conforming to the NSObject protocol.  You must retain this returned value as long as you want the time observer to be invoked by the player.
  /// Pass this object to -removeTimeObserver: to cancel time observation.
  /// @discussion		Each call to -addPeriodicTimeObserverForInterval:queue:usingBlock: should be paired with a corresponding call to -removeTimeObserver:.
  /// Releasing the observer object without a call to -removeTimeObserver: will result in undefined behavior.
  objc.ObjCObjectBase addBoundaryTimeObserverForTimes(
    objc.NSArray times, {
    objc.NSObject? queue,
    required objc.ObjCBlock<ffi.Void Function()> usingBlock,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.addBoundaryTimeObserverForTimes:queue:usingBlock:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_2wiv66(
      this.ref.pointer,
      _sel_addBoundaryTimeObserverForTimes_queue_usingBlock_,
      times.ref.pointer,
      queue?.ref.pointer ?? ffi.nullptr,
      usingBlock.ref.pointer,
    );
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// !
  /// @method			removeTimeObserver:
  /// @abstract		Cancels a previously registered time observer.
  /// @param			observer
  /// An object returned by a previous call to -addPeriodicTimeObserverForInterval:queue:usingBlock: or -addBoundaryTimeObserverForTimes:queue:usingBlock:.
  /// @discussion		Upon return, the caller is guaranteed that no new time observer blocks will begin executing.  Depending on the calling thread and the queue
  /// used to add the time observer, an in-flight block may continue to execute after this method returns.  You can guarantee synchronous time
  /// observer removal by enqueuing the call to -removeTimeObserver: on that queue.  Alternatively, call dispatch_sync(queue, ^{}) after
  /// -removeTimeObserver: to wait for any in-flight blocks to finish executing.
  /// -removeTimeObserver: should be used to explicitly cancel each time observer added using -addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// and -addBoundaryTimeObserverForTimes:queue:usingBlock:.
  ///
  /// This method throws an exception for any of the following reasons:
  /// - observer was added by a different instance of AVPlayer
  /// - observer was not returned by -addPeriodicTimeObserverForInterval:queue:usingBlock:
  /// - observer was not returned by -addBoundaryTimeObserverForTimes:queue:usingBlock:
  void removeTimeObserver(objc.ObjCObjectBase observer) {
    objc.checkOsVersionInternal('AVPlayer.removeTimeObserver:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeTimeObserver_, observer.ref.pointer);
  }
}

late final _sel_volume = objc.registerName("volume");
late final _sel_setVolume_ = objc.registerName("setVolume:");
late final _sel_isMuted = objc.registerName("isMuted");
late final _sel_setMuted_ = objc.registerName("setMuted:");

/// AVPlayerMediaControl
extension AVPlayerMediaControl on AVPlayer {
  /// volume
  double get volume {
    objc.checkOsVersionInternal('AVPlayer.volume', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_volume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_volume);
  }

  /// setVolume:
  set volume(double value) {
    objc.checkOsVersionInternal('AVPlayer.setVolume:', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setVolume_, value);
  }

  /// isMuted
  bool get muted {
    objc.checkOsVersionInternal('AVPlayer.isMuted', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isMuted);
  }

  /// setMuted:
  set muted(bool value) {
    objc.checkOsVersionInternal('AVPlayer.setMuted:', iOS: (false, (7, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setMuted_, value);
  }
}

late final _sel_appliesMediaSelectionCriteriaAutomatically = objc.registerName(
  "appliesMediaSelectionCriteriaAutomatically",
);
late final _sel_setAppliesMediaSelectionCriteriaAutomatically_ = objc.registerName(
  "setAppliesMediaSelectionCriteriaAutomatically:",
);

/// WARNING: AVPlayerMediaSelectionCriteria is a stub. To generate bindings for this class, include
/// AVPlayerMediaSelectionCriteria in your config's objc-interfaces list.
///
/// AVPlayerMediaSelectionCriteria
class AVPlayerMediaSelectionCriteria extends objc.ObjCObjectBase {
  AVPlayerMediaSelectionCriteria._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerMediaSelectionCriteria] that points to the same underlying object as [other].
  AVPlayerMediaSelectionCriteria.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerMediaSelectionCriteria] that wraps the given raw object pointer.
  AVPlayerMediaSelectionCriteria.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_setMediaSelectionCriteria_forMediaCharacteristic_ = objc.registerName(
  "setMediaSelectionCriteria:forMediaCharacteristic:",
);
late final _sel_mediaSelectionCriteriaForMediaCharacteristic_ = objc.registerName(
  "mediaSelectionCriteriaForMediaCharacteristic:",
);

/// AVPlayerAutomaticMediaSelection
extension AVPlayerAutomaticMediaSelection on AVPlayer {
  /// appliesMediaSelectionCriteriaAutomatically
  bool get appliesMediaSelectionCriteriaAutomatically {
    objc.checkOsVersionInternal(
      'AVPlayer.appliesMediaSelectionCriteriaAutomatically',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_appliesMediaSelectionCriteriaAutomatically);
  }

  /// setAppliesMediaSelectionCriteriaAutomatically:
  set appliesMediaSelectionCriteriaAutomatically(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAppliesMediaSelectionCriteriaAutomatically:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAppliesMediaSelectionCriteriaAutomatically_, value);
  }

  /// !
  /// @method     setMediaSelectionCriteria:forMediaCharacteristic:
  /// @abstract   Applies automatic selection criteria for media that has the specified media characteristic.
  /// @param      criteria
  /// An instance of AVPlayerMediaSelectionCriteria.
  /// @param      mediaCharacteristic
  /// The media characteristic for which the selection criteria are to be applied. Supported values include AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual.
  /// @discussion
  /// Criteria will be applied to an AVPlayerItem when:
  /// a) It is made ready to play
  /// b) Specific media selections are made by -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:] in a different group. The automatic choice in one group may be influenced by a specific selection in another group.
  /// c) Underlying system preferences change, e.g. system language, accessibility captions.
  ///
  /// Specific selections made by -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:] within any group will override automatic selection in that group until -[AVPlayerItem selectMediaOptionAutomaticallyInMediaSelectionGroup:] is received.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  void setMediaSelectionCriteria(
    AVPlayerMediaSelectionCriteria? criteria, {
    required objc.NSString forMediaCharacteristic,
  }) {
    objc.checkOsVersionInternal(
      'AVPlayer.setMediaSelectionCriteria:forMediaCharacteristic:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_pfv6jd(
      this.ref.pointer,
      _sel_setMediaSelectionCriteria_forMediaCharacteristic_,
      criteria?.ref.pointer ?? ffi.nullptr,
      forMediaCharacteristic.ref.pointer,
    );
  }

  /// !
  /// @method     mediaSelectionCriteriaForMediaCharacteristic:
  /// @abstract   Returns the automatic selection criteria for media that has the specified media characteristic.
  /// @param      mediaCharacteristic
  /// The media characteristic for which the selection criteria is to be returned. Supported values include AVMediaCharacteristicAudible, AVMediaCharacteristicLegible, and AVMediaCharacteristicVisual.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this method must be invoked on the main thread/queue.
  AVPlayerMediaSelectionCriteria? mediaSelectionCriteriaForMediaCharacteristic(objc.NSString mediaCharacteristic) {
    objc.checkOsVersionInternal(
      'AVPlayer.mediaSelectionCriteriaForMediaCharacteristic:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_mediaSelectionCriteriaForMediaCharacteristic_,
      mediaCharacteristic.ref.pointer,
    );
    return _ret.address == 0 ? null : AVPlayerMediaSelectionCriteria.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_audioOutputDeviceUniqueID = objc.registerName("audioOutputDeviceUniqueID");
late final _sel_setAudioOutputDeviceUniqueID_ = objc.registerName("setAudioOutputDeviceUniqueID:");

/// AVPlayerAudioDeviceSupport
extension AVPlayerAudioDeviceSupport on AVPlayer {
  /// !
  /// @property audioOutputDeviceUniqueID
  /// @abstract
  /// Specifies the unique ID of the Core Audio output device used to play audio.
  /// @discussion
  /// By default, the value of this property is nil, indicating that the default audio output device is used. Otherwise the value of this property is an NSString containing the unique ID of the Core Audio output device to be used for audio output.
  ///
  /// Core Audio's kAudioDevicePropertyDeviceUID is a suitable source of audio output device unique IDs.
  objc.NSString? get audioOutputDeviceUniqueID {
    objc.checkOsVersionInternal('AVPlayer.audioOutputDeviceUniqueID', iOS: (true, null), macOS: (false, (10, 9, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_audioOutputDeviceUniqueID);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property audioOutputDeviceUniqueID
  /// @abstract
  /// Specifies the unique ID of the Core Audio output device used to play audio.
  /// @discussion
  /// By default, the value of this property is nil, indicating that the default audio output device is used. Otherwise the value of this property is an NSString containing the unique ID of the Core Audio output device to be used for audio output.
  ///
  /// Core Audio's kAudioDevicePropertyDeviceUID is a suitable source of audio output device unique IDs.
  set audioOutputDeviceUniqueID(objc.NSString? value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAudioOutputDeviceUniqueID:',
      iOS: (true, null),
      macOS: (false, (10, 9, 0)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAudioOutputDeviceUniqueID_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_allowsExternalPlayback = objc.registerName("allowsExternalPlayback");
late final _sel_setAllowsExternalPlayback_ = objc.registerName("setAllowsExternalPlayback:");
late final _sel_isExternalPlaybackActive = objc.registerName("isExternalPlaybackActive");
late final _sel_usesExternalPlaybackWhileExternalScreenIsActive = objc.registerName(
  "usesExternalPlaybackWhileExternalScreenIsActive",
);
late final _sel_setUsesExternalPlaybackWhileExternalScreenIsActive_ = objc.registerName(
  "setUsesExternalPlaybackWhileExternalScreenIsActive:",
);
late final _sel_externalPlaybackVideoGravity = objc.registerName("externalPlaybackVideoGravity");
late final _sel_setExternalPlaybackVideoGravity_ = objc.registerName("setExternalPlaybackVideoGravity:");

/// AVPlayerExternalPlaybackSupport
extension AVPlayerExternalPlaybackSupport on AVPlayer {
  /// allowsExternalPlayback
  bool get allowsExternalPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.allowsExternalPlayback',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_allowsExternalPlayback);
  }

  /// setAllowsExternalPlayback:
  set allowsExternalPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAllowsExternalPlayback:',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setAllowsExternalPlayback_, value);
  }

  /// isExternalPlaybackActive
  bool get externalPlaybackActive {
    objc.checkOsVersionInternal(
      'AVPlayer.isExternalPlaybackActive',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 11, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isExternalPlaybackActive);
  }

  /// usesExternalPlaybackWhileExternalScreenIsActive
  bool get usesExternalPlaybackWhileExternalScreenIsActive {
    objc.checkOsVersionInternal(
      'AVPlayer.usesExternalPlaybackWhileExternalScreenIsActive',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_usesExternalPlaybackWhileExternalScreenIsActive);
  }

  /// setUsesExternalPlaybackWhileExternalScreenIsActive:
  set usesExternalPlaybackWhileExternalScreenIsActive(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setUsesExternalPlaybackWhileExternalScreenIsActive:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setUsesExternalPlaybackWhileExternalScreenIsActive_, value);
  }

  /// externalPlaybackVideoGravity
  objc.NSString get externalPlaybackVideoGravity {
    objc.checkOsVersionInternal('AVPlayer.externalPlaybackVideoGravity', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_externalPlaybackVideoGravity);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setExternalPlaybackVideoGravity:
  set externalPlaybackVideoGravity(objc.NSString value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setExternalPlaybackVideoGravity:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setExternalPlaybackVideoGravity_, value.ref.pointer);
  }
}

late final _sel_outputObscuredDueToInsufficientExternalProtection = objc.registerName(
  "outputObscuredDueToInsufficientExternalProtection",
);

/// AVPlayerProtectedContent
extension AVPlayerProtectedContent on AVPlayer {
  /// !
  /// @property outputObscuredDueToInsufficientExternalProtection
  /// @abstract
  /// Whether or not decoded output is being obscured due to insufficient external protection.
  ///
  /// @discussion
  /// The value of this property indicates whether the player is purposefully obscuring the visual output
  /// of the current item because the requirement for an external protection mechanism is not met by the
  /// current device configuration. It is highly recommended that clients whose content requires external
  /// protection observe this property and set the playback rate to zero and display an appropriate user
  /// interface when the value changes to YES. This property is key value observable.
  ///
  /// Note that the value of this property is dependent on the external protection requirements of the
  /// current item. These requirements are inherent to the content itself and cannot be externally specified.
  /// If the current item does not require external protection, the value of this property will be NO.
  bool get outputObscuredDueToInsufficientExternalProtection {
    objc.checkOsVersionInternal(
      'AVPlayer.outputObscuredDueToInsufficientExternalProtection',
      iOS: (false, (6, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_outputObscuredDueToInsufficientExternalProtection);
  }
}

/// !
/// @typedef AVPlayerHDRMode
/// @abstract  A bitfield type that specifies an HDR mode.
///
/// @constant	AVPlayerHDRModeHLG
/// @abstract	Indicates that HLG (Hybrid Log-Gamma) HDR mode is available.
/// @constant	AVPlayerHDRModeHDR10
/// @abstract	Indicates that HDR10 HDR mode is available.
/// @constant	AVPlayerHDRModeDolbyVision
/// @abstract	Indicates that Dolby Vision HDR mode is available.
enum AVPlayerHDRMode {
  AVPlayerHDRModeHLG(1),
  AVPlayerHDRModeHDR10(2),
  AVPlayerHDRModeDolbyVision(4);

  final int value;
  const AVPlayerHDRMode(this.value);

  static AVPlayerHDRMode fromValue(int value) => switch (value) {
    1 => AVPlayerHDRModeHLG,
    2 => AVPlayerHDRModeHDR10,
    4 => AVPlayerHDRModeDolbyVision,
    _ => throw ArgumentError('Unknown value for AVPlayerHDRMode: $value'),
  };
}

late final _sel_availableHDRModes = objc.registerName("availableHDRModes");
final _objc_msgSend_fttnwg = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_eligibleForHDRPlayback = objc.registerName("eligibleForHDRPlayback");

/// AVPlayerPlaybackCapabilities
extension AVPlayerPlaybackCapabilities on AVPlayer {
  /// !
  /// @property		availableHDRModes
  /// @abstract		An AVPlayerHDRMode value that indicates the HDR modes the device can play to an appropriate display.   A value of 0 indicates that no HDR modes are supported.
  ///
  /// @discussion
  /// This property indicates all of the HDR modes that the device can play.  Each value indicates that an appropriate HDR display is available for the specified HDR mode.  Additionally, the device must be capable of playing the specified HDR type.  This property does not indicate whether video contains HDR content, whether HDR video is currently playing, or whether video is playing on an HDR display.
  static AVPlayerHDRMode getAvailableHDRModes() {
    objc.checkOsVersionInternal('AVPlayer.availableHDRModes', iOS: (false, (11, 2, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_fttnwg(_class_AVPlayer, _sel_availableHDRModes);
    return AVPlayerHDRMode.fromValue(_ret);
  }

  /// !
  /// @property		eligibleForHDRPlayback
  /// @abstract		Indicates whether HDR content can be played to an appropriate display.
  ///
  /// @discussion
  /// This property is YES if an HDR display is available and the device is capable of playing HDR content from an appropriate AVAsset, NO otherwise.  This property does not indicate whether video contains HDR content, whether HDR video is currently playing, or whether video is playing on an HDR display.  This property is not KVO observable.
  static bool getEligibleForHDRPlayback() {
    objc.checkOsVersionInternal(
      'AVPlayer.eligibleForHDRPlayback',
      iOS: (false, (13, 4, 0)),
      macOS: (false, (10, 15, 0)),
    );
    return _objc_msgSend_91o635(_class_AVPlayer, _sel_eligibleForHDRPlayback);
  }
}

late final _sel_preferredVideoDecoderGPURegistryID = objc.registerName("preferredVideoDecoderGPURegistryID");
final _objc_msgSend_9qbz9w = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Uint64 Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPreferredVideoDecoderGPURegistryID_ = objc.registerName("setPreferredVideoDecoderGPURegistryID:");
final _objc_msgSend_1xsl7ae = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Uint64)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerVideoDecoderGPUSupport
extension AVPlayerVideoDecoderGPUSupport on AVPlayer {
  /// !
  /// @property		preferredVideoDecoderGPURegistryID
  /// @abstract		Specifies a registryID associated with a GPU that should be used for video decode.
  ///
  /// @discussion
  /// By default, whenever possible, video decode will be performed on the GPU associated with the display on which the presenting CALayer is located.  Decode will be transitioned to a new GPU if appropriate when the CALayer moves to a new display.  This property overrides this default behavior, forcing decode to prefer an affinity to the GPU specified regardless of which GPU is being used to display the associated CALayer.
  ///
  /// The GPU registryID can be obtained from the GPU MTLDevice using [MTLDevice registryID] or can be obtained from OpenGL or OpenCL.
  int get preferredVideoDecoderGPURegistryID {
    objc.checkOsVersionInternal(
      'AVPlayer.preferredVideoDecoderGPURegistryID',
      iOS: (true, null),
      macOS: (false, (10, 13, 0)),
    );
    return _objc_msgSend_9qbz9w(this.ref.pointer, _sel_preferredVideoDecoderGPURegistryID);
  }

  /// !
  /// @property		preferredVideoDecoderGPURegistryID
  /// @abstract		Specifies a registryID associated with a GPU that should be used for video decode.
  ///
  /// @discussion
  /// By default, whenever possible, video decode will be performed on the GPU associated with the display on which the presenting CALayer is located.  Decode will be transitioned to a new GPU if appropriate when the CALayer moves to a new display.  This property overrides this default behavior, forcing decode to prefer an affinity to the GPU specified regardless of which GPU is being used to display the associated CALayer.
  ///
  /// The GPU registryID can be obtained from the GPU MTLDevice using [MTLDevice registryID] or can be obtained from OpenGL or OpenCL.
  set preferredVideoDecoderGPURegistryID(int value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreferredVideoDecoderGPURegistryID:',
      iOS: (true, null),
      macOS: (false, (10, 13, 0)),
    );
    _objc_msgSend_1xsl7ae(this.ref.pointer, _sel_setPreferredVideoDecoderGPURegistryID_, value);
  }
}

late final _sel_preventsDisplaySleepDuringVideoPlayback = objc.registerName("preventsDisplaySleepDuringVideoPlayback");
late final _sel_setPreventsDisplaySleepDuringVideoPlayback_ = objc.registerName(
  "setPreventsDisplaySleepDuringVideoPlayback:",
);

/// AVPlayerVideoDisplaySleepPrevention
extension AVPlayerVideoDisplaySleepPrevention on AVPlayer {
  /// !
  /// @property   preventsDisplaySleepDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents display and device sleep.
  /// @discussion
  /// Default is YES on iOS, tvOS and in Mac Catalyst apps.  Default is NO on macOS.
  /// Setting this property to NO does not force the display to sleep, it simply stops preventing display sleep.  Other apps or frameworks within your app may still be preventing display sleep for various reasons.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  bool get preventsDisplaySleepDuringVideoPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.preventsDisplaySleepDuringVideoPlayback',
      iOS: (false, (12, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_preventsDisplaySleepDuringVideoPlayback);
  }

  /// !
  /// @property   preventsDisplaySleepDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents display and device sleep.
  /// @discussion
  /// Default is YES on iOS, tvOS and in Mac Catalyst apps.  Default is NO on macOS.
  /// Setting this property to NO does not force the display to sleep, it simply stops preventing display sleep.  Other apps or frameworks within your app may still be preventing display sleep for various reasons.
  ///
  /// Before macOS 13, iOS 16, tvOS 16, and watchOS 9, this property must be accessed on the main thread/queue.
  set preventsDisplaySleepDuringVideoPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreventsDisplaySleepDuringVideoPlayback:',
      iOS: (false, (12, 0, 0)),
      macOS: (false, (10, 14, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setPreventsDisplaySleepDuringVideoPlayback_, value);
  }
}

late final _sel_preventsAutomaticBackgroundingDuringVideoPlayback = objc.registerName(
  "preventsAutomaticBackgroundingDuringVideoPlayback",
);
late final _sel_setPreventsAutomaticBackgroundingDuringVideoPlayback_ = objc.registerName(
  "setPreventsAutomaticBackgroundingDuringVideoPlayback:",
);

/// AVPlayerAutomaticBackgroundPrevention
extension AVPlayerAutomaticBackgroundPrevention on AVPlayer {
  /// !
  /// @property   preventsAutomaticBackgroundingDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents the app from automatically getting backgrounded.
  /// @discussion
  /// Default value is YES.
  /// Setting this property to YES prevents an application that is playing video from automatically getting backgrounded.  This property does not prevent the user from backgrounding the application.
  bool get preventsAutomaticBackgroundingDuringVideoPlayback {
    objc.checkOsVersionInternal(
      'AVPlayer.preventsAutomaticBackgroundingDuringVideoPlayback',
      iOS: (true, null),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_preventsAutomaticBackgroundingDuringVideoPlayback);
  }

  /// !
  /// @property   preventsAutomaticBackgroundingDuringVideoPlayback
  /// @abstract   Indicates whether video playback prevents the app from automatically getting backgrounded.
  /// @discussion
  /// Default value is YES.
  /// Setting this property to YES prevents an application that is playing video from automatically getting backgrounded.  This property does not prevent the user from backgrounding the application.
  set preventsAutomaticBackgroundingDuringVideoPlayback(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setPreventsAutomaticBackgroundingDuringVideoPlayback:',
      iOS: (true, null),
      macOS: (true, null),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setPreventsAutomaticBackgroundingDuringVideoPlayback_, value);
  }
}

/// !
/// @typedef AVPlayerAudiovisualBackgroundPlaybackPolicy
/// @discussion This policy describes how AVPlayer behaves when the application transitions to UIApplicationStateBackground while playing video.
///
/// @constant	AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic
/// Indicates that the system is free to decide. This is the default policy.
///
/// @constant  AVPlayerAudiovisualBackgroundPlaybackPolicyPauses
/// Indicates that the player must be paused on going to background.
///
/// @constant	AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible
/// Indicates that the player continues to play if possible in background.
enum AVPlayerAudiovisualBackgroundPlaybackPolicy {
  AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic(1),
  AVPlayerAudiovisualBackgroundPlaybackPolicyPauses(2),
  AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible(3);

  final int value;
  const AVPlayerAudiovisualBackgroundPlaybackPolicy(this.value);

  static AVPlayerAudiovisualBackgroundPlaybackPolicy fromValue(int value) => switch (value) {
    1 => AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic,
    2 => AVPlayerAudiovisualBackgroundPlaybackPolicyPauses,
    3 => AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible,
    _ => throw ArgumentError('Unknown value for AVPlayerAudiovisualBackgroundPlaybackPolicy: $value'),
  };
}

late final _sel_audiovisualBackgroundPlaybackPolicy = objc.registerName("audiovisualBackgroundPlaybackPolicy");
final _objc_msgSend_zjfuws = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setAudiovisualBackgroundPlaybackPolicy_ = objc.registerName("setAudiovisualBackgroundPlaybackPolicy:");
final _objc_msgSend_1e0eiei = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// AVPlayerBackgroundSupport
extension AVPlayerBackgroundSupport on AVPlayer {
  /// !
  /// @property   audiovisualBackgroundPlaybackPolicy
  /// @abstract   Controls the policy to be used in deciding how playback of audiovisual content should continue while the application transitions to background.
  /// @discussion By default, the system is free to decide the background playback policy (AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic).
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyPauses, player will be paused on entering background.
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible, the system makes the best effort to continue playback but the app also needs appropriate UIBackgroundModes for the system to let it continue running in the background. Note that this policy only applies to items with enabled video.
  AVPlayerAudiovisualBackgroundPlaybackPolicy get audiovisualBackgroundPlaybackPolicy {
    objc.checkOsVersionInternal(
      'AVPlayer.audiovisualBackgroundPlaybackPolicy',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    final _ret = _objc_msgSend_zjfuws(this.ref.pointer, _sel_audiovisualBackgroundPlaybackPolicy);
    return AVPlayerAudiovisualBackgroundPlaybackPolicy.fromValue(_ret);
  }

  /// !
  /// @property   audiovisualBackgroundPlaybackPolicy
  /// @abstract   Controls the policy to be used in deciding how playback of audiovisual content should continue while the application transitions to background.
  /// @discussion By default, the system is free to decide the background playback policy (AVPlayerAudiovisualBackgroundPlaybackPolicyAutomatic).
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyPauses, player will be paused on entering background.
  /// If set to AVPlayerAudiovisualBackgroundPlaybackPolicyContinuesIfPossible, the system makes the best effort to continue playback but the app also needs appropriate UIBackgroundModes for the system to let it continue running in the background. Note that this policy only applies to items with enabled video.
  set audiovisualBackgroundPlaybackPolicy(AVPlayerAudiovisualBackgroundPlaybackPolicy value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setAudiovisualBackgroundPlaybackPolicy:',
      iOS: (false, (15, 0, 0)),
      macOS: (false, (12, 0, 0)),
    );
    _objc_msgSend_1e0eiei(this.ref.pointer, _sel_setAudiovisualBackgroundPlaybackPolicy_, value.value);
  }
}

/// WARNING: AVPlayerPlaybackCoordinator is a stub. To generate bindings for this class, include
/// AVPlayerPlaybackCoordinator in your config's objc-interfaces list.
///
/// AVPlayerPlaybackCoordinator
class AVPlayerPlaybackCoordinator extends objc.ObjCObjectBase {
  AVPlayerPlaybackCoordinator._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerPlaybackCoordinator] that points to the same underlying object as [other].
  AVPlayerPlaybackCoordinator.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerPlaybackCoordinator] that wraps the given raw object pointer.
  AVPlayerPlaybackCoordinator.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_playbackCoordinator = objc.registerName("playbackCoordinator");

/// PlaybackCoordination
extension PlaybackCoordination on AVPlayer {
  /// @property playbackCoordinator
  /// @abstract The playback coordinator for this player.
  /// @discussion If the playback coordinator is connected to other participants, rate changes and seeks on the current item will be automatically mirrored to all connected participants.
  /// Depending on policies, the coordinatormay also intercept rate changes to non-zero to coordinate playback start with the rest of the group.
  /// Use [AVPlayer playImmediatelyAtRate:] to override the coordinated startup behavior and start playback immediately. This is useful to give users an opportunity to override waiting caused by other participants' suspensions.
  /// Player configuration other than rate and seeks are not communicated to other participants and can be configured independently by each participant.
  /// A player with a connected playbackCoordinator will change behavior in situations that require the player to pause for internal reasons, such as a route change or a stall.
  /// When resuming after these events, the player will not resume at the stop time. Instead, it will attempt to rejoin the group, potentially seeking to match the other participant's progress.
  /// It is left to the owner of the AVPlayer to ensure that all participants are playing the same item. See the discussion of AVPlaybackCoordinator for considerations about item transitions.
  AVPlayerPlaybackCoordinator get playbackCoordinator {
    objc.checkOsVersionInternal('AVPlayer.playbackCoordinator', iOS: (false, (15, 0, 0)), macOS: (false, (12, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_playbackCoordinator);
    return AVPlayerPlaybackCoordinator.castFromPointer(_ret, retain: true, release: true);
  }
}

/// WARNING: AVPlayerVideoOutput is a stub. To generate bindings for this class, include
/// AVPlayerVideoOutput in your config's objc-interfaces list.
///
/// AVPlayerVideoOutput
class AVPlayerVideoOutput extends objc.ObjCObjectBase {
  AVPlayerVideoOutput._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVPlayerVideoOutput] that points to the same underlying object as [other].
  AVPlayerVideoOutput.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayerVideoOutput] that wraps the given raw object pointer.
  AVPlayerVideoOutput.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_videoOutput = objc.registerName("videoOutput");
late final _sel_setVideoOutput_ = objc.registerName("setVideoOutput:");

/// AVPlayerOutputSupport
extension AVPlayerOutputSupport on AVPlayer {
  /// !
  /// @property	videoOutput
  /// @abstract	The video output for this player, if one was set.
  /// @discussion When an AVPlayerVideoOutput is associated with an AVPlayer, the AVPlayerVideoOutput can then be used to receive video-related samples during playback.
  /// @note		If an output is set while AVPlayer has a current item it may cause different data channels to be selected for that item, which can have a performance impact.
  /// As a result, when possible, it is best to set an output before setting items on an AVPlayer.
  AVPlayerVideoOutput? get videoOutput {
    objc.checkOsVersionInternal('AVPlayer.videoOutput', iOS: (false, (17, 2, 0)), macOS: (false, (14, 2, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_videoOutput);
    return _ret.address == 0 ? null : AVPlayerVideoOutput.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @property	videoOutput
  /// @abstract	The video output for this player, if one was set.
  /// @discussion When an AVPlayerVideoOutput is associated with an AVPlayer, the AVPlayerVideoOutput can then be used to receive video-related samples during playback.
  /// @note		If an output is set while AVPlayer has a current item it may cause different data channels to be selected for that item, which can have a performance impact.
  /// As a result, when possible, it is best to set an output before setting items on an AVPlayer.
  set videoOutput(AVPlayerVideoOutput? value) {
    objc.checkOsVersionInternal('AVPlayer.setVideoOutput:', iOS: (false, (17, 2, 0)), macOS: (false, (14, 2, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setVideoOutput_, value?.ref.pointer ?? ffi.nullptr);
  }
}

late final _sel_isClosedCaptionDisplayEnabled = objc.registerName("isClosedCaptionDisplayEnabled");
late final _sel_setClosedCaptionDisplayEnabled_ = objc.registerName("setClosedCaptionDisplayEnabled:");
late final _sel_masterClock = objc.registerName("masterClock");
late final _sel_setMasterClock_ = objc.registerName("setMasterClock:");

/// AVPlayerDeprecated
extension AVPlayerDeprecated on AVPlayer {
  /// !
  /// @property closedCaptionDisplayEnabled
  /// @abstract
  /// Indicates whether display of closed captions is enabled.
  ///
  /// @discussion
  /// This property is deprecated.
  ///
  /// When the value of appliesMediaSelectionCriteriaAutomatically is YES, the receiver will enable closed captions automatically either according to user preferences or, if you provide them, according to AVPlayerMediaSelectionCriteria for the media characteristic AVMediaCharacteristicLegible.
  ///
  /// If you want to determine whether closed captions may be available for a given AVPlayerItem, you can examine the AVMediaSelectionOptions in the AVMediaSelectionGroup for the characteristic AVMediaCharacteristicLegible, as vended by -[AVAsset mediaSelectionGroupForMediaCharacteristic:]. See AVMediaCharacteristicTranscribesSpokenDialogForAccessibility and AVMediaCharacteristicDescribesMusicAndSoundForAccessibility as documented in AVMediaFormat.h for information about how to identify legible media selection options that offer the features of closed captions for accessibility purposes.
  ///
  /// You can select or deselect a specific AVMediaSelectionOption via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// For further information about Media Accessibility preferences, see MediaAccessibility framework documentation.
  bool get closedCaptionDisplayEnabled {
    objc.checkOsVersionInternal(
      'AVPlayer.isClosedCaptionDisplayEnabled',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isClosedCaptionDisplayEnabled);
  }

  /// !
  /// @property closedCaptionDisplayEnabled
  /// @abstract
  /// Indicates whether display of closed captions is enabled.
  ///
  /// @discussion
  /// This property is deprecated.
  ///
  /// When the value of appliesMediaSelectionCriteriaAutomatically is YES, the receiver will enable closed captions automatically either according to user preferences or, if you provide them, according to AVPlayerMediaSelectionCriteria for the media characteristic AVMediaCharacteristicLegible.
  ///
  /// If you want to determine whether closed captions may be available for a given AVPlayerItem, you can examine the AVMediaSelectionOptions in the AVMediaSelectionGroup for the characteristic AVMediaCharacteristicLegible, as vended by -[AVAsset mediaSelectionGroupForMediaCharacteristic:]. See AVMediaCharacteristicTranscribesSpokenDialogForAccessibility and AVMediaCharacteristicDescribesMusicAndSoundForAccessibility as documented in AVMediaFormat.h for information about how to identify legible media selection options that offer the features of closed captions for accessibility purposes.
  ///
  /// You can select or deselect a specific AVMediaSelectionOption via -[AVPlayerItem selectMediaOption:inMediaSelectionGroup:].
  ///
  /// For further information about Media Accessibility preferences, see MediaAccessibility framework documentation.
  set closedCaptionDisplayEnabled(bool value) {
    objc.checkOsVersionInternal(
      'AVPlayer.setClosedCaptionDisplayEnabled:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setClosedCaptionDisplayEnabled_, value);
  }

  /// masterClock
  ffi.Pointer<OpaqueCMClock> get masterClock {
    objc.checkOsVersionInternal('AVPlayer.masterClock', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_1lamzyt(this.ref.pointer, _sel_masterClock);
  }

  /// setMasterClock:
  set masterClock(ffi.Pointer<OpaqueCMClock> value) {
    objc.checkOsVersionInternal('AVPlayer.setMasterClock:', iOS: (false, (6, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_1samav9(this.ref.pointer, _sel_setMasterClock_, value);
  }
}

late final _sel_playerWithURL_ = objc.registerName("playerWithURL:");
late final _sel_playerWithPlayerItem_ = objc.registerName("playerWithPlayerItem:");
late final _sel_initWithPlayerItem_ = objc.registerName("initWithPlayerItem:");
final _objc_msgSend_cou425 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVPlayer
class AVPlayer extends objc.NSObject {
  AVPlayer._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVPlayer', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVPlayer] that points to the same underlying object as [other].
  AVPlayer.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVPlayer] that wraps the given raw object pointer.
  AVPlayer.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVPlayer].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVPlayer);
  }

  /// init
  AVPlayer init() {
    objc.checkOsVersionInternal('AVPlayer.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			playerWithURL:
  /// @abstract		Returns an instance of AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  static AVPlayer playerWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayer.playerWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayer, _sel_playerWithURL_, URL.ref.pointer);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			playerWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  static AVPlayer playerWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal('AVPlayer.playerWithPlayerItem:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVPlayer, _sel_playerWithPlayerItem_, item?.ref.pointer ?? ffi.nullptr);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			initWithURL:
  /// @abstract		Initializes an AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  AVPlayer initWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVPlayer.initWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithURL_, URL.ref.pointer);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			initWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  /// This method throws an exception if the item is not an AVPlayerItem, or if the item is
  /// associated with another AVPlayer.
  AVPlayer initWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal('AVPlayer.initWithPlayerItem:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithPlayerItem_,
      item?.ref.pointer ?? ffi.nullptr,
    );
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @property status
  /// @abstract
  /// The ability of the receiver to be used for playback.
  ///
  /// @discussion
  /// The value of this property is an AVPlayerStatus that indicates whether the receiver can be used for playback. When
  /// the value of this property is AVPlayerStatusFailed, the receiver can no longer be used for playback and a new
  /// instance needs to be created in its place. When this happens, clients can check the value of the error property to
  /// determine the nature of the failure. This property is key value observable.
  AVPlayerStatus get status {
    objc.checkOsVersionInternal('AVPlayer.status', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_cou425(this.ref.pointer, _sel_status);
    return AVPlayerStatus.fromValue(_ret);
  }

  /// !
  /// @property error
  /// @abstract
  /// If the receiver's status is AVPlayerStatusFailed, this describes the error that caused the failure.
  ///
  /// @discussion
  /// The value of this property is an NSError that describes what caused the receiver to no longer be able to play items.
  /// If the receiver's status is not AVPlayerStatusFailed, the value of this property is nil.
  objc.NSError? get error {
    objc.checkOsVersionInternal('AVPlayer.error', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_error);
    return _ret.address == 0 ? null : objc.NSError.castFromPointer(_ret, retain: true, release: true);
  }

  /// new
  static AVPlayer new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayer, _sel_new);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVPlayer allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVPlayer, _sel_allocWithZone_, zone);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVPlayer alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVPlayer, _sel_alloc);
    return AVPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVPlayer self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVPlayer retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVPlayer autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVPlayer constructed with the default `new` method.
  factory AVPlayer() => new$();
}

late final _class_AVQueuePlayer = objc.getClass("AVQueuePlayer");
late final _sel_queuePlayerWithItems_ = objc.registerName("queuePlayerWithItems:");
late final _sel_initWithItems_ = objc.registerName("initWithItems:");
late final _sel_items = objc.registerName("items");
late final _sel_advanceToNextItem = objc.registerName("advanceToNextItem");
late final _sel_canInsertItem_afterItem_ = objc.registerName("canInsertItem:afterItem:");
final _objc_msgSend_1lsax7n = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_insertItem_afterItem_ = objc.registerName("insertItem:afterItem:");
late final _sel_removeItem_ = objc.registerName("removeItem:");
late final _sel_removeAllItems = objc.registerName("removeAllItems");

/// AVQueuePlayer
class AVQueuePlayer extends AVPlayer {
  AVQueuePlayer._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVQueuePlayer', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVQueuePlayer] that points to the same underlying object as [other].
  AVQueuePlayer.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVQueuePlayer] that wraps the given raw object pointer.
  AVQueuePlayer.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVQueuePlayer].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVQueuePlayer);
  }

  /// !
  /// @method     queuePlayerWithItems:
  /// @abstract   Creates an instance of AVQueuePlayer and enqueues the AVPlayerItems from the specified array.
  /// @param      items
  /// An NSArray of AVPlayerItems with which to populate the player's queue initially.
  /// @result
  /// An instance of AVQueuePlayer.
  static AVQueuePlayer queuePlayerWithItems(objc.NSArray items) {
    objc.checkOsVersionInternal(
      'AVQueuePlayer.queuePlayerWithItems:',
      iOS: (false, (4, 1, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(_class_AVQueuePlayer, _sel_queuePlayerWithItems_, items.ref.pointer);
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method     initWithItems:
  /// @abstract   Initializes an instance of AVQueuePlayer by enqueueing the AVPlayerItems from the specified array.
  /// @param      items
  /// An NSArray of AVPlayerItems with which to populate the player's queue initially.
  /// @result
  /// An instance of AVQueuePlayer.
  /// @discussion
  /// This method throws an exception if items contains duplicated values or values associated with another AVPlayer.
  AVQueuePlayer initWithItems(objc.NSArray items) {
    objc.checkOsVersionInternal('AVQueuePlayer.initWithItems:', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithItems_, items.ref.pointer);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method     items
  /// @abstract   Provides an array of the currently enqueued items.
  /// @result     An NSArray containing the enqueued AVPlayerItems.
  objc.NSArray items() {
    objc.checkOsVersionInternal('AVQueuePlayer.items', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_items);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method     advanceToNextItem
  /// @abstract   Ends playback of the current item and initiates playback of the next item in the player's queue.
  /// @discussion Removes the current item from the play queue.
  void advanceToNextItem() {
    objc.checkOsVersionInternal('AVQueuePlayer.advanceToNextItem', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_advanceToNextItem);
  }

  /// !
  /// @method     canInsertItem:afterItem:
  /// @abstract   Tests whether an AVPlayerItem can be inserted into the player's queue.
  /// @param      item
  /// The AVPlayerItem to be tested.
  /// @param      afterItem
  /// The item that the item to be tested is to follow in the queue. Pass nil to test whether the item can be appended to the queue.
  /// @result
  /// An indication of whether the item can be inserted into the queue after the specified item.
  /// @discussion
  /// Note that adding the same AVPlayerItem to an AVQueuePlayer at more than one position in the queue is not supported.
  bool canInsertItem(AVPlayerItem item, {AVPlayerItem? afterItem}) {
    objc.checkOsVersionInternal(
      'AVQueuePlayer.canInsertItem:afterItem:',
      iOS: (false, (4, 1, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return _objc_msgSend_1lsax7n(
      this.ref.pointer,
      _sel_canInsertItem_afterItem_,
      item.ref.pointer,
      afterItem?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method     insertItem:afterItem:
  /// @abstract   Places an AVPlayerItem after the specified item in the queue.
  /// @param      item
  /// The item to be inserted.
  /// @param      afterItem
  /// The item that the newly inserted item should follow in the queue. Pass nil to append the item to the queue.
  /// @discussion
  /// This method throws an exception if item already exists in the queue.
  void insertItem(AVPlayerItem item, {AVPlayerItem? afterItem}) {
    objc.checkOsVersionInternal(
      'AVQueuePlayer.insertItem:afterItem:',
      iOS: (false, (4, 1, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_pfv6jd(
      this.ref.pointer,
      _sel_insertItem_afterItem_,
      item.ref.pointer,
      afterItem?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// !
  /// @method     removeItem:
  /// @abstract   Removes an AVPlayerItem from the queue.
  /// @param      item
  /// The item to be removed.
  /// @discussion
  /// If the item to be removed is currently playing, has the same effect as -advanceToNextItem.
  void removeItem(AVPlayerItem item) {
    objc.checkOsVersionInternal('AVQueuePlayer.removeItem:', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeItem_, item.ref.pointer);
  }

  /// !
  /// @method     removeAllItems
  /// @abstract   Removes all items from the queue.
  /// @discussion Stops playback by the target.
  void removeAllItems() {
    objc.checkOsVersionInternal('AVQueuePlayer.removeAllItems', iOS: (false, (4, 1, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_removeAllItems);
  }

  /// init
  AVQueuePlayer init() {
    objc.checkOsVersionInternal('AVQueuePlayer.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			playerWithURL:
  /// @abstract		Returns an instance of AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  static AVQueuePlayer playerWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVQueuePlayer.playerWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(_class_AVQueuePlayer, _sel_playerWithURL_, URL.ref.pointer);
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			playerWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  static AVQueuePlayer playerWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal(
      'AVQueuePlayer.playerWithPlayerItem:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      _class_AVQueuePlayer,
      _sel_playerWithPlayerItem_,
      item?.ref.pointer ?? ffi.nullptr,
    );
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// !
  /// @method			initWithURL:
  /// @abstract		Initializes an AVPlayer that plays a single audiovisual resource referenced by URL.
  /// @param			URL
  /// @result			An instance of AVPlayer
  /// @discussion		Implicitly creates an AVPlayerItem. Clients can obtain the AVPlayerItem as it becomes the player's currentItem.
  AVQueuePlayer initWithURL(objc.NSURL URL) {
    objc.checkOsVersionInternal('AVQueuePlayer.initWithURL:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithURL_, URL.ref.pointer);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// !
  /// @method			initWithPlayerItem:
  /// @abstract		Create an AVPlayer that plays a single audiovisual item.
  /// @param			item
  /// @result			An instance of AVPlayer
  /// @discussion		Useful in order to play items for which an AVAsset has previously been created. See -[AVPlayerItem initWithAsset:].
  /// This method throws an exception if the item is not an AVPlayerItem, or if the item is
  /// associated with another AVPlayer.
  AVQueuePlayer initWithPlayerItem(AVPlayerItem? item) {
    objc.checkOsVersionInternal(
      'AVQueuePlayer.initWithPlayerItem:',
      iOS: (false, (4, 0, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithPlayerItem_,
      item?.ref.pointer ?? ffi.nullptr,
    );
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVQueuePlayer new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVQueuePlayer, _sel_new);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVQueuePlayer allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVQueuePlayer, _sel_allocWithZone_, zone);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVQueuePlayer alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVQueuePlayer, _sel_alloc);
    return AVQueuePlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVQueuePlayer self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVQueuePlayer retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVQueuePlayer autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVQueuePlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVQueuePlayer constructed with the default `new` method.
  factory AVQueuePlayer() => new$();
}

enum AVAudioCommonFormat {
  AVAudioOtherFormat(0),
  AVAudioPCMFormatFloat32(1),
  AVAudioPCMFormatFloat64(2),
  AVAudioPCMFormatInt16(3),
  AVAudioPCMFormatInt32(4);

  final int value;
  const AVAudioCommonFormat(this.value);

  static AVAudioCommonFormat fromValue(int value) => switch (value) {
    0 => AVAudioOtherFormat,
    1 => AVAudioPCMFormatFloat32,
    2 => AVAudioPCMFormatFloat64,
    3 => AVAudioPCMFormatInt16,
    4 => AVAudioPCMFormatInt32,
    _ => throw ArgumentError('Unknown value for AVAudioCommonFormat: $value'),
  };
}

/// WARNING: AVAudioFormat is a stub. To generate bindings for this class, include
/// AVAudioFormat in your config's objc-interfaces list.
///
/// AVAudioFormat
class AVAudioFormat extends objc.NSObject implements objc.NSSecureCoding {
  AVAudioFormat._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioFormat', iOS: (false, (8, 0, 0)), macOS: (false, (10, 10, 0)));
  }

  /// Constructs a [AVAudioFormat] that points to the same underlying object as [other].
  AVAudioFormat.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioFormat] that wraps the given raw object pointer.
  AVAudioFormat.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

enum AVAudioSessionActivationOptions {
  AVAudioSessionActivationOptionNone(0);

  final int value;
  const AVAudioSessionActivationOptions(this.value);

  static AVAudioSessionActivationOptions fromValue(int value) => switch (value) {
    0 => AVAudioSessionActivationOptionNone,
    _ => throw ArgumentError('Unknown value for AVAudioSessionActivationOptions: $value'),
  };
}

enum AVAudioSessionPortOverride {
  AVAudioSessionPortOverrideNone(0),
  AVAudioSessionPortOverrideSpeaker(1936747378);

  final int value;
  const AVAudioSessionPortOverride(this.value);

  static AVAudioSessionPortOverride fromValue(int value) => switch (value) {
    0 => AVAudioSessionPortOverrideNone,
    1936747378 => AVAudioSessionPortOverrideSpeaker,
    _ => throw ArgumentError('Unknown value for AVAudioSessionPortOverride: $value'),
  };
}

enum AVAudioSessionCategoryOptions {
  AVAudioSessionCategoryOptionMixWithOthers(1),
  AVAudioSessionCategoryOptionDuckOthers(2),
  AVAudioSessionCategoryOptionAllowBluetooth(4),
  AVAudioSessionCategoryOptionDefaultToSpeaker(8),
  AVAudioSessionCategoryOptionInterruptSpokenAudioAndMixWithOthers(17),
  AVAudioSessionCategoryOptionAllowBluetoothA2DP(32),
  AVAudioSessionCategoryOptionAllowAirPlay(64),
  AVAudioSessionCategoryOptionOverrideMutedMicrophoneInterruption(128);

  final int value;
  const AVAudioSessionCategoryOptions(this.value);

  static AVAudioSessionCategoryOptions fromValue(int value) => switch (value) {
    1 => AVAudioSessionCategoryOptionMixWithOthers,
    2 => AVAudioSessionCategoryOptionDuckOthers,
    4 => AVAudioSessionCategoryOptionAllowBluetooth,
    8 => AVAudioSessionCategoryOptionDefaultToSpeaker,
    17 => AVAudioSessionCategoryOptionInterruptSpokenAudioAndMixWithOthers,
    32 => AVAudioSessionCategoryOptionAllowBluetoothA2DP,
    64 => AVAudioSessionCategoryOptionAllowAirPlay,
    128 => AVAudioSessionCategoryOptionOverrideMutedMicrophoneInterruption,
    _ => throw ArgumentError('Unknown value for AVAudioSessionCategoryOptions: $value'),
  };
}

enum AVAudioSessionSetActiveOptions {
  AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation(1);

  final int value;
  const AVAudioSessionSetActiveOptions(this.value);

  static AVAudioSessionSetActiveOptions fromValue(int value) => switch (value) {
    1 => AVAudioSessionSetActiveOptionNotifyOthersOnDeactivation,
    _ => throw ArgumentError('Unknown value for AVAudioSessionSetActiveOptions: $value'),
  };
}

enum AVAudioSessionIOType {
  AVAudioSessionIOTypeNotSpecified(0),
  AVAudioSessionIOTypeAggregated(1);

  final int value;
  const AVAudioSessionIOType(this.value);

  static AVAudioSessionIOType fromValue(int value) => switch (value) {
    0 => AVAudioSessionIOTypeNotSpecified,
    1 => AVAudioSessionIOTypeAggregated,
    _ => throw ArgumentError('Unknown value for AVAudioSessionIOType: $value'),
  };
}

enum AVAudioSessionRouteSharingPolicy {
  AVAudioSessionRouteSharingPolicyDefault(0),
  AVAudioSessionRouteSharingPolicyLongFormAudio(1),
  AVAudioSessionRouteSharingPolicyIndependent(2),
  AVAudioSessionRouteSharingPolicyLongFormVideo(3);

  static const AVAudioSessionRouteSharingPolicyLongForm = AVAudioSessionRouteSharingPolicyLongFormAudio;

  final int value;
  const AVAudioSessionRouteSharingPolicy(this.value);

  static AVAudioSessionRouteSharingPolicy fromValue(int value) => switch (value) {
    0 => AVAudioSessionRouteSharingPolicyDefault,
    1 => AVAudioSessionRouteSharingPolicyLongFormAudio,
    2 => AVAudioSessionRouteSharingPolicyIndependent,
    3 => AVAudioSessionRouteSharingPolicyLongFormVideo,
    _ => throw ArgumentError('Unknown value for AVAudioSessionRouteSharingPolicy: $value'),
  };

  @override
  String toString() {
    if (this == AVAudioSessionRouteSharingPolicyLongFormAudio)
      return "AVAudioSessionRouteSharingPolicy.AVAudioSessionRouteSharingPolicyLongFormAudio, AVAudioSessionRouteSharingPolicy.AVAudioSessionRouteSharingPolicyLongForm";
    return super.toString();
  }
}

enum AVAudioSessionPromptStyle {
  AVAudioSessionPromptStyleNone(1852796517),
  AVAudioSessionPromptStyleShort(1936224884),
  AVAudioSessionPromptStyleNormal(1852992876);

  final int value;
  const AVAudioSessionPromptStyle(this.value);

  static AVAudioSessionPromptStyle fromValue(int value) => switch (value) {
    1852796517 => AVAudioSessionPromptStyleNone,
    1936224884 => AVAudioSessionPromptStyleShort,
    1852992876 => AVAudioSessionPromptStyleNormal,
    _ => throw ArgumentError('Unknown value for AVAudioSessionPromptStyle: $value'),
  };
}

enum AVAudioStereoOrientation {
  AVAudioStereoOrientationNone(0),
  AVAudioStereoOrientationPortrait(1),
  AVAudioStereoOrientationPortraitUpsideDown(2),
  AVAudioStereoOrientationLandscapeRight(3),
  AVAudioStereoOrientationLandscapeLeft(4);

  final int value;
  const AVAudioStereoOrientation(this.value);

  static AVAudioStereoOrientation fromValue(int value) => switch (value) {
    0 => AVAudioStereoOrientationNone,
    1 => AVAudioStereoOrientationPortrait,
    2 => AVAudioStereoOrientationPortraitUpsideDown,
    3 => AVAudioStereoOrientationLandscapeRight,
    4 => AVAudioStereoOrientationLandscapeLeft,
    _ => throw ArgumentError('Unknown value for AVAudioStereoOrientation: $value'),
  };
}

enum AVAudioSessionRecordPermission {
  AVAudioSessionRecordPermissionUndetermined(1970168948),
  AVAudioSessionRecordPermissionDenied(1684369017),
  AVAudioSessionRecordPermissionGranted(1735552628);

  final int value;
  const AVAudioSessionRecordPermission(this.value);

  static AVAudioSessionRecordPermission fromValue(int value) => switch (value) {
    1970168948 => AVAudioSessionRecordPermissionUndetermined,
    1684369017 => AVAudioSessionRecordPermissionDenied,
    1735552628 => AVAudioSessionRecordPermissionGranted,
    _ => throw ArgumentError('Unknown value for AVAudioSessionRecordPermission: $value'),
  };
}

enum AVAudioSessionRenderingMode {
  AVAudioSessionRenderingModeNotApplicable(0),
  AVAudioSessionRenderingModeMonoStereo(1),
  AVAudioSessionRenderingModeSurround(2),
  AVAudioSessionRenderingModeSpatialAudio(3),
  AVAudioSessionRenderingModeDolbyAudio(4),
  AVAudioSessionRenderingModeDolbyAtmos(5);

  final int value;
  const AVAudioSessionRenderingMode(this.value);

  static AVAudioSessionRenderingMode fromValue(int value) => switch (value) {
    0 => AVAudioSessionRenderingModeNotApplicable,
    1 => AVAudioSessionRenderingModeMonoStereo,
    2 => AVAudioSessionRenderingModeSurround,
    3 => AVAudioSessionRenderingModeSpatialAudio,
    4 => AVAudioSessionRenderingModeDolbyAudio,
    5 => AVAudioSessionRenderingModeDolbyAtmos,
    _ => throw ArgumentError('Unknown value for AVAudioSessionRenderingMode: $value'),
  };
}

/// WARNING: AVAudioSessionDataSourceDescription is a stub. To generate bindings for this class, include
/// AVAudioSessionDataSourceDescription in your config's objc-interfaces list.
///
/// AVAudioSessionDataSourceDescription
class AVAudioSessionDataSourceDescription extends objc.NSObject {
  AVAudioSessionDataSourceDescription._(
    ffi.Pointer<objc.ObjCObject> pointer, {
    bool retain = false,
    bool release = false,
  }) : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioSessionDataSourceDescription', iOS: (false, (6, 0, 0)), macOS: (true, null));
  }

  /// Constructs a [AVAudioSessionDataSourceDescription] that points to the same underlying object as [other].
  AVAudioSessionDataSourceDescription.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioSessionDataSourceDescription] that wraps the given raw object pointer.
  AVAudioSessionDataSourceDescription.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

/// WARNING: AVAudioSessionPortDescription is a stub. To generate bindings for this class, include
/// AVAudioSessionPortDescription in your config's objc-interfaces list.
///
/// AVAudioSessionPortDescription
class AVAudioSessionPortDescription extends objc.NSObject {
  AVAudioSessionPortDescription._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioSessionPortDescription', iOS: (false, (6, 0, 0)), macOS: (true, null));
  }

  /// Constructs a [AVAudioSessionPortDescription] that points to the same underlying object as [other].
  AVAudioSessionPortDescription.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioSessionPortDescription] that wraps the given raw object pointer.
  AVAudioSessionPortDescription.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

/// WARNING: AVAudioSessionRouteDescription is a stub. To generate bindings for this class, include
/// AVAudioSessionRouteDescription in your config's objc-interfaces list.
///
/// AVAudioSessionRouteDescription
class AVAudioSessionRouteDescription extends objc.NSObject {
  AVAudioSessionRouteDescription._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioSessionRouteDescription', iOS: (false, (6, 0, 0)), macOS: (true, null));
  }

  /// Constructs a [AVAudioSessionRouteDescription] that points to the same underlying object as [other].
  AVAudioSessionRouteDescription.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioSessionRouteDescription] that wraps the given raw object pointer.
  AVAudioSessionRouteDescription.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _class_AVAudioSession = objc.getClass("AVAudioSession");
late final _sel_setActive_error_ = objc.registerName("setActive:error:");
final _objc_msgSend_164wts2 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Bool,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        bool,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_setActive_withOptions_error_ = objc.registerName("setActive:withOptions:error:");
final _objc_msgSend_1nqw6vl = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Bool,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        bool,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
void _ObjCBlock_ffiVoid_bool_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  bool arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(bool, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_bool_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_bool_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  bool arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(bool, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_bool_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_bool_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_bool_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  bool arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(bool, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)>
_ObjCBlock_ffiVoid_bool_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_bool_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_bool_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  bool arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(bool, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_bool_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Bool,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_bool_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Bool, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_bool_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Bool,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_bool_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_bool_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Bool arg0, ffi.Pointer<objc.ObjCObject> arg1)>> ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_bool_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> fromFunction(
    void Function(bool, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_NSError_closureCallable,
      (bool arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> listener(
    void Function(bool, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_NSError_listenerCallable.nativeFunction.cast(),
      (bool arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_hk7n97(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> blocking(
    void Function(bool, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_NSError_blockingCallable.nativeFunction.cast(),
      (bool arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_bool_NSError_blockingListenerCallable.nativeFunction.cast(),
      (bool arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_hk7n97(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_bool_NSError_CallExtension on objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> {
  void call(bool arg0, objc.NSError? arg1) =>
      ref.pointer.ref.invoke
          .cast<
            ffi.NativeFunction<
              ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Bool arg0, ffi.Pointer<objc.ObjCObject> arg1)
            >
          >()
          .asFunction<void Function(ffi.Pointer<objc.ObjCBlockImpl>, bool, ffi.Pointer<objc.ObjCObject>)>()(
        ref.pointer,
        arg0,
        arg1?.ref.pointer ?? ffi.nullptr,
      );
}

late final _sel_activateWithOptions_completionHandler_ = objc.registerName("activateWithOptions:completionHandler:");
final _objc_msgSend_ivnkdn = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.UnsignedLong,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int, ffi.Pointer<objc.ObjCBlockImpl>)
    >();

/// Activation
extension Activation on AVAudioSession {
  /// setActive:error:
  bool setActive(bool active, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal('AVAudioSession.setActive:error:', iOS: (false, (3, 0, 0)), macOS: (true, null));
    return _objc_msgSend_164wts2(this.ref.pointer, _sel_setActive_error_, active, error);
  }

  /// setActive:withOptions:error:
  bool setActive$1(
    bool active, {
    required AVAudioSessionSetActiveOptions withOptions,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setActive:withOptions:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1nqw6vl(this.ref.pointer, _sel_setActive_withOptions_error_, active, withOptions.value, error);
  }

  /// activateWithOptions:completionHandler:
  void activateWithOptions(
    AVAudioSessionActivationOptions options, {
    required objc.ObjCBlock<ffi.Void Function(ffi.Bool, objc.NSError?)> completionHandler,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.activateWithOptions:completionHandler:',
      iOS: (true, null),
      macOS: (true, null),
    );
    _objc_msgSend_ivnkdn(
      this.ref.pointer,
      _sel_activateWithOptions_completionHandler_,
      options.value,
      completionHandler.ref.pointer,
    );
  }
}

late final _sel_setPreferredSampleRate_error_ = objc.registerName("setPreferredSampleRate:error:");
final _objc_msgSend_xhvge5 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Double,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        double,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_preferredSampleRate = objc.registerName("preferredSampleRate");
late final _sel_setPreferredIOBufferDuration_error_ = objc.registerName("setPreferredIOBufferDuration:error:");
late final _sel_preferredIOBufferDuration = objc.registerName("preferredIOBufferDuration");
late final _sel_setPreferredInputNumberOfChannels_error_ = objc.registerName(
  "setPreferredInputNumberOfChannels:error:",
);
final _objc_msgSend_165e55c = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Long,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_preferredInputNumberOfChannels = objc.registerName("preferredInputNumberOfChannels");
final _objc_msgSend_1hz7y9r = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPreferredOutputNumberOfChannels_error_ = objc.registerName(
  "setPreferredOutputNumberOfChannels:error:",
);
late final _sel_preferredOutputNumberOfChannels = objc.registerName("preferredOutputNumberOfChannels");
late final _sel_setPreferredInputOrientation_error_ = objc.registerName("setPreferredInputOrientation:error:");
final _objc_msgSend_1db3yj = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Long,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_preferredInputOrientation = objc.registerName("preferredInputOrientation");
final _objc_msgSend_1n4ndiq = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_inputOrientation = objc.registerName("inputOrientation");
late final _sel_maximumInputNumberOfChannels = objc.registerName("maximumInputNumberOfChannels");
late final _sel_maximumOutputNumberOfChannels = objc.registerName("maximumOutputNumberOfChannels");
late final _sel_setInputGain_error_ = objc.registerName("setInputGain:error:");
final _objc_msgSend_1c1ssyi = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Float,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        double,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_inputGain = objc.registerName("inputGain");
late final _sel_isInputGainSettable = objc.registerName("isInputGainSettable");
late final _sel_isInputAvailable = objc.registerName("isInputAvailable");
late final _sel_inputDataSources = objc.registerName("inputDataSources");
late final _sel_inputDataSource = objc.registerName("inputDataSource");
late final _sel_setInputDataSource_error_ = objc.registerName("setInputDataSource:error:");
final _objc_msgSend_l9p60w = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_outputDataSources = objc.registerName("outputDataSources");
late final _sel_outputDataSource = objc.registerName("outputDataSource");
late final _sel_setOutputDataSource_error_ = objc.registerName("setOutputDataSource:error:");
late final _sel_sampleRate = objc.registerName("sampleRate");
late final _sel_inputNumberOfChannels = objc.registerName("inputNumberOfChannels");
late final _sel_outputNumberOfChannels = objc.registerName("outputNumberOfChannels");
late final _sel_inputLatency = objc.registerName("inputLatency");
late final _sel_outputLatency = objc.registerName("outputLatency");
late final _sel_IOBufferDuration = objc.registerName("IOBufferDuration");
late final _sel_supportedOutputChannelLayouts = objc.registerName("supportedOutputChannelLayouts");

/// AVAudioSessionHardwareConfiguration
extension AVAudioSessionHardwareConfiguration on AVAudioSession {
  /// setPreferredSampleRate:error:
  bool setPreferredSampleRate(double sampleRate, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredSampleRate:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_xhvge5(this.ref.pointer, _sel_setPreferredSampleRate_error_, sampleRate, error);
  }

  /// preferredSampleRate
  double get preferredSampleRate {
    objc.checkOsVersionInternal('AVAudioSession.preferredSampleRate', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredSampleRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredSampleRate);
  }

  /// setPreferredIOBufferDuration:error:
  bool setPreferredIOBufferDuration(double duration, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredIOBufferDuration:error:',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_xhvge5(this.ref.pointer, _sel_setPreferredIOBufferDuration_error_, duration, error);
  }

  /// preferredIOBufferDuration
  double get preferredIOBufferDuration {
    objc.checkOsVersionInternal(
      'AVAudioSession.preferredIOBufferDuration',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredIOBufferDuration)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredIOBufferDuration);
  }

  /// setPreferredInputNumberOfChannels:error:
  bool setPreferredInputNumberOfChannels(int count, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredInputNumberOfChannels:error:',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_165e55c(this.ref.pointer, _sel_setPreferredInputNumberOfChannels_error_, count, error);
  }

  /// preferredInputNumberOfChannels
  int get preferredInputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.preferredInputNumberOfChannels',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_preferredInputNumberOfChannels);
  }

  /// setPreferredOutputNumberOfChannels:error:
  bool setPreferredOutputNumberOfChannels(int count, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredOutputNumberOfChannels:error:',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_165e55c(this.ref.pointer, _sel_setPreferredOutputNumberOfChannels_error_, count, error);
  }

  /// preferredOutputNumberOfChannels
  int get preferredOutputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.preferredOutputNumberOfChannels',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_preferredOutputNumberOfChannels);
  }

  /// setPreferredInputOrientation:error:
  bool setPreferredInputOrientation(
    AVAudioStereoOrientation orientation, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredInputOrientation:error:',
      iOS: (false, (14, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1db3yj(this.ref.pointer, _sel_setPreferredInputOrientation_error_, orientation.value, error);
  }

  /// preferredInputOrientation
  AVAudioStereoOrientation get preferredInputOrientation {
    objc.checkOsVersionInternal(
      'AVAudioSession.preferredInputOrientation',
      iOS: (false, (14, 0, 0)),
      macOS: (true, null),
    );
    final _ret = _objc_msgSend_1n4ndiq(this.ref.pointer, _sel_preferredInputOrientation);
    return AVAudioStereoOrientation.fromValue(_ret);
  }

  /// inputOrientation
  AVAudioStereoOrientation get inputOrientation {
    objc.checkOsVersionInternal('AVAudioSession.inputOrientation', iOS: (false, (14, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_1n4ndiq(this.ref.pointer, _sel_inputOrientation);
    return AVAudioStereoOrientation.fromValue(_ret);
  }

  /// maximumInputNumberOfChannels
  int get maximumInputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.maximumInputNumberOfChannels',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_maximumInputNumberOfChannels);
  }

  /// maximumOutputNumberOfChannels
  int get maximumOutputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.maximumOutputNumberOfChannels',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_maximumOutputNumberOfChannels);
  }

  /// setInputGain:error:
  bool setInputGain(double gain, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal('AVAudioSession.setInputGain:error:', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_1c1ssyi(this.ref.pointer, _sel_setInputGain_error_, gain, error);
  }

  /// inputGain
  double get inputGain {
    objc.checkOsVersionInternal('AVAudioSession.inputGain', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_inputGain)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_inputGain);
  }

  /// isInputGainSettable
  bool get inputGainSettable {
    objc.checkOsVersionInternal('AVAudioSession.isInputGainSettable', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isInputGainSettable);
  }

  /// isInputAvailable
  bool get inputAvailable {
    objc.checkOsVersionInternal('AVAudioSession.isInputAvailable', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isInputAvailable);
  }

  /// inputDataSources
  objc.NSArray? get inputDataSources {
    objc.checkOsVersionInternal('AVAudioSession.inputDataSources', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_inputDataSources);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// inputDataSource
  AVAudioSessionDataSourceDescription? get inputDataSource {
    objc.checkOsVersionInternal('AVAudioSession.inputDataSource', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_inputDataSource);
    return _ret.address == 0
        ? null
        : AVAudioSessionDataSourceDescription.castFromPointer(_ret, retain: true, release: true);
  }

  /// setInputDataSource:error:
  bool setInputDataSource(
    AVAudioSessionDataSourceDescription? dataSource, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setInputDataSource:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_l9p60w(
      this.ref.pointer,
      _sel_setInputDataSource_error_,
      dataSource?.ref.pointer ?? ffi.nullptr,
      error,
    );
  }

  /// outputDataSources
  objc.NSArray? get outputDataSources {
    objc.checkOsVersionInternal('AVAudioSession.outputDataSources', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputDataSources);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// outputDataSource
  AVAudioSessionDataSourceDescription? get outputDataSource {
    objc.checkOsVersionInternal('AVAudioSession.outputDataSource', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_outputDataSource);
    return _ret.address == 0
        ? null
        : AVAudioSessionDataSourceDescription.castFromPointer(_ret, retain: true, release: true);
  }

  /// setOutputDataSource:error:
  bool setOutputDataSource(
    AVAudioSessionDataSourceDescription? dataSource, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setOutputDataSource:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_l9p60w(
      this.ref.pointer,
      _sel_setOutputDataSource_error_,
      dataSource?.ref.pointer ?? ffi.nullptr,
      error,
    );
  }

  /// sampleRate
  double get sampleRate {
    objc.checkOsVersionInternal('AVAudioSession.sampleRate', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_sampleRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_sampleRate);
  }

  /// inputNumberOfChannels
  int get inputNumberOfChannels {
    objc.checkOsVersionInternal('AVAudioSession.inputNumberOfChannels', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_inputNumberOfChannels);
  }

  /// outputNumberOfChannels
  int get outputNumberOfChannels {
    objc.checkOsVersionInternal('AVAudioSession.outputNumberOfChannels', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_outputNumberOfChannels);
  }

  /// inputLatency
  double get inputLatency {
    objc.checkOsVersionInternal('AVAudioSession.inputLatency', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_inputLatency)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_inputLatency);
  }

  /// outputLatency
  double get outputLatency {
    objc.checkOsVersionInternal('AVAudioSession.outputLatency', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_outputLatency)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_outputLatency);
  }

  /// IOBufferDuration
  double get IOBufferDuration {
    objc.checkOsVersionInternal('AVAudioSession.IOBufferDuration', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_IOBufferDuration)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_IOBufferDuration);
  }

  /// supportedOutputChannelLayouts
  objc.NSArray get supportedOutputChannelLayouts {
    objc.checkOsVersionInternal(
      'AVAudioSession.supportedOutputChannelLayouts',
      iOS: (false, (17, 2, 0)),
      macOS: (true, null),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_supportedOutputChannelLayouts);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }
}

late final _sel_isOtherAudioPlaying = objc.registerName("isOtherAudioPlaying");
late final _sel_secondaryAudioShouldBeSilencedHint = objc.registerName("secondaryAudioShouldBeSilencedHint");
late final _sel_outputVolume = objc.registerName("outputVolume");
late final _sel_promptStyle = objc.registerName("promptStyle");
final _objc_msgSend_fooyu3 = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// Observation
extension Observation on AVAudioSession {
  /// isOtherAudioPlaying
  bool get otherAudioPlaying {
    objc.checkOsVersionInternal('AVAudioSession.isOtherAudioPlaying', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isOtherAudioPlaying);
  }

  /// secondaryAudioShouldBeSilencedHint
  bool get secondaryAudioShouldBeSilencedHint {
    objc.checkOsVersionInternal(
      'AVAudioSession.secondaryAudioShouldBeSilencedHint',
      iOS: (false, (8, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_secondaryAudioShouldBeSilencedHint);
  }

  /// outputVolume
  double get outputVolume {
    objc.checkOsVersionInternal('AVAudioSession.outputVolume', iOS: (false, (6, 0, 0)), macOS: (true, null));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_outputVolume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_outputVolume);
  }

  /// promptStyle
  AVAudioSessionPromptStyle get promptStyle {
    objc.checkOsVersionInternal('AVAudioSession.promptStyle', iOS: (false, (13, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_fooyu3(this.ref.pointer, _sel_promptStyle);
    return AVAudioSessionPromptStyle.fromValue(_ret);
  }
}

late final _sel_availableInputs = objc.registerName("availableInputs");
late final _sel_currentRoute = objc.registerName("currentRoute");
late final _sel_setAggregatedIOPreference_error_ = objc.registerName("setAggregatedIOPreference:error:");
final _objc_msgSend_vqual9 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_setSupportsMultichannelContent_error_ = objc.registerName("setSupportsMultichannelContent:error:");
late final _sel_supportsMultichannelContent = objc.registerName("supportsMultichannelContent");
late final _sel_setPrefersInterruptionOnRouteDisconnect_error_ = objc.registerName(
  "setPrefersInterruptionOnRouteDisconnect:error:",
);
late final _sel_prefersInterruptionOnRouteDisconnect = objc.registerName("prefersInterruptionOnRouteDisconnect");

/// RoutingConfiguration
extension RoutingConfiguration on AVAudioSession {
  /// availableInputs
  objc.NSArray? get availableInputs {
    objc.checkOsVersionInternal('AVAudioSession.availableInputs', iOS: (false, (7, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableInputs);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// currentRoute
  AVAudioSessionRouteDescription get currentRoute {
    objc.checkOsVersionInternal('AVAudioSession.currentRoute', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentRoute);
    return AVAudioSessionRouteDescription.castFromPointer(_ret, retain: true, release: true);
  }

  /// setAggregatedIOPreference:error:
  bool setAggregatedIOPreference(
    AVAudioSessionIOType inIOType, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setAggregatedIOPreference:error:',
      iOS: (false, (10, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_vqual9(this.ref.pointer, _sel_setAggregatedIOPreference_error_, inIOType.value, error);
  }

  /// setSupportsMultichannelContent:error:
  bool setSupportsMultichannelContent(bool inValue, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setSupportsMultichannelContent:error:',
      iOS: (false, (15, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_164wts2(this.ref.pointer, _sel_setSupportsMultichannelContent_error_, inValue, error);
  }

  /// supportsMultichannelContent
  bool get supportsMultichannelContent {
    objc.checkOsVersionInternal(
      'AVAudioSession.supportsMultichannelContent',
      iOS: (false, (15, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_supportsMultichannelContent);
  }

  /// setPrefersInterruptionOnRouteDisconnect:error:
  bool setPrefersInterruptionOnRouteDisconnect(
    bool inValue, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPrefersInterruptionOnRouteDisconnect:error:',
      iOS: (false, (17, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_164wts2(this.ref.pointer, _sel_setPrefersInterruptionOnRouteDisconnect_error_, inValue, error);
  }

  /// prefersInterruptionOnRouteDisconnect
  bool get prefersInterruptionOnRouteDisconnect {
    objc.checkOsVersionInternal(
      'AVAudioSession.prefersInterruptionOnRouteDisconnect',
      iOS: (false, (17, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_prefersInterruptionOnRouteDisconnect);
  }
}

/// WARNING: AVAudioSessionDelegate is a stub. To generate bindings for this class, include
/// AVAudioSessionDelegate in your config's objc-protocols list.
///
/// AVAudioSessionDelegate
interface class AVAudioSessionDelegate extends objc.ObjCProtocolBase implements objc.NSObjectProtocol {
  AVAudioSessionDelegate._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAudioSessionDelegate] that points to the same underlying object as [other].
  AVAudioSessionDelegate.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioSessionDelegate] that wraps the given raw object pointer.
  AVAudioSessionDelegate.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_delegate = objc.registerName("delegate");
late final _sel_setDelegate_ = objc.registerName("setDelegate:");
late final _sel_setActive_withFlags_error_ = objc.registerName("setActive:withFlags:error:");
final _objc_msgSend_tpnpd0 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Bool,
          ffi.Long,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        bool,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_inputIsAvailable = objc.registerName("inputIsAvailable");
late final _sel_currentHardwareSampleRate = objc.registerName("currentHardwareSampleRate");
late final _sel_currentHardwareInputNumberOfChannels = objc.registerName("currentHardwareInputNumberOfChannels");
late final _sel_currentHardwareOutputNumberOfChannels = objc.registerName("currentHardwareOutputNumberOfChannels");
late final _sel_setPreferredHardwareSampleRate_error_ = objc.registerName("setPreferredHardwareSampleRate:error:");
late final _sel_preferredHardwareSampleRate = objc.registerName("preferredHardwareSampleRate");

/// AVAudioSessionDeprecated
extension AVAudioSessionDeprecated on AVAudioSession {
  /// delegate
  AVAudioSessionDelegate? get delegate {
    objc.checkOsVersionInternal('AVAudioSession.delegate', iOS: (false, (4, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_delegate);
    return _ret.address == 0 ? null : AVAudioSessionDelegate.castFromPointer(_ret, retain: true, release: true);
  }

  /// setDelegate:
  set delegate(AVAudioSessionDelegate? value) {
    objc.checkOsVersionInternal('AVAudioSession.setDelegate:', iOS: (false, (4, 0, 0)), macOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setDelegate_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// setActive:withFlags:error:
  bool setActive(bool active, {required int withFlags, required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setActive:withFlags:error:',
      iOS: (false, (4, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_tpnpd0(this.ref.pointer, _sel_setActive_withFlags_error_, active, withFlags, error);
  }

  /// inputIsAvailable
  bool get inputIsAvailable {
    objc.checkOsVersionInternal('AVAudioSession.inputIsAvailable', iOS: (false, (3, 0, 0)), macOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_inputIsAvailable);
  }

  /// currentHardwareSampleRate
  double get currentHardwareSampleRate {
    objc.checkOsVersionInternal(
      'AVAudioSession.currentHardwareSampleRate',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_currentHardwareSampleRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_currentHardwareSampleRate);
  }

  /// currentHardwareInputNumberOfChannels
  int get currentHardwareInputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.currentHardwareInputNumberOfChannels',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_currentHardwareInputNumberOfChannels);
  }

  /// currentHardwareOutputNumberOfChannels
  int get currentHardwareOutputNumberOfChannels {
    objc.checkOsVersionInternal(
      'AVAudioSession.currentHardwareOutputNumberOfChannels',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_currentHardwareOutputNumberOfChannels);
  }

  /// setPreferredHardwareSampleRate:error:
  bool setPreferredHardwareSampleRate(double sampleRate, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredHardwareSampleRate:error:',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_xhvge5(this.ref.pointer, _sel_setPreferredHardwareSampleRate_error_, sampleRate, error);
  }

  /// preferredHardwareSampleRate
  double get preferredHardwareSampleRate {
    objc.checkOsVersionInternal(
      'AVAudioSession.preferredHardwareSampleRate',
      iOS: (false, (3, 0, 0)),
      macOS: (true, null),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_preferredHardwareSampleRate)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_preferredHardwareSampleRate);
  }
}

late final _sel_sharedInstance = objc.registerName("sharedInstance");
late final _sel_availableCategories = objc.registerName("availableCategories");
late final _sel_setCategory_error_ = objc.registerName("setCategory:error:");
late final _sel_setCategory_withOptions_error_ = objc.registerName("setCategory:withOptions:error:");
final _objc_msgSend_1dyo7td = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_setCategory_mode_options_error_ = objc.registerName("setCategory:mode:options:error:");
final _objc_msgSend_1xawsmb = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_setCategory_mode_routeSharingPolicy_options_error_ = objc.registerName(
  "setCategory:mode:routeSharingPolicy:options:error:",
);
final _objc_msgSend_5f4kt7 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.UnsignedLong,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        int,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_category = objc.registerName("category");
late final _sel_categoryOptions = objc.registerName("categoryOptions");
final _objc_msgSend_dn2ony = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_routeSharingPolicy = objc.registerName("routeSharingPolicy");
final _objc_msgSend_1dlq48t = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_availableModes = objc.registerName("availableModes");
late final _sel_setMode_error_ = objc.registerName("setMode:error:");
late final _sel_mode = objc.registerName("mode");
late final _sel_setAllowHapticsAndSystemSoundsDuringRecording_error_ = objc.registerName(
  "setAllowHapticsAndSystemSoundsDuringRecording:error:",
);
late final _sel_allowHapticsAndSystemSoundsDuringRecording = objc.registerName(
  "allowHapticsAndSystemSoundsDuringRecording",
);
late final _sel_recordPermission = objc.registerName("recordPermission");
final _objc_msgSend_1jfdhky = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_requestRecordPermission_ = objc.registerName("requestRecordPermission:");
final _objc_msgSend_f167m6 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCBlockImpl>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCBlockImpl>)
    >();
late final _sel_overrideOutputAudioPort_error_ = objc.registerName("overrideOutputAudioPort:error:");
final _objc_msgSend_avsgdw = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.UnsignedLong,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        int,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_setPreferredInput_error_ = objc.registerName("setPreferredInput:error:");
late final _sel_preferredInput = objc.registerName("preferredInput");
late final _sel_setPrefersNoInterruptionsFromSystemAlerts_error_ = objc.registerName(
  "setPrefersNoInterruptionsFromSystemAlerts:error:",
);
late final _sel_prefersNoInterruptionsFromSystemAlerts = objc.registerName("prefersNoInterruptionsFromSystemAlerts");
late final _sel_renderingMode = objc.registerName("renderingMode");
final _objc_msgSend_yy5lzv = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();

/// AVAudioSession
class AVAudioSession extends objc.NSObject {
  AVAudioSession._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioSession', iOS: (false, (3, 0, 0)), macOS: (true, null));
  }

  /// Constructs a [AVAudioSession] that points to the same underlying object as [other].
  AVAudioSession.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioSession] that wraps the given raw object pointer.
  AVAudioSession.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVAudioSession].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVAudioSession);
  }

  /// sharedInstance
  static AVAudioSession sharedInstance() {
    objc.checkOsVersionInternal('AVAudioSession.sharedInstance', iOS: (false, (3, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(_class_AVAudioSession, _sel_sharedInstance);
    return AVAudioSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// availableCategories
  objc.NSArray get availableCategories {
    objc.checkOsVersionInternal('AVAudioSession.availableCategories', iOS: (false, (9, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableCategories);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// setCategory:error:
  bool setCategory(objc.NSString category, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal('AVAudioSession.setCategory:error:', iOS: (false, (3, 0, 0)), macOS: (true, null));
    return _objc_msgSend_l9p60w(this.ref.pointer, _sel_setCategory_error_, category.ref.pointer, error);
  }

  /// setCategory:withOptions:error:
  bool setCategory$1(
    objc.NSString category, {
    required AVAudioSessionCategoryOptions withOptions,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setCategory:withOptions:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1dyo7td(
      this.ref.pointer,
      _sel_setCategory_withOptions_error_,
      category.ref.pointer,
      withOptions.value,
      error,
    );
  }

  /// setCategory:mode:options:error:
  bool setCategory$2(
    objc.NSString category, {
    required objc.NSString mode,
    required AVAudioSessionCategoryOptions options,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setCategory:mode:options:error:',
      iOS: (false, (10, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_1xawsmb(
      this.ref.pointer,
      _sel_setCategory_mode_options_error_,
      category.ref.pointer,
      mode.ref.pointer,
      options.value,
      error,
    );
  }

  /// setCategory:mode:routeSharingPolicy:options:error:
  bool setCategory$3(
    objc.NSString category, {
    required objc.NSString mode,
    required AVAudioSessionRouteSharingPolicy routeSharingPolicy,
    required AVAudioSessionCategoryOptions options,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setCategory:mode:routeSharingPolicy:options:error:',
      iOS: (false, (11, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_5f4kt7(
      this.ref.pointer,
      _sel_setCategory_mode_routeSharingPolicy_options_error_,
      category.ref.pointer,
      mode.ref.pointer,
      routeSharingPolicy.value,
      options.value,
      error,
    );
  }

  /// category
  objc.NSString get category {
    objc.checkOsVersionInternal('AVAudioSession.category', iOS: (false, (3, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_category);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// categoryOptions
  AVAudioSessionCategoryOptions get categoryOptions {
    objc.checkOsVersionInternal('AVAudioSession.categoryOptions', iOS: (false, (6, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_dn2ony(this.ref.pointer, _sel_categoryOptions);
    return AVAudioSessionCategoryOptions.fromValue(_ret);
  }

  /// routeSharingPolicy
  AVAudioSessionRouteSharingPolicy get routeSharingPolicy {
    objc.checkOsVersionInternal('AVAudioSession.routeSharingPolicy', iOS: (false, (11, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_1dlq48t(this.ref.pointer, _sel_routeSharingPolicy);
    return AVAudioSessionRouteSharingPolicy.fromValue(_ret);
  }

  /// availableModes
  objc.NSArray get availableModes {
    objc.checkOsVersionInternal('AVAudioSession.availableModes', iOS: (false, (9, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_availableModes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// setMode:error:
  bool setMode(objc.NSString mode, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal('AVAudioSession.setMode:error:', iOS: (false, (5, 0, 0)), macOS: (true, null));
    return _objc_msgSend_l9p60w(this.ref.pointer, _sel_setMode_error_, mode.ref.pointer, error);
  }

  /// mode
  objc.NSString get mode {
    objc.checkOsVersionInternal('AVAudioSession.mode', iOS: (false, (5, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_mode);
    return objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setAllowHapticsAndSystemSoundsDuringRecording:error:
  bool setAllowHapticsAndSystemSoundsDuringRecording(
    bool inValue, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setAllowHapticsAndSystemSoundsDuringRecording:error:',
      iOS: (false, (13, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_164wts2(
      this.ref.pointer,
      _sel_setAllowHapticsAndSystemSoundsDuringRecording_error_,
      inValue,
      error,
    );
  }

  /// allowHapticsAndSystemSoundsDuringRecording
  bool get allowHapticsAndSystemSoundsDuringRecording {
    objc.checkOsVersionInternal(
      'AVAudioSession.allowHapticsAndSystemSoundsDuringRecording',
      iOS: (false, (13, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_allowHapticsAndSystemSoundsDuringRecording);
  }

  /// recordPermission
  AVAudioSessionRecordPermission get recordPermission {
    objc.checkOsVersionInternal('AVAudioSession.recordPermission', iOS: (false, (8, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_1jfdhky(this.ref.pointer, _sel_recordPermission);
    return AVAudioSessionRecordPermission.fromValue(_ret);
  }

  /// requestRecordPermission:
  void requestRecordPermission(objc.ObjCBlock<ffi.Void Function(ffi.Bool)> response) {
    objc.checkOsVersionInternal(
      'AVAudioSession.requestRecordPermission:',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    _objc_msgSend_f167m6(this.ref.pointer, _sel_requestRecordPermission_, response.ref.pointer);
  }

  /// overrideOutputAudioPort:error:
  bool overrideOutputAudioPort(
    AVAudioSessionPortOverride portOverride, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.overrideOutputAudioPort:error:',
      iOS: (false, (6, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_avsgdw(this.ref.pointer, _sel_overrideOutputAudioPort_error_, portOverride.value, error);
  }

  /// setPreferredInput:error:
  bool setPreferredInput(
    AVAudioSessionPortDescription? inPort, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPreferredInput:error:',
      iOS: (false, (7, 0, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_l9p60w(
      this.ref.pointer,
      _sel_setPreferredInput_error_,
      inPort?.ref.pointer ?? ffi.nullptr,
      error,
    );
  }

  /// preferredInput
  AVAudioSessionPortDescription? get preferredInput {
    objc.checkOsVersionInternal('AVAudioSession.preferredInput', iOS: (false, (7, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_preferredInput);
    return _ret.address == 0 ? null : AVAudioSessionPortDescription.castFromPointer(_ret, retain: true, release: true);
  }

  /// setPrefersNoInterruptionsFromSystemAlerts:error:
  bool setPrefersNoInterruptionsFromSystemAlerts(
    bool inValue, {
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioSession.setPrefersNoInterruptionsFromSystemAlerts:error:',
      iOS: (false, (14, 5, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_164wts2(
      this.ref.pointer,
      _sel_setPrefersNoInterruptionsFromSystemAlerts_error_,
      inValue,
      error,
    );
  }

  /// prefersNoInterruptionsFromSystemAlerts
  bool get prefersNoInterruptionsFromSystemAlerts {
    objc.checkOsVersionInternal(
      'AVAudioSession.prefersNoInterruptionsFromSystemAlerts',
      iOS: (false, (14, 5, 0)),
      macOS: (true, null),
    );
    return _objc_msgSend_91o635(this.ref.pointer, _sel_prefersNoInterruptionsFromSystemAlerts);
  }

  /// renderingMode
  AVAudioSessionRenderingMode get renderingMode {
    objc.checkOsVersionInternal('AVAudioSession.renderingMode', iOS: (false, (17, 2, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_yy5lzv(this.ref.pointer, _sel_renderingMode);
    return AVAudioSessionRenderingMode.fromValue(_ret);
  }

  /// init
  AVAudioSession init() {
    objc.checkOsVersionInternal('AVAudioSession.init', iOS: (false, (3, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVAudioSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVAudioSession new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVAudioSession, _sel_new);
    return AVAudioSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVAudioSession allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVAudioSession, _sel_allocWithZone_, zone);
    return AVAudioSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVAudioSession alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVAudioSession, _sel_alloc);
    return AVAudioSession.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVAudioSession self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVAudioSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVAudioSession retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVAudioSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVAudioSession autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVAudioSession.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVAudioSession constructed with the default `new` method.
  factory AVAudioSession() => new$();
}

late final _class_AVAudioPlayer = objc.getClass("AVAudioPlayer");
late final _sel_initWithContentsOfURL_error_ = objc.registerName("initWithContentsOfURL:error:");
final _objc_msgSend_1lhpu4m = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_initWithData_error_ = objc.registerName("initWithData:error:");
late final _sel_initWithContentsOfURL_fileTypeHint_error_ = objc.registerName(
  "initWithContentsOfURL:fileTypeHint:error:",
);
final _objc_msgSend_1pnyuds = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >();
late final _sel_initWithData_fileTypeHint_error_ = objc.registerName("initWithData:fileTypeHint:error:");
late final _sel_prepareToPlay = objc.registerName("prepareToPlay");
late final _sel_playAtTime_ = objc.registerName("playAtTime:");
final _objc_msgSend_18chyc = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)>
    >()
    .asFunction<bool Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();
late final _sel_stop = objc.registerName("stop");
late final _sel_isPlaying = objc.registerName("isPlaying");
late final _sel_numberOfChannels = objc.registerName("numberOfChannels");
final _objc_msgSend_xw2lbc = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_currentDevice = objc.registerName("currentDevice");
late final _sel_setCurrentDevice_ = objc.registerName("setCurrentDevice:");

/// WARNING: AVAudioPlayerDelegate is a stub. To generate bindings for this class, include
/// AVAudioPlayerDelegate in your config's objc-protocols list.
///
/// AVAudioPlayerDelegate
interface class AVAudioPlayerDelegate extends objc.ObjCProtocolBase implements objc.NSObjectProtocol {
  AVAudioPlayerDelegate._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [AVAudioPlayerDelegate] that points to the same underlying object as [other].
  AVAudioPlayerDelegate.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioPlayerDelegate] that wraps the given raw object pointer.
  AVAudioPlayerDelegate.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_url = objc.registerName("url");
late final _sel_data = objc.registerName("data");
late final _sel_pan = objc.registerName("pan");
late final _sel_setPan_ = objc.registerName("setPan:");
late final _sel_setVolume_fadeDuration_ = objc.registerName("setVolume:fadeDuration:");
final _objc_msgSend_1p4uk9e = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Float, ffi.Double)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double, double)>();
late final _sel_enableRate = objc.registerName("enableRate");
late final _sel_setEnableRate_ = objc.registerName("setEnableRate:");
late final _sel_setCurrentTime_ = objc.registerName("setCurrentTime:");
late final _sel_deviceCurrentTime = objc.registerName("deviceCurrentTime");
late final _sel_numberOfLoops = objc.registerName("numberOfLoops");
late final _sel_setNumberOfLoops_ = objc.registerName("setNumberOfLoops:");
late final _sel_settings = objc.registerName("settings");
late final _sel_format = objc.registerName("format");
late final _sel_isMeteringEnabled = objc.registerName("isMeteringEnabled");
late final _sel_setMeteringEnabled_ = objc.registerName("setMeteringEnabled:");
late final _sel_updateMeters = objc.registerName("updateMeters");
late final _sel_peakPowerForChannel_ = objc.registerName("peakPowerForChannel:");
final _objc_msgSend_65s5yw = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
final _objc_msgSend_65s5ywFpret = objc.msgSendFpretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Float Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
late final _sel_averagePowerForChannel_ = objc.registerName("averagePowerForChannel:");
late final _sel_channelAssignments = objc.registerName("channelAssignments");
late final _sel_setChannelAssignments_ = objc.registerName("setChannelAssignments:");

/// AVAudioPlayer
class AVAudioPlayer extends objc.NSObject {
  AVAudioPlayer._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('AVAudioPlayer', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
  }

  /// Constructs a [AVAudioPlayer] that points to the same underlying object as [other].
  AVAudioPlayer.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [AVAudioPlayer] that wraps the given raw object pointer.
  AVAudioPlayer.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [AVAudioPlayer].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_AVAudioPlayer);
  }

  /// initWithContentsOfURL:error:
  AVAudioPlayer? initWithContentsOfURL(objc.NSURL url, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.initWithContentsOfURL:error:',
      iOS: (false, (2, 2, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1lhpu4m(
      this.ref.retainAndReturnPointer(),
      _sel_initWithContentsOfURL_error_,
      url.ref.pointer,
      error,
    );
    return _ret.address == 0 ? null : AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithData:error:
  AVAudioPlayer? initWithData(objc.NSData data, {required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error}) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.initWithData:error:',
      iOS: (false, (2, 2, 0)),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_1lhpu4m(
      this.ref.retainAndReturnPointer(),
      _sel_initWithData_error_,
      data.ref.pointer,
      error,
    );
    return _ret.address == 0 ? null : AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithContentsOfURL:fileTypeHint:error:
  AVAudioPlayer? initWithContentsOfURL$1(
    objc.NSURL url, {
    objc.NSString? fileTypeHint,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.initWithContentsOfURL:fileTypeHint:error:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_1pnyuds(
      this.ref.retainAndReturnPointer(),
      _sel_initWithContentsOfURL_fileTypeHint_error_,
      url.ref.pointer,
      fileTypeHint?.ref.pointer ?? ffi.nullptr,
      error,
    );
    return _ret.address == 0 ? null : AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithData:fileTypeHint:error:
  AVAudioPlayer? initWithData$1(
    objc.NSData data, {
    objc.NSString? fileTypeHint,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.initWithData:fileTypeHint:error:',
      iOS: (false, (7, 0, 0)),
      macOS: (false, (10, 9, 0)),
    );
    final _ret = _objc_msgSend_1pnyuds(
      this.ref.retainAndReturnPointer(),
      _sel_initWithData_fileTypeHint_error_,
      data.ref.pointer,
      fileTypeHint?.ref.pointer ?? ffi.nullptr,
      error,
    );
    return _ret.address == 0 ? null : AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// prepareToPlay
  bool prepareToPlay() {
    objc.checkOsVersionInternal('AVAudioPlayer.prepareToPlay', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_prepareToPlay);
  }

  /// play
  bool play() {
    objc.checkOsVersionInternal('AVAudioPlayer.play', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_play);
  }

  /// playAtTime:
  bool playAtTime(double time) {
    objc.checkOsVersionInternal('AVAudioPlayer.playAtTime:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_18chyc(this.ref.pointer, _sel_playAtTime_, time);
  }

  /// pause
  void pause() {
    objc.checkOsVersionInternal('AVAudioPlayer.pause', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_pause);
  }

  /// stop
  void stop() {
    objc.checkOsVersionInternal('AVAudioPlayer.stop', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_stop);
  }

  /// isPlaying
  bool get playing {
    objc.checkOsVersionInternal('AVAudioPlayer.isPlaying', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isPlaying);
  }

  /// numberOfChannels
  int get numberOfChannels {
    objc.checkOsVersionInternal('AVAudioPlayer.numberOfChannels', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_xw2lbc(this.ref.pointer, _sel_numberOfChannels);
  }

  /// duration
  double get duration {
    objc.checkOsVersionInternal('AVAudioPlayer.duration', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_duration)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_duration);
  }

  /// currentDevice
  objc.NSString? get currentDevice {
    objc.checkOsVersionInternal('AVAudioPlayer.currentDevice', iOS: (true, null), macOS: (false, (10, 13, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_currentDevice);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setCurrentDevice:
  set currentDevice(objc.NSString? value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setCurrentDevice:', iOS: (true, null), macOS: (false, (10, 13, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setCurrentDevice_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// delegate
  AVAudioPlayerDelegate? get delegate {
    objc.checkOsVersionInternal('AVAudioPlayer.delegate', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_delegate);
    return _ret.address == 0 ? null : AVAudioPlayerDelegate.castFromPointer(_ret, retain: true, release: true);
  }

  /// setDelegate:
  set delegate(AVAudioPlayerDelegate? value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setDelegate:', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setDelegate_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// url
  objc.NSURL? get url {
    objc.checkOsVersionInternal('AVAudioPlayer.url', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_url);
    return _ret.address == 0 ? null : objc.NSURL.castFromPointer(_ret, retain: true, release: true);
  }

  /// data
  objc.NSData? get data {
    objc.checkOsVersionInternal('AVAudioPlayer.data', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_data);
    return _ret.address == 0 ? null : objc.NSData.castFromPointer(_ret, retain: true, release: true);
  }

  /// pan
  double get pan {
    objc.checkOsVersionInternal('AVAudioPlayer.pan', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_pan)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_pan);
  }

  /// setPan:
  set pan(double value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setPan:', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setPan_, value);
  }

  /// volume
  double get volume {
    objc.checkOsVersionInternal('AVAudioPlayer.volume', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_volume)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_volume);
  }

  /// setVolume:
  set volume(double value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setVolume:', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setVolume_, value);
  }

  /// setVolume:fadeDuration:
  void setVolume(double volume$1, {required double fadeDuration}) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.setVolume:fadeDuration:',
      iOS: (false, (10, 0, 0)),
      macOS: (false, (10, 12, 0)),
    );
    _objc_msgSend_1p4uk9e(this.ref.pointer, _sel_setVolume_fadeDuration_, volume$1, fadeDuration);
  }

  /// enableRate
  bool get enableRate {
    objc.checkOsVersionInternal('AVAudioPlayer.enableRate', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_enableRate);
  }

  /// setEnableRate:
  set enableRate(bool value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setEnableRate:', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setEnableRate_, value);
  }

  /// rate
  double get rate {
    objc.checkOsVersionInternal('AVAudioPlayer.rate', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_2cgrxlFpret(this.ref.pointer, _sel_rate)
        : _objc_msgSend_2cgrxl(this.ref.pointer, _sel_rate);
  }

  /// setRate:
  set rate(double value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setRate:', iOS: (false, (5, 0, 0)), macOS: (false, (10, 8, 0)));
    _objc_msgSend_v5hmet(this.ref.pointer, _sel_setRate_, value);
  }

  /// currentTime
  double get currentTime {
    objc.checkOsVersionInternal('AVAudioPlayer.currentTime', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_currentTime)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_currentTime);
  }

  /// setCurrentTime:
  set currentTime(double value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setCurrentTime:', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_hwm8nu(this.ref.pointer, _sel_setCurrentTime_, value);
  }

  /// deviceCurrentTime
  double get deviceCurrentTime {
    objc.checkOsVersionInternal('AVAudioPlayer.deviceCurrentTime', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    return objc.useMsgSendVariants
        ? _objc_msgSend_1ukqyt8Fpret(this.ref.pointer, _sel_deviceCurrentTime)
        : _objc_msgSend_1ukqyt8(this.ref.pointer, _sel_deviceCurrentTime);
  }

  /// numberOfLoops
  int get numberOfLoops {
    objc.checkOsVersionInternal('AVAudioPlayer.numberOfLoops', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_1hz7y9r(this.ref.pointer, _sel_numberOfLoops);
  }

  /// setNumberOfLoops:
  set numberOfLoops(int value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setNumberOfLoops:', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_4sp4xj(this.ref.pointer, _sel_setNumberOfLoops_, value);
  }

  /// settings
  objc.NSDictionary get settings {
    objc.checkOsVersionInternal('AVAudioPlayer.settings', iOS: (false, (4, 0, 0)), macOS: (false, (10, 7, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_settings);
    return objc.NSDictionary.castFromPointer(_ret, retain: true, release: true);
  }

  /// format
  AVAudioFormat get format {
    objc.checkOsVersionInternal('AVAudioPlayer.format', iOS: (false, (10, 0, 0)), macOS: (false, (10, 12, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_format);
    return AVAudioFormat.castFromPointer(_ret, retain: true, release: true);
  }

  /// isMeteringEnabled
  bool get meteringEnabled {
    objc.checkOsVersionInternal('AVAudioPlayer.isMeteringEnabled', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isMeteringEnabled);
  }

  /// setMeteringEnabled:
  set meteringEnabled(bool value) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.setMeteringEnabled:',
      iOS: (false, (2, 2, 0)),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setMeteringEnabled_, value);
  }

  /// updateMeters
  void updateMeters() {
    objc.checkOsVersionInternal('AVAudioPlayer.updateMeters', iOS: (false, (2, 2, 0)), macOS: (false, (10, 7, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_updateMeters);
  }

  /// peakPowerForChannel:
  double peakPowerForChannel(int channelNumber) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.peakPowerForChannel:',
      iOS: (false, (2, 2, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_65s5ywFpret(this.ref.pointer, _sel_peakPowerForChannel_, channelNumber)
        : _objc_msgSend_65s5yw(this.ref.pointer, _sel_peakPowerForChannel_, channelNumber);
  }

  /// averagePowerForChannel:
  double averagePowerForChannel(int channelNumber) {
    objc.checkOsVersionInternal(
      'AVAudioPlayer.averagePowerForChannel:',
      iOS: (false, (2, 2, 0)),
      macOS: (false, (10, 7, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_65s5ywFpret(this.ref.pointer, _sel_averagePowerForChannel_, channelNumber)
        : _objc_msgSend_65s5yw(this.ref.pointer, _sel_averagePowerForChannel_, channelNumber);
  }

  /// channelAssignments
  objc.NSArray? get channelAssignments {
    objc.checkOsVersionInternal('AVAudioPlayer.channelAssignments', iOS: (false, (7, 0, 0)), macOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_channelAssignments);
    return _ret.address == 0 ? null : objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// setChannelAssignments:
  set channelAssignments(objc.NSArray? value) {
    objc.checkOsVersionInternal('AVAudioPlayer.setChannelAssignments:', iOS: (false, (7, 0, 0)), macOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setChannelAssignments_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// init
  AVAudioPlayer init() {
    objc.checkOsVersionInternal('AVAudioPlayer.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static AVAudioPlayer new$() {
    final _ret = _objc_msgSend_151sglz(_class_AVAudioPlayer, _sel_new);
    return AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static AVAudioPlayer allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_AVAudioPlayer, _sel_allocWithZone_, zone);
    return AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static AVAudioPlayer alloc() {
    final _ret = _objc_msgSend_151sglz(_class_AVAudioPlayer, _sel_alloc);
    return AVAudioPlayer.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  AVAudioPlayer self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return AVAudioPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  AVAudioPlayer retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return AVAudioPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  AVAudioPlayer autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return AVAudioPlayer.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of AVAudioPlayer constructed with the default `new` method.
  factory AVAudioPlayer() => new$();
}

late final _class_MPRemoteCommandCenter = objc.getClass("MPRemoteCommandCenter");
late final _class_MPRemoteCommand = objc.getClass("MPRemoteCommand");
late final _sel_isEnabled = objc.registerName("isEnabled");
late final _sel_setEnabled_ = objc.registerName("setEnabled:");
late final _sel_addTarget_action_ = objc.registerName("addTarget:action:");
final _objc_msgSend_1fn20c8 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
      )
    >();
late final _sel_removeTarget_action_ = objc.registerName("removeTarget:action:");
late final _sel_removeTarget_ = objc.registerName("removeTarget:");

enum MPRemoteCommandHandlerStatus {
  /// There was no error executing the requested command.
  MPRemoteCommandHandlerStatusSuccess(0),

  /// The command could not be executed because the requested content does not
  /// exist in the current application state.
  MPRemoteCommandHandlerStatusNoSuchContent(100),

  /// The command could not be executed because there is no now playing item
  /// available that is required for this command. As an example, an
  /// application would return this error code if an "enable language option"
  /// command is received, but nothing is currently playing.
  MPRemoteCommandHandlerStatusNoActionableNowPlayingItem(110),

  /// The command could not be executed because a device required
  /// is not available. For instance, if headphones are required, or if a watch
  /// app realizes that it needs the companion to fulfull a request.
  MPRemoteCommandHandlerStatusDeviceNotFound(120),

  /// The command could not be executed for another reason.
  MPRemoteCommandHandlerStatusCommandFailed(200);

  final int value;
  const MPRemoteCommandHandlerStatus(this.value);

  static MPRemoteCommandHandlerStatus fromValue(int value) => switch (value) {
    0 => MPRemoteCommandHandlerStatusSuccess,
    100 => MPRemoteCommandHandlerStatusNoSuchContent,
    110 => MPRemoteCommandHandlerStatusNoActionableNowPlayingItem,
    120 => MPRemoteCommandHandlerStatusDeviceNotFound,
    200 => MPRemoteCommandHandlerStatusCommandFailed,
    _ => throw ArgumentError('Unknown value for MPRemoteCommandHandlerStatus: $value'),
  };
}

/// WARNING: MPRemoteCommandEvent is a stub. To generate bindings for this class, include
/// MPRemoteCommandEvent in your config's objc-interfaces list.
///
/// MPRemoteCommandEvent
class MPRemoteCommandEvent extends objc.ObjCObjectBase {
  MPRemoteCommandEvent._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [MPRemoteCommandEvent] that points to the same underlying object as [other].
  MPRemoteCommandEvent.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPRemoteCommandEvent] that wraps the given raw object pointer.
  MPRemoteCommandEvent.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

int _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject> arg0)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Long Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_fnPtrTrampoline,
      0,
    ).cast();
int _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
) => (objc.getBlockClosure(block) as int Function(ffi.Pointer<objc.ObjCObject>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_closureCallable =
    ffi.Pointer.fromFunction<ffi.Long Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>(
      _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_closureTrampoline,
      0,
    ).cast();

/// Construction methods for `objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)>`.
abstract final class ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)>(
    objc.newPointerBlock(_ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)> fromFunction(
    MPRemoteCommandHandlerStatus Function(MPRemoteCommandEvent) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)>(
    objc.newClosureBlock(
      _ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0) =>
          fn(MPRemoteCommandEvent.castFromPointer(arg0, retain: true, release: true)).value,
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)>`.
extension ObjCBlock_MPRemoteCommandHandlerStatus_MPRemoteCommandEvent_CallExtension
    on objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)> {
  MPRemoteCommandHandlerStatus call(MPRemoteCommandEvent arg0) => MPRemoteCommandHandlerStatus.fromValue(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Long Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<objc.ObjCObject> arg0)
          >
        >()
        .asFunction<int Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>)>()(
      ref.pointer,
      arg0.ref.pointer,
    ),
  );
}

late final _sel_addTargetWithHandler_ = objc.registerName("addTargetWithHandler:");
final _objc_msgSend_nnxkei = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();

/// MPRemoteCommand
class MPRemoteCommand extends objc.NSObject {
  MPRemoteCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPRemoteCommand] that points to the same underlying object as [other].
  MPRemoteCommand.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPRemoteCommand] that wraps the given raw object pointer.
  MPRemoteCommand.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [MPRemoteCommand].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_MPRemoteCommand);
  }

  /// new
  static MPRemoteCommand new$() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommand, _sel_new);
    return MPRemoteCommand.castFromPointer(_ret, retain: false, release: true);
  }

  /// init
  MPRemoteCommand init() {
    objc.checkOsVersionInternal('MPRemoteCommand.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return MPRemoteCommand.castFromPointer(_ret, retain: false, release: true);
  }

  /// Whether a button (for example) should be enabled and tappable for this
  /// particular command.
  bool get enabled {
    objc.checkOsVersionInternal('MPRemoteCommand.isEnabled', iOS: (false, (7, 1, 0)), macOS: (false, (10, 12, 2)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isEnabled);
  }

  /// Whether a button (for example) should be enabled and tappable for this
  /// particular command.
  set enabled(bool value) {
    objc.checkOsVersionInternal('MPRemoteCommand.setEnabled:', iOS: (false, (7, 1, 0)), macOS: (false, (10, 12, 2)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setEnabled_, value);
  }

  /// addTarget:action:
  void addTarget(objc.ObjCObjectBase target, {required ffi.Pointer<objc.ObjCSelector> action}) {
    objc.checkOsVersionInternal(
      'MPRemoteCommand.addTarget:action:',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    _objc_msgSend_1fn20c8(this.ref.pointer, _sel_addTarget_action_, target.ref.pointer, action);
  }

  /// removeTarget:action:
  void removeTarget(objc.ObjCObjectBase target, {required ffi.Pointer<objc.ObjCSelector> action}) {
    objc.checkOsVersionInternal(
      'MPRemoteCommand.removeTarget:action:',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    _objc_msgSend_1fn20c8(this.ref.pointer, _sel_removeTarget_action_, target.ref.pointer, action);
  }

  /// removeTarget:
  void removeTarget$1(objc.ObjCObjectBase? target) {
    objc.checkOsVersionInternal('MPRemoteCommand.removeTarget:', iOS: (false, (7, 1, 0)), macOS: (false, (10, 12, 2)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeTarget_, target?.ref.pointer ?? ffi.nullptr);
  }

  /// Returns an opaque object to act as the target.
  objc.ObjCObjectBase addTargetWithHandler(objc.ObjCBlock<ffi.Long Function(MPRemoteCommandEvent)> handler) {
    objc.checkOsVersionInternal(
      'MPRemoteCommand.addTargetWithHandler:',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_nnxkei(this.ref.pointer, _sel_addTargetWithHandler_, handler.ref.pointer);
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// allocWithZone:
  static MPRemoteCommand allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_MPRemoteCommand, _sel_allocWithZone_, zone);
    return MPRemoteCommand.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static MPRemoteCommand alloc() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommand, _sel_alloc);
    return MPRemoteCommand.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  MPRemoteCommand self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  MPRemoteCommand retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  MPRemoteCommand autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of MPRemoteCommand constructed with the default `new` method.
  factory MPRemoteCommand() => new$();
}

late final _sel_pauseCommand = objc.registerName("pauseCommand");
late final _sel_playCommand = objc.registerName("playCommand");
late final _sel_stopCommand = objc.registerName("stopCommand");
late final _sel_togglePlayPauseCommand = objc.registerName("togglePlayPauseCommand");
late final _sel_enableLanguageOptionCommand = objc.registerName("enableLanguageOptionCommand");
late final _sel_disableLanguageOptionCommand = objc.registerName("disableLanguageOptionCommand");

/// WARNING: MPChangePlaybackRateCommand is a stub. To generate bindings for this class, include
/// MPChangePlaybackRateCommand in your config's objc-interfaces list.
///
/// MPChangePlaybackRateCommand
class MPChangePlaybackRateCommand extends MPRemoteCommand {
  MPChangePlaybackRateCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPChangePlaybackRateCommand] that points to the same underlying object as [other].
  MPChangePlaybackRateCommand.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPChangePlaybackRateCommand] that wraps the given raw object pointer.
  MPChangePlaybackRateCommand.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_changePlaybackRateCommand = objc.registerName("changePlaybackRateCommand");

/// WARNING: MPChangeRepeatModeCommand is a stub. To generate bindings for this class, include
/// MPChangeRepeatModeCommand in your config's objc-interfaces list.
///
/// MPChangeRepeatModeCommand
class MPChangeRepeatModeCommand extends MPRemoteCommand {
  MPChangeRepeatModeCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPChangeRepeatModeCommand] that points to the same underlying object as [other].
  MPChangeRepeatModeCommand.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPChangeRepeatModeCommand] that wraps the given raw object pointer.
  MPChangeRepeatModeCommand.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_changeRepeatModeCommand = objc.registerName("changeRepeatModeCommand");

/// WARNING: MPChangeShuffleModeCommand is a stub. To generate bindings for this class, include
/// MPChangeShuffleModeCommand in your config's objc-interfaces list.
///
/// MPChangeShuffleModeCommand
class MPChangeShuffleModeCommand extends MPRemoteCommand {
  MPChangeShuffleModeCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPChangeShuffleModeCommand] that points to the same underlying object as [other].
  MPChangeShuffleModeCommand.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPChangeShuffleModeCommand] that wraps the given raw object pointer.
  MPChangeShuffleModeCommand.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_changeShuffleModeCommand = objc.registerName("changeShuffleModeCommand");
late final _sel_nextTrackCommand = objc.registerName("nextTrackCommand");
late final _sel_previousTrackCommand = objc.registerName("previousTrackCommand");

/// WARNING: MPSkipIntervalCommand is a stub. To generate bindings for this class, include
/// MPSkipIntervalCommand in your config's objc-interfaces list.
///
/// MPSkipIntervalCommand
class MPSkipIntervalCommand extends MPRemoteCommand {
  MPSkipIntervalCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPSkipIntervalCommand] that points to the same underlying object as [other].
  MPSkipIntervalCommand.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPSkipIntervalCommand] that wraps the given raw object pointer.
  MPSkipIntervalCommand.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_skipForwardCommand = objc.registerName("skipForwardCommand");
late final _sel_skipBackwardCommand = objc.registerName("skipBackwardCommand");
late final _sel_seekForwardCommand = objc.registerName("seekForwardCommand");
late final _sel_seekBackwardCommand = objc.registerName("seekBackwardCommand");

/// WARNING: MPChangePlaybackPositionCommand is a stub. To generate bindings for this class, include
/// MPChangePlaybackPositionCommand in your config's objc-interfaces list.
///
/// MPChangePlaybackPositionCommand
class MPChangePlaybackPositionCommand extends MPRemoteCommand {
  MPChangePlaybackPositionCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPChangePlaybackPositionCommand] that points to the same underlying object as [other].
  MPChangePlaybackPositionCommand.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPChangePlaybackPositionCommand] that wraps the given raw object pointer.
  MPChangePlaybackPositionCommand.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_changePlaybackPositionCommand = objc.registerName("changePlaybackPositionCommand");

/// WARNING: MPRatingCommand is a stub. To generate bindings for this class, include
/// MPRatingCommand in your config's objc-interfaces list.
///
/// MPRatingCommand
class MPRatingCommand extends MPRemoteCommand {
  MPRatingCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPRatingCommand] that points to the same underlying object as [other].
  MPRatingCommand.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPRatingCommand] that wraps the given raw object pointer.
  MPRatingCommand.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_ratingCommand = objc.registerName("ratingCommand");

/// WARNING: MPFeedbackCommand is a stub. To generate bindings for this class, include
/// MPFeedbackCommand in your config's objc-interfaces list.
///
/// MPFeedbackCommand
class MPFeedbackCommand extends MPRemoteCommand {
  MPFeedbackCommand._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPFeedbackCommand] that points to the same underlying object as [other].
  MPFeedbackCommand.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPFeedbackCommand] that wraps the given raw object pointer.
  MPFeedbackCommand.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_likeCommand = objc.registerName("likeCommand");
late final _sel_dislikeCommand = objc.registerName("dislikeCommand");
late final _sel_bookmarkCommand = objc.registerName("bookmarkCommand");
late final _sel_sharedCommandCenter = objc.registerName("sharedCommandCenter");

/// MPRemoteCommandCenter
class MPRemoteCommandCenter extends objc.NSObject {
  MPRemoteCommandCenter._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('MPRemoteCommandCenter', iOS: (false, (7, 1, 0)), macOS: (false, (10, 12, 2)));
  }

  /// Constructs a [MPRemoteCommandCenter] that points to the same underlying object as [other].
  MPRemoteCommandCenter.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPRemoteCommandCenter] that wraps the given raw object pointer.
  MPRemoteCommandCenter.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [MPRemoteCommandCenter].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_MPRemoteCommandCenter);
  }

  /// pauseCommand
  MPRemoteCommand get pauseCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.pauseCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_pauseCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// playCommand
  MPRemoteCommand get playCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.playCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_playCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// stopCommand
  MPRemoteCommand get stopCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.stopCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_stopCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// togglePlayPauseCommand
  MPRemoteCommand get togglePlayPauseCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.togglePlayPauseCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_togglePlayPauseCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// enableLanguageOptionCommand
  MPRemoteCommand get enableLanguageOptionCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.enableLanguageOptionCommand',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_enableLanguageOptionCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// disableLanguageOptionCommand
  MPRemoteCommand get disableLanguageOptionCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.disableLanguageOptionCommand',
      iOS: (false, (9, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_disableLanguageOptionCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// changePlaybackRateCommand
  MPChangePlaybackRateCommand get changePlaybackRateCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.changePlaybackRateCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_changePlaybackRateCommand);
    return MPChangePlaybackRateCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// changeRepeatModeCommand
  MPChangeRepeatModeCommand get changeRepeatModeCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.changeRepeatModeCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_changeRepeatModeCommand);
    return MPChangeRepeatModeCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// changeShuffleModeCommand
  MPChangeShuffleModeCommand get changeShuffleModeCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.changeShuffleModeCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_changeShuffleModeCommand);
    return MPChangeShuffleModeCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// nextTrackCommand
  MPRemoteCommand get nextTrackCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.nextTrackCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_nextTrackCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// previousTrackCommand
  MPRemoteCommand get previousTrackCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.previousTrackCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_previousTrackCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// skipForwardCommand
  MPSkipIntervalCommand get skipForwardCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.skipForwardCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_skipForwardCommand);
    return MPSkipIntervalCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// skipBackwardCommand
  MPSkipIntervalCommand get skipBackwardCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.skipBackwardCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_skipBackwardCommand);
    return MPSkipIntervalCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// seekForwardCommand
  MPRemoteCommand get seekForwardCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.seekForwardCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_seekForwardCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// seekBackwardCommand
  MPRemoteCommand get seekBackwardCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.seekBackwardCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_seekBackwardCommand);
    return MPRemoteCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// changePlaybackPositionCommand
  MPChangePlaybackPositionCommand get changePlaybackPositionCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.changePlaybackPositionCommand',
      iOS: (false, (9, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_changePlaybackPositionCommand);
    return MPChangePlaybackPositionCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// ratingCommand
  MPRatingCommand get ratingCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.ratingCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_ratingCommand);
    return MPRatingCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// likeCommand
  MPFeedbackCommand get likeCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.likeCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_likeCommand);
    return MPFeedbackCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// dislikeCommand
  MPFeedbackCommand get dislikeCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.dislikeCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_dislikeCommand);
    return MPFeedbackCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// bookmarkCommand
  MPFeedbackCommand get bookmarkCommand {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.bookmarkCommand',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_bookmarkCommand);
    return MPFeedbackCommand.castFromPointer(_ret, retain: true, release: true);
  }

  /// sharedCommandCenter
  static MPRemoteCommandCenter sharedCommandCenter() {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenter.sharedCommandCenter',
      iOS: (false, (7, 1, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommandCenter, _sel_sharedCommandCenter);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// new
  static MPRemoteCommandCenter new$() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommandCenter, _sel_new);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// init
  MPRemoteCommandCenter init() {
    objc.checkOsVersionInternal('MPRemoteCommandCenter.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static MPRemoteCommandCenter allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_MPRemoteCommandCenter, _sel_allocWithZone_, zone);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static MPRemoteCommandCenter alloc() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommandCenter, _sel_alloc);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  MPRemoteCommandCenter self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  MPRemoteCommandCenter retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  MPRemoteCommandCenter autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return MPRemoteCommandCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of MPRemoteCommandCenter constructed with the default `new` method.
  factory MPRemoteCommandCenter() => new$();
}

enum MPShuffleType {
  MPShuffleTypeOff(0),
  MPShuffleTypeItems(1),
  MPShuffleTypeCollections(2);

  final int value;
  const MPShuffleType(this.value);

  static MPShuffleType fromValue(int value) => switch (value) {
    0 => MPShuffleTypeOff,
    1 => MPShuffleTypeItems,
    2 => MPShuffleTypeCollections,
    _ => throw ArgumentError('Unknown value for MPShuffleType: $value'),
  };
}

enum MPRepeatType {
  MPRepeatTypeOff(0),
  MPRepeatTypeOne(1),
  MPRepeatTypeAll(2);

  final int value;
  const MPRepeatType(this.value);

  static MPRepeatType fromValue(int value) => switch (value) {
    0 => MPRepeatTypeOff,
    1 => MPRepeatTypeOne,
    2 => MPRepeatTypeAll,
    _ => throw ArgumentError('Unknown value for MPRepeatType: $value'),
  };
}

enum MPNowPlayingPlaybackState {
  MPNowPlayingPlaybackStateUnknown(0),
  MPNowPlayingPlaybackStatePlaying(1),
  MPNowPlayingPlaybackStatePaused(2),
  MPNowPlayingPlaybackStateStopped(3),
  MPNowPlayingPlaybackStateInterrupted(4);

  final int value;
  const MPNowPlayingPlaybackState(this.value);

  static MPNowPlayingPlaybackState fromValue(int value) => switch (value) {
    0 => MPNowPlayingPlaybackStateUnknown,
    1 => MPNowPlayingPlaybackStatePlaying,
    2 => MPNowPlayingPlaybackStatePaused,
    3 => MPNowPlayingPlaybackStateStopped,
    4 => MPNowPlayingPlaybackStateInterrupted,
    _ => throw ArgumentError('Unknown value for MPNowPlayingPlaybackState: $value'),
  };
}

late final _class_MPNowPlayingInfoCenter = objc.getClass("MPNowPlayingInfoCenter");
late final _sel_defaultCenter = objc.registerName("defaultCenter");
late final _sel_nowPlayingInfo = objc.registerName("nowPlayingInfo");
late final _sel_setNowPlayingInfo_ = objc.registerName("setNowPlayingInfo:");
late final _sel_playbackState = objc.registerName("playbackState");
final _objc_msgSend_1pl2tiw = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setPlaybackState_ = objc.registerName("setPlaybackState:");
final _objc_msgSend_1rihg3y = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// MPNowPlayingInfoCenter
class MPNowPlayingInfoCenter extends objc.NSObject {
  MPNowPlayingInfoCenter._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('MPNowPlayingInfoCenter', iOS: (false, (5, 0, 0)), macOS: (false, (10, 12, 2)));
  }

  /// Constructs a [MPNowPlayingInfoCenter] that points to the same underlying object as [other].
  MPNowPlayingInfoCenter.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPNowPlayingInfoCenter] that wraps the given raw object pointer.
  MPNowPlayingInfoCenter.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [MPNowPlayingInfoCenter].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_MPNowPlayingInfoCenter);
  }

  /// Returns the default now playing info center.
  /// The default center holds now playing info about the current application.
  static MPNowPlayingInfoCenter defaultCenter() {
    objc.checkOsVersionInternal(
      'MPNowPlayingInfoCenter.defaultCenter',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(_class_MPNowPlayingInfoCenter, _sel_defaultCenter);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// new
  static MPNowPlayingInfoCenter new$() {
    final _ret = _objc_msgSend_151sglz(_class_MPNowPlayingInfoCenter, _sel_new);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// init
  MPNowPlayingInfoCenter init() {
    objc.checkOsVersionInternal('MPNowPlayingInfoCenter.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// The current now playing info for the center.
  /// Setting the info to nil will clear it.
  objc.NSDictionary? get nowPlayingInfo {
    objc.checkOsVersionInternal(
      'MPNowPlayingInfoCenter.nowPlayingInfo',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_nowPlayingInfo);
    return _ret.address == 0 ? null : objc.NSDictionary.castFromPointer(_ret, retain: true, release: true);
  }

  /// The current now playing info for the center.
  /// Setting the info to nil will clear it.
  set nowPlayingInfo(objc.NSDictionary? value) {
    objc.checkOsVersionInternal(
      'MPNowPlayingInfoCenter.setNowPlayingInfo:',
      iOS: (false, (5, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setNowPlayingInfo_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// The current playback state of the app.
  /// This only applies on macOS, where playback state cannot be determined by
  /// the application's audio session. This property must be set every time
  /// the app begins or halts playback, otherwise remote control functionality may
  /// not work as expected.
  MPNowPlayingPlaybackState get playbackState {
    objc.checkOsVersionInternal(
      'MPNowPlayingInfoCenter.playbackState',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    final _ret = _objc_msgSend_1pl2tiw(this.ref.pointer, _sel_playbackState);
    return MPNowPlayingPlaybackState.fromValue(_ret);
  }

  /// The current playback state of the app.
  /// This only applies on macOS, where playback state cannot be determined by
  /// the application's audio session. This property must be set every time
  /// the app begins or halts playback, otherwise remote control functionality may
  /// not work as expected.
  set playbackState(MPNowPlayingPlaybackState value) {
    objc.checkOsVersionInternal(
      'MPNowPlayingInfoCenter.setPlaybackState:',
      iOS: (false, (13, 0, 0)),
      macOS: (false, (10, 12, 2)),
    );
    _objc_msgSend_1rihg3y(this.ref.pointer, _sel_setPlaybackState_, value.value);
  }

  /// allocWithZone:
  static MPNowPlayingInfoCenter allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_MPNowPlayingInfoCenter, _sel_allocWithZone_, zone);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static MPNowPlayingInfoCenter alloc() {
    final _ret = _objc_msgSend_151sglz(_class_MPNowPlayingInfoCenter, _sel_alloc);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  MPNowPlayingInfoCenter self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  MPNowPlayingInfoCenter retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  MPNowPlayingInfoCenter autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return MPNowPlayingInfoCenter.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of MPNowPlayingInfoCenter constructed with the default `new` method.
  factory MPNowPlayingInfoCenter() => new$();
}

late final _class_MPMediaItemArtwork = objc.getClass("MPMediaItemArtwork");
late final _class_NSImage = objc.getClass("NSImage");

/// WARNING: NSPasteboardReading is a stub. To generate bindings for this class, include
/// NSPasteboardReading in your config's objc-protocols list.
///
/// NSPasteboardReading
interface class NSPasteboardReading extends objc.ObjCProtocolBase implements objc.NSObjectProtocol {
  NSPasteboardReading._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [NSPasteboardReading] that points to the same underlying object as [other].
  NSPasteboardReading.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSPasteboardReading] that wraps the given raw object pointer.
  NSPasteboardReading.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

/// WARNING: NSPasteboardWriting is a stub. To generate bindings for this class, include
/// NSPasteboardWriting in your config's objc-protocols list.
///
/// NSPasteboardWriting
interface class NSPasteboardWriting extends objc.ObjCProtocolBase implements objc.NSObjectProtocol {
  NSPasteboardWriting._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [NSPasteboardWriting] that points to the same underlying object as [other].
  NSPasteboardWriting.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSPasteboardWriting] that wraps the given raw object pointer.
  NSPasteboardWriting.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

///
extension unnamed on NSImage {}

///
extension unnamed$1 on NSImage {}

late final _sel_imageUnfilteredFileTypes = objc.registerName("imageUnfilteredFileTypes");
late final _sel_imageUnfilteredPasteboardTypes = objc.registerName("imageUnfilteredPasteboardTypes");
late final _sel_imageFileTypes = objc.registerName("imageFileTypes");
late final _sel_imagePasteboardTypes = objc.registerName("imagePasteboardTypes");

/// WARNING: NSImageRep is a stub. To generate bindings for this class, include
/// NSImageRep in your config's objc-interfaces list.
///
/// NSImageRep
class NSImageRep extends objc.NSObject implements objc.NSCopying, objc.NSCoding {
  NSImageRep._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('NSImageRep', iOS: (true, null));
  }

  /// Constructs a [NSImageRep] that points to the same underlying object as [other].
  NSImageRep.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSImageRep] that wraps the given raw object pointer.
  NSImageRep.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_bestRepresentationForDevice_ = objc.registerName("bestRepresentationForDevice:");
late final _sel_lockFocus = objc.registerName("lockFocus");
late final _sel_lockFocusFlipped_ = objc.registerName("lockFocusFlipped:");
late final _sel_unlockFocus = objc.registerName("unlockFocus");
late final _sel_setFlipped_ = objc.registerName("setFlipped:");
late final _sel_isFlipped = objc.registerName("isFlipped");
late final _sel_setScalesWhenResized_ = objc.registerName("setScalesWhenResized:");
late final _sel_scalesWhenResized = objc.registerName("scalesWhenResized");
late final _sel_setDataRetained_ = objc.registerName("setDataRetained:");
late final _sel_isDataRetained = objc.registerName("isDataRetained");
late final _sel_setCachedSeparately_ = objc.registerName("setCachedSeparately:");
late final _sel_isCachedSeparately = objc.registerName("isCachedSeparately");
late final _sel_setCacheDepthMatchesImageDepth_ = objc.registerName("setCacheDepthMatchesImageDepth:");
late final _sel_cacheDepthMatchesImageDepth = objc.registerName("cacheDepthMatchesImageDepth");
late final _sel_dissolveToPoint_fraction_ = objc.registerName("dissolveToPoint:fraction:");
final _objc_msgSend_1lkz44l = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, ffi.Double)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, double)>();
late final _sel_dissolveToPoint_fromRect_fraction_ = objc.registerName("dissolveToPoint:fromRect:fraction:");
final _objc_msgSend_93gyx4 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGPoint,
          objc.CGRect,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, objc.CGRect, double)
    >();

enum NSCompositingOperation {
  NSCompositingOperationClear(0),
  NSCompositingOperationCopy(1),
  NSCompositingOperationSourceOver(2),
  NSCompositingOperationSourceIn(3),
  NSCompositingOperationSourceOut(4),
  NSCompositingOperationSourceAtop(5),
  NSCompositingOperationDestinationOver(6),
  NSCompositingOperationDestinationIn(7),
  NSCompositingOperationDestinationOut(8),
  NSCompositingOperationDestinationAtop(9),
  NSCompositingOperationXOR(10),
  NSCompositingOperationPlusDarker(11),
  NSCompositingOperationHighlight(12),
  NSCompositingOperationPlusLighter(13),
  NSCompositingOperationMultiply(14),
  NSCompositingOperationScreen(15),
  NSCompositingOperationOverlay(16),
  NSCompositingOperationDarken(17),
  NSCompositingOperationLighten(18),
  NSCompositingOperationColorDodge(19),
  NSCompositingOperationColorBurn(20),
  NSCompositingOperationSoftLight(21),
  NSCompositingOperationHardLight(22),
  NSCompositingOperationDifference(23),
  NSCompositingOperationExclusion(24),
  NSCompositingOperationHue(25),
  NSCompositingOperationSaturation(26),
  NSCompositingOperationColor(27),
  NSCompositingOperationLuminosity(28);

  final int value;
  const NSCompositingOperation(this.value);

  static NSCompositingOperation fromValue(int value) => switch (value) {
    0 => NSCompositingOperationClear,
    1 => NSCompositingOperationCopy,
    2 => NSCompositingOperationSourceOver,
    3 => NSCompositingOperationSourceIn,
    4 => NSCompositingOperationSourceOut,
    5 => NSCompositingOperationSourceAtop,
    6 => NSCompositingOperationDestinationOver,
    7 => NSCompositingOperationDestinationIn,
    8 => NSCompositingOperationDestinationOut,
    9 => NSCompositingOperationDestinationAtop,
    10 => NSCompositingOperationXOR,
    11 => NSCompositingOperationPlusDarker,
    12 => NSCompositingOperationHighlight,
    13 => NSCompositingOperationPlusLighter,
    14 => NSCompositingOperationMultiply,
    15 => NSCompositingOperationScreen,
    16 => NSCompositingOperationOverlay,
    17 => NSCompositingOperationDarken,
    18 => NSCompositingOperationLighten,
    19 => NSCompositingOperationColorDodge,
    20 => NSCompositingOperationColorBurn,
    21 => NSCompositingOperationSoftLight,
    22 => NSCompositingOperationHardLight,
    23 => NSCompositingOperationDifference,
    24 => NSCompositingOperationExclusion,
    25 => NSCompositingOperationHue,
    26 => NSCompositingOperationSaturation,
    27 => NSCompositingOperationColor,
    28 => NSCompositingOperationLuminosity,
    _ => throw ArgumentError('Unknown value for NSCompositingOperation: $value'),
  };
}

late final _sel_compositeToPoint_operation_ = objc.registerName("compositeToPoint:operation:");
final _objc_msgSend_tutwec = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, int)>();
late final _sel_compositeToPoint_fromRect_operation_ = objc.registerName("compositeToPoint:fromRect:operation:");
final _objc_msgSend_bjle81 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGPoint,
          objc.CGRect,
          ffi.UnsignedLong,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, objc.CGRect, int)
    >();
late final _sel_compositeToPoint_operation_fraction_ = objc.registerName("compositeToPoint:operation:fraction:");
final _objc_msgSend_16t8gcf = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGPoint,
          ffi.UnsignedLong,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGPoint, int, double)
    >();
late final _sel_compositeToPoint_fromRect_operation_fraction_ = objc.registerName(
  "compositeToPoint:fromRect:operation:fraction:",
);
final _objc_msgSend_1xnlu4e = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGPoint,
          objc.CGRect,
          ffi.UnsignedLong,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGPoint,
        objc.CGRect,
        int,
        double,
      )
    >();
late final _sel_lockFocusOnRepresentation_ = objc.registerName("lockFocusOnRepresentation:");
late final _sel_cancelIncrementalLoad = objc.registerName("cancelIncrementalLoad");

/// Deprecated
extension Deprecated on NSImage {
  /// imageUnfilteredFileTypes
  static objc.NSArray imageUnfilteredFileTypes() {
    objc.checkOsVersionInternal('NSImage.imageUnfilteredFileTypes', iOS: (true, null), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imageUnfilteredFileTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// imageUnfilteredPasteboardTypes
  static objc.NSArray imageUnfilteredPasteboardTypes() {
    objc.checkOsVersionInternal(
      'NSImage.imageUnfilteredPasteboardTypes',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imageUnfilteredPasteboardTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// imageFileTypes
  static objc.NSArray imageFileTypes() {
    objc.checkOsVersionInternal('NSImage.imageFileTypes', iOS: (true, null), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imageFileTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// imagePasteboardTypes
  static objc.NSArray imagePasteboardTypes() {
    objc.checkOsVersionInternal('NSImage.imagePasteboardTypes', iOS: (true, null), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imagePasteboardTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// bestRepresentationForDevice:
  NSImageRep bestRepresentationForDevice(objc.NSDictionary deviceDescription) {
    objc.checkOsVersionInternal('NSImage.bestRepresentationForDevice:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.pointer,
      _sel_bestRepresentationForDevice_,
      deviceDescription.ref.pointer,
    );
    return NSImageRep.castFromPointer(_ret, retain: true, release: true);
  }

  /// lockFocus
  void lockFocus() {
    objc.checkOsVersionInternal('NSImage.lockFocus', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_lockFocus);
  }

  /// lockFocusFlipped:
  void lockFocusFlipped(bool flipped) {
    objc.checkOsVersionInternal('NSImage.lockFocusFlipped:', iOS: (true, null), macOS: (false, (10, 6, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_lockFocusFlipped_, flipped);
  }

  /// unlockFocus
  void unlockFocus() {
    objc.checkOsVersionInternal('NSImage.unlockFocus', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_unlockFocus);
  }

  /// setFlipped:
  void setFlipped(bool flag) {
    objc.checkOsVersionInternal('NSImage.setFlipped:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setFlipped_, flag);
  }

  /// isFlipped
  bool isFlipped() {
    objc.checkOsVersionInternal('NSImage.isFlipped', iOS: (true, null), macOS: (false, (10, 0, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isFlipped);
  }

  /// setScalesWhenResized:
  void setScalesWhenResized(bool flag) {
    objc.checkOsVersionInternal('NSImage.setScalesWhenResized:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setScalesWhenResized_, flag);
  }

  /// scalesWhenResized
  bool scalesWhenResized() {
    objc.checkOsVersionInternal('NSImage.scalesWhenResized', iOS: (true, null), macOS: (false, (10, 0, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_scalesWhenResized);
  }

  /// setDataRetained:
  void setDataRetained(bool flag) {
    objc.checkOsVersionInternal('NSImage.setDataRetained:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setDataRetained_, flag);
  }

  /// isDataRetained
  bool isDataRetained() {
    objc.checkOsVersionInternal('NSImage.isDataRetained', iOS: (true, null), macOS: (false, (10, 0, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isDataRetained);
  }

  /// setCachedSeparately:
  void setCachedSeparately(bool flag) {
    objc.checkOsVersionInternal('NSImage.setCachedSeparately:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setCachedSeparately_, flag);
  }

  /// isCachedSeparately
  bool isCachedSeparately() {
    objc.checkOsVersionInternal('NSImage.isCachedSeparately', iOS: (true, null), macOS: (false, (10, 0, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isCachedSeparately);
  }

  /// setCacheDepthMatchesImageDepth:
  void setCacheDepthMatchesImageDepth(bool flag) {
    objc.checkOsVersionInternal(
      'NSImage.setCacheDepthMatchesImageDepth:',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setCacheDepthMatchesImageDepth_, flag);
  }

  /// cacheDepthMatchesImageDepth
  bool cacheDepthMatchesImageDepth() {
    objc.checkOsVersionInternal('NSImage.cacheDepthMatchesImageDepth', iOS: (true, null), macOS: (false, (10, 0, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_cacheDepthMatchesImageDepth);
  }

  /// dissolveToPoint:fraction:
  void dissolveToPoint(objc.CGPoint point, {required double fraction}) {
    objc.checkOsVersionInternal('NSImage.dissolveToPoint:fraction:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1lkz44l(this.ref.pointer, _sel_dissolveToPoint_fraction_, point, fraction);
  }

  /// dissolveToPoint:fromRect:fraction:
  void dissolveToPoint$1(objc.CGPoint point, {required objc.CGRect fromRect, required double fraction}) {
    objc.checkOsVersionInternal(
      'NSImage.dissolveToPoint:fromRect:fraction:',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    _objc_msgSend_93gyx4(this.ref.pointer, _sel_dissolveToPoint_fromRect_fraction_, point, fromRect, fraction);
  }

  /// compositeToPoint:operation:
  void compositeToPoint(objc.CGPoint point, {required NSCompositingOperation operation}) {
    objc.checkOsVersionInternal('NSImage.compositeToPoint:operation:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_tutwec(this.ref.pointer, _sel_compositeToPoint_operation_, point, operation.value);
  }

  /// compositeToPoint:fromRect:operation:
  void compositeToPoint$1(
    objc.CGPoint point, {
    required objc.CGRect fromRect,
    required NSCompositingOperation operation,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.compositeToPoint:fromRect:operation:',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    _objc_msgSend_bjle81(this.ref.pointer, _sel_compositeToPoint_fromRect_operation_, point, fromRect, operation.value);
  }

  /// compositeToPoint:operation:fraction:
  void compositeToPoint$2(objc.CGPoint point, {required NSCompositingOperation operation, required double fraction}) {
    objc.checkOsVersionInternal(
      'NSImage.compositeToPoint:operation:fraction:',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    _objc_msgSend_16t8gcf(
      this.ref.pointer,
      _sel_compositeToPoint_operation_fraction_,
      point,
      operation.value,
      fraction,
    );
  }

  /// compositeToPoint:fromRect:operation:fraction:
  void compositeToPoint$3(
    objc.CGPoint point, {
    required objc.CGRect fromRect,
    required NSCompositingOperation operation,
    required double fraction,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.compositeToPoint:fromRect:operation:fraction:',
      iOS: (true, null),
      macOS: (false, (10, 0, 0)),
    );
    _objc_msgSend_1xnlu4e(
      this.ref.pointer,
      _sel_compositeToPoint_fromRect_operation_fraction_,
      point,
      fromRect,
      operation.value,
      fraction,
    );
  }

  /// lockFocusOnRepresentation:
  void lockFocusOnRepresentation(NSImageRep imageRepresentation) {
    objc.checkOsVersionInternal('NSImage.lockFocusOnRepresentation:', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_lockFocusOnRepresentation_, imageRepresentation.ref.pointer);
  }

  /// cancelIncrementalLoad
  void cancelIncrementalLoad() {
    objc.checkOsVersionInternal('NSImage.cancelIncrementalLoad', iOS: (true, null), macOS: (false, (10, 0, 0)));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_cancelIncrementalLoad);
  }
}

late final _sel_imageNamed_ = objc.registerName("imageNamed:");
late final _sel_imageWithSystemSymbolName_accessibilityDescription_ = objc.registerName(
  "imageWithSystemSymbolName:accessibilityDescription:",
);
late final _sel_imageWithSystemSymbolName_variableValue_accessibilityDescription_ = objc.registerName(
  "imageWithSystemSymbolName:variableValue:accessibilityDescription:",
);
final _objc_msgSend_17i4wqy = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Double,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        double,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_imageWithSymbolName_variableValue_ = objc.registerName("imageWithSymbolName:variableValue:");
final _objc_msgSend_6plvbo = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        double,
      )
    >();
late final _sel_imageWithSymbolName_bundle_variableValue_ = objc.registerName(
  "imageWithSymbolName:bundle:variableValue:",
);
final _objc_msgSend_hzzkpm = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        double,
      )
    >();
late final _sel_initWithSize_ = objc.registerName("initWithSize:");
final _objc_msgSend_1c2zpn3 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGSize)
    >();
late final _sel_initWithCoder_ = objc.registerName("initWithCoder:");
instancetype _ObjCBlock_instancetype_ffiVoid_NSCoder_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<instancetype Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<instancetype Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_instancetype_ffiVoid_NSCoder_fnPtrCallable =
    ffi.Pointer.fromFunction<
          instancetype Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_instancetype_ffiVoid_NSCoder_fnPtrTrampoline)
        .cast();
instancetype _ObjCBlock_instancetype_ffiVoid_NSCoder_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as instancetype Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_instancetype_ffiVoid_NSCoder_closureCallable =
    ffi.Pointer.fromFunction<
          instancetype Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_instancetype_ffiVoid_NSCoder_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>`.
abstract final class ObjCBlock_instancetype_ffiVoid_NSCoder {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
        pointer,
        retain: retain,
        release: release,
      );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<instancetype Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
    objc.newPointerBlock(_ObjCBlock_instancetype_ffiVoid_NSCoder_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>
  fromFunction(Dartinstancetype? Function(ffi.Pointer<ffi.Void>, objc.NSCoder) fn, {bool keepIsolateAlive = true}) =>
      objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
        objc.newClosureBlock(
          _ObjCBlock_instancetype_ffiVoid_NSCoder_closureCallable,
          (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
              fn(arg0, objc.NSCoder.castFromPointer(arg1, retain: true, release: true))?.ref.retainAndReturnPointer() ??
              ffi.nullptr,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>`.
extension ObjCBlock_instancetype_ffiVoid_NSCoder_CallExtension
    on objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> {
  Dartinstancetype? call(ffi.Pointer<ffi.Void> arg0, objc.NSCoder arg1) =>
      ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  instancetype Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                  )
                >
              >()
              .asFunction<
                instancetype Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer)
              .address ==
          0
      ? null
      : objc.ObjCObjectBase(
          ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  instancetype Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                  )
                >
              >()
              .asFunction<
                instancetype Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer),
          retain: false,
          release: true,
        );
}

late final _sel_initWithData_ = objc.registerName("initWithData:");
late final _sel_initWithContentsOfFile_ = objc.registerName("initWithContentsOfFile:");
late final _sel_initWithContentsOfURL_ = objc.registerName("initWithContentsOfURL:");
late final _sel_initByReferencingFile_ = objc.registerName("initByReferencingFile:");
late final _sel_initByReferencingURL_ = objc.registerName("initByReferencingURL:");

/// WARNING: NSPasteboard is a stub. To generate bindings for this class, include
/// NSPasteboard in your config's objc-interfaces list.
///
/// NSPasteboard
class NSPasteboard extends objc.NSObject {
  NSPasteboard._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('NSPasteboard', iOS: (true, null));
  }

  /// Constructs a [NSPasteboard] that points to the same underlying object as [other].
  NSPasteboard.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSPasteboard] that wraps the given raw object pointer.
  NSPasteboard.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_initWithPasteboard_ = objc.registerName("initWithPasteboard:");
late final _sel_initWithDataIgnoringOrientation_ = objc.registerName("initWithDataIgnoringOrientation:");
bool _ObjCBlock_bool_NSRect_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, objc.CGRect arg0) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Bool Function(objc.CGRect arg0)>>()
    .asFunction<bool Function(objc.CGRect)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_bool_NSRect_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGRect)>(
      _ObjCBlock_bool_NSRect_fnPtrTrampoline,
      false,
    ).cast();
bool _ObjCBlock_bool_NSRect_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, objc.CGRect arg0) =>
    (objc.getBlockClosure(block) as bool Function(objc.CGRect))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_bool_NSRect_closureCallable =
    ffi.Pointer.fromFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGRect)>(
      _ObjCBlock_bool_NSRect_closureTrampoline,
      false,
    ).cast();

/// Construction methods for `objc.ObjCBlock<ffi.Bool Function(objc.CGRect)>`.
abstract final class ObjCBlock_bool_NSRect {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Bool Function(objc.CGRect)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Bool Function(objc.CGRect)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Bool Function(objc.CGRect)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Bool Function(objc.CGRect arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Bool Function(objc.CGRect)>(
    objc.newPointerBlock(_ObjCBlock_bool_NSRect_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Bool Function(objc.CGRect)> fromFunction(
    bool Function(objc.CGRect) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Bool Function(objc.CGRect)>(
    objc.newClosureBlock(_ObjCBlock_bool_NSRect_closureCallable, (objc.CGRect arg0) => fn(arg0), keepIsolateAlive),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Bool Function(objc.CGRect)>`.
extension ObjCBlock_bool_NSRect_CallExtension on objc.ObjCBlock<ffi.Bool Function(objc.CGRect)> {
  bool call(objc.CGRect arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl> block, objc.CGRect arg0)>>()
      .asFunction<bool Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGRect)>()(ref.pointer, arg0);
}

late final _sel_imageWithSize_flipped_drawingHandler_ = objc.registerName("imageWithSize:flipped:drawingHandler:");
final _objc_msgSend_ap2ayg = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGSize,
          ffi.Bool,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGSize,
        bool,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_size = objc.registerName("size");
late final _sel_setSize_ = objc.registerName("setSize:");
late final _sel_setName_ = objc.registerName("setName:");
late final _sel_name = objc.registerName("name");

/// WARNING: NSColor is a stub. To generate bindings for this class, include
/// NSColor in your config's objc-interfaces list.
///
/// NSColor
class NSColor extends objc.ObjCObjectBase {
  NSColor._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [NSColor] that points to the same underlying object as [other].
  NSColor.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSColor] that wraps the given raw object pointer.
  NSColor.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_backgroundColor = objc.registerName("backgroundColor");
late final _sel_setBackgroundColor_ = objc.registerName("setBackgroundColor:");
late final _sel_usesEPSOnResolutionMismatch = objc.registerName("usesEPSOnResolutionMismatch");
late final _sel_setUsesEPSOnResolutionMismatch_ = objc.registerName("setUsesEPSOnResolutionMismatch:");
late final _sel_prefersColorMatch = objc.registerName("prefersColorMatch");
late final _sel_setPrefersColorMatch_ = objc.registerName("setPrefersColorMatch:");
late final _sel_matchesOnMultipleResolution = objc.registerName("matchesOnMultipleResolution");
late final _sel_setMatchesOnMultipleResolution_ = objc.registerName("setMatchesOnMultipleResolution:");
late final _sel_matchesOnlyOnBestFittingAxis = objc.registerName("matchesOnlyOnBestFittingAxis");
late final _sel_setMatchesOnlyOnBestFittingAxis_ = objc.registerName("setMatchesOnlyOnBestFittingAxis:");
late final _sel_drawAtPoint_fromRect_operation_fraction_ = objc.registerName(
  "drawAtPoint:fromRect:operation:fraction:",
);
late final _sel_drawInRect_fromRect_operation_fraction_ = objc.registerName("drawInRect:fromRect:operation:fraction:");
final _objc_msgSend_bfgdl2 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGRect,
          objc.CGRect,
          ffi.UnsignedLong,
          ffi.Double,
        )
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGRect, objc.CGRect, int, double)
    >();
late final _sel_drawInRect_fromRect_operation_fraction_respectFlipped_hints_ = objc.registerName(
  "drawInRect:fromRect:operation:fraction:respectFlipped:hints:",
);
final _objc_msgSend_1qus490 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGRect,
          objc.CGRect,
          ffi.UnsignedLong,
          ffi.Double,
          ffi.Bool,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGRect,
        objc.CGRect,
        int,
        double,
        bool,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_drawRepresentation_inRect_ = objc.registerName("drawRepresentation:inRect:");
final _objc_msgSend_x4xkoq = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          objc.CGRect,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        objc.CGRect,
      )
    >();
late final _sel_drawInRect_ = objc.registerName("drawInRect:");
final _objc_msgSend_1okkq16 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGRect)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.CGRect)>();
late final _sel_recache = objc.registerName("recache");
late final _sel_TIFFRepresentation = objc.registerName("TIFFRepresentation");

enum NSTIFFCompression {
  NSTIFFCompressionNone(1),
  NSTIFFCompressionCCITTFAX3(3),
  NSTIFFCompressionCCITTFAX4(4),
  NSTIFFCompressionLZW(5),
  NSTIFFCompressionJPEG(6),
  NSTIFFCompressionNEXT(32766),
  NSTIFFCompressionPackBits(32773),
  NSTIFFCompressionOldJPEG(32865);

  final int value;
  const NSTIFFCompression(this.value);

  static NSTIFFCompression fromValue(int value) => switch (value) {
    1 => NSTIFFCompressionNone,
    3 => NSTIFFCompressionCCITTFAX3,
    4 => NSTIFFCompressionCCITTFAX4,
    5 => NSTIFFCompressionLZW,
    6 => NSTIFFCompressionJPEG,
    32766 => NSTIFFCompressionNEXT,
    32773 => NSTIFFCompressionPackBits,
    32865 => NSTIFFCompressionOldJPEG,
    _ => throw ArgumentError('Unknown value for NSTIFFCompression: $value'),
  };
}

late final _sel_TIFFRepresentationUsingCompression_factor_ = objc.registerName(
  "TIFFRepresentationUsingCompression:factor:",
);
final _objc_msgSend_gs5ux1 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.UnsignedLong,
          ffi.Float,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int, double)
    >();
late final _sel_representations = objc.registerName("representations");
late final _sel_addRepresentations_ = objc.registerName("addRepresentations:");
late final _sel_addRepresentation_ = objc.registerName("addRepresentation:");
late final _sel_removeRepresentation_ = objc.registerName("removeRepresentation:");
late final _sel_isValid = objc.registerName("isValid");

/// WARNING: NSImageDelegate is a stub. To generate bindings for this class, include
/// NSImageDelegate in your config's objc-protocols list.
///
/// NSImageDelegate
interface class NSImageDelegate extends objc.ObjCProtocolBase implements objc.NSObjectProtocol {
  NSImageDelegate._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [NSImageDelegate] that points to the same underlying object as [other].
  NSImageDelegate.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSImageDelegate] that wraps the given raw object pointer.
  NSImageDelegate.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_imageTypes = objc.registerName("imageTypes");
late final _sel_imageUnfilteredTypes = objc.registerName("imageUnfilteredTypes");
late final _sel_canInitWithPasteboard_ = objc.registerName("canInitWithPasteboard:");

enum NSImageCacheMode {
  NSImageCacheDefault(0),
  NSImageCacheAlways(1),
  NSImageCacheBySize(2),
  NSImageCacheNever(3);

  final int value;
  const NSImageCacheMode(this.value);

  static NSImageCacheMode fromValue(int value) => switch (value) {
    0 => NSImageCacheDefault,
    1 => NSImageCacheAlways,
    2 => NSImageCacheBySize,
    3 => NSImageCacheNever,
    _ => throw ArgumentError('Unknown value for NSImageCacheMode: $value'),
  };
}

late final _sel_cacheMode = objc.registerName("cacheMode");
final _objc_msgSend_1d4tuvg = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.UnsignedLong Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setCacheMode_ = objc.registerName("setCacheMode:");
final _objc_msgSend_14xnhaq = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.UnsignedLong)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();
late final _sel_alignmentRect = objc.registerName("alignmentRect");
final _objc_msgSend_bu1hbw = objc.msgSendPointer
    .cast<ffi.NativeFunction<objc.CGRect Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<objc.CGRect Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_bu1hbwStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.CGRect>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.CGRect>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();
late final _sel_setAlignmentRect_ = objc.registerName("setAlignmentRect:");
late final _sel_isTemplate = objc.registerName("isTemplate");
late final _sel_setTemplate_ = objc.registerName("setTemplate:");
late final _sel_accessibilityDescription = objc.registerName("accessibilityDescription");
late final _sel_setAccessibilityDescription_ = objc.registerName("setAccessibilityDescription:");
late final _sel_initWithCGImage_size_ = objc.registerName("initWithCGImage:size:");
final _objc_msgSend_lvz2zr = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<CGImage>,
          objc.CGSize,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<CGImage>,
        objc.CGSize,
      )
    >();

/// WARNING: NSGraphicsContext is a stub. To generate bindings for this class, include
/// NSGraphicsContext in your config's objc-interfaces list.
///
/// NSGraphicsContext
class NSGraphicsContext extends objc.ObjCObjectBase {
  NSGraphicsContext._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super(pointer, retain: retain, release: release);

  /// Constructs a [NSGraphicsContext] that points to the same underlying object as [other].
  NSGraphicsContext.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSGraphicsContext] that wraps the given raw object pointer.
  NSGraphicsContext.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);
}

late final _sel_CGImageForProposedRect_context_hints_ = objc.registerName("CGImageForProposedRect:context:hints:");
final _objc_msgSend_1lfy6m2 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<CGImage> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.CGRect>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<CGImage> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.CGRect>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_bestRepresentationForRect_context_hints_ = objc.registerName(
  "bestRepresentationForRect:context:hints:",
);
final _objc_msgSend_1o8sa9u = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGRect,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGRect,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
late final _sel_hitTestRect_withImageDestinationRect_context_hints_flipped_ = objc.registerName(
  "hitTestRect:withImageDestinationRect:context:hints:flipped:",
);
final _objc_msgSend_h03lrd = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Bool Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGRect,
          objc.CGRect,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Bool,
        )
      >
    >()
    .asFunction<
      bool Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGRect,
        objc.CGRect,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        bool,
      )
    >();
late final _sel_recommendedLayerContentsScale_ = objc.registerName("recommendedLayerContentsScale:");
final _objc_msgSend_1tczmpv = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)>
    >()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();
final _objc_msgSend_1tczmpvFpret = objc.msgSendFpretPointer
    .cast<
      ffi.NativeFunction<ffi.Double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)>
    >()
    .asFunction<double Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)>();
late final _sel_layerContentsForContentsScale_ = objc.registerName("layerContentsForContentsScale:");
final _objc_msgSend_oa8mke = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Double)
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, double)
    >();
late final _sel_capInsets = objc.registerName("capInsets");
final _objc_msgSend_sl0cgw = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<objc.NSEdgeInsets Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>
    >()
    .asFunction<objc.NSEdgeInsets Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
final _objc_msgSend_sl0cgwStret = objc.msgSendStretPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.NSEdgeInsets>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
      >
    >()
    .asFunction<
      void Function(ffi.Pointer<objc.NSEdgeInsets>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)
    >();
late final _sel_setCapInsets_ = objc.registerName("setCapInsets:");
final _objc_msgSend_1ug163q = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.NSEdgeInsets)
      >
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, objc.NSEdgeInsets)>();

enum NSImageResizingMode {
  NSImageResizingModeTile(0),
  NSImageResizingModeStretch(1);

  final int value;
  const NSImageResizingMode(this.value);

  static NSImageResizingMode fromValue(int value) => switch (value) {
    0 => NSImageResizingModeTile,
    1 => NSImageResizingModeStretch,
    _ => throw ArgumentError('Unknown value for NSImageResizingMode: $value'),
  };
}

late final _sel_resizingMode = objc.registerName("resizingMode");
final _objc_msgSend_q65rpn = objc.msgSendPointer
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>>()
    .asFunction<int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>)>();
late final _sel_setResizingMode_ = objc.registerName("setResizingMode:");
final _objc_msgSend_197i80f = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Long)>
    >()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, int)>();

/// WARNING: NSImageSymbolConfiguration is a stub. To generate bindings for this class, include
/// NSImageSymbolConfiguration in your config's objc-interfaces list.
///
/// NSImageSymbolConfiguration
class NSImageSymbolConfiguration extends objc.NSObject implements objc.NSCopying, objc.NSSecureCoding {
  NSImageSymbolConfiguration._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('NSImageSymbolConfiguration', iOS: (true, null), macOS: (false, (11, 0, 0)));
  }

  /// Constructs a [NSImageSymbolConfiguration] that points to the same underlying object as [other].
  NSImageSymbolConfiguration.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSImageSymbolConfiguration] that wraps the given raw object pointer.
  NSImageSymbolConfiguration.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);
}

late final _sel_imageWithSymbolConfiguration_ = objc.registerName("imageWithSymbolConfiguration:");
late final _sel_symbolConfiguration = objc.registerName("symbolConfiguration");
late final _sel_imageWithLocale_ = objc.registerName("imageWithLocale:");
late final _sel_locale = objc.registerName("locale");
late final _sel_supportsSecureCoding = objc.registerName("supportsSecureCoding");
bool _ObjCBlock_bool_ffiVoid_fnPtrTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0) => block
    .ref
    .target
    .cast<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ffi.Void> arg0)>>()
    .asFunction<bool Function(ffi.Pointer<ffi.Void>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_bool_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>(
      _ObjCBlock_bool_ffiVoid_fnPtrTrampoline,
      false,
    ).cast();
bool _ObjCBlock_bool_ffiVoid_closureTrampoline(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0) =>
    (objc.getBlockClosure(block) as bool Function(ffi.Pointer<ffi.Void>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_bool_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>(
      _ObjCBlock_bool_ffiVoid_closureTrampoline,
      false,
    ).cast();

/// Construction methods for `objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)>`.
abstract final class ObjCBlock_bool_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<ffi.Void> arg0)>> ptr,
  ) => objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)>(
    objc.newPointerBlock(_ObjCBlock_bool_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)> fromFunction(
    bool Function(ffi.Pointer<ffi.Void>) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)>(
    objc.newClosureBlock(
      _ObjCBlock_bool_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0) => fn(arg0),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)>`.
extension ObjCBlock_bool_ffiVoid_CallExtension on objc.ObjCBlock<ffi.Bool Function(ffi.Pointer<ffi.Void>)> {
  bool call(ffi.Pointer<ffi.Void> arg0) => ref.pointer.ref.invoke
      .cast<ffi.NativeFunction<ffi.Bool Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0)>>()
      .asFunction<bool Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>()(ref.pointer, arg0);
}

late final _sel_encodeWithCoder_ = objc.registerName("encodeWithCoder:");
void _ObjCBlock_ffiVoid_ffiVoid_NSCoder_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSCoder_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSCoder_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_ffiVoid_NSCoder_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_ffiVoid_NSCoder_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_ffiVoid_NSCoder_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>`.
abstract final class ObjCBlock_ffiVoid_ffiVoid_NSCoder {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) =>
      objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_ffiVoid_NSCoder_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> fromFunction(
    void Function(ffi.Pointer<ffi.Void>, objc.NSCoder) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSCoder_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSCoder.castFromPointer(arg1, retain: true, release: true)),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> listener(
    void Function(ffi.Pointer<ffi.Void>, objc.NSCoder) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSCoder_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSCoder.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_18v1jvf(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
      wrapper,
      retain: false,
      release: true,
    );
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> blocking(
    void Function(ffi.Pointer<ffi.Void>, objc.NSCoder) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSCoder.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_ffiVoid_NSCoder_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSCoder.castFromPointer(arg1, retain: false, release: true)),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_18v1jvf(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>(
      wrapper,
      retain: false,
      release: true,
    );
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)>`.
extension ObjCBlock_ffiVoid_ffiVoid_NSCoder_CallExtension
    on objc.ObjCBlock<ffi.Void Function(ffi.Pointer<ffi.Void>, objc.NSCoder)> {
  void call(ffi.Pointer<ffi.Void> arg0, objc.NSCoder arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0, arg1.ref.pointer);
}

late final _sel_readableTypesForPasteboard_ = objc.registerName("readableTypesForPasteboard:");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSArray_ffiVoid_NSPasteboard_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) =>
    block.ref.target
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()(
      arg0,
      arg1,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_NSArray_ffiVoid_NSPasteboard_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSArray_ffiVoid_NSPasteboard_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSArray_ffiVoid_NSPasteboard_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) =>
    (objc.getBlockClosure(block)
        as ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_NSArray_ffiVoid_NSPasteboard_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSArray_ffiVoid_NSPasteboard_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)>`.
abstract final class ObjCBlock_NSArray_ffiVoid_NSPasteboard {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)
      >
    >
    ptr,
  ) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)>(
    objc.newPointerBlock(_ObjCBlock_NSArray_ffiVoid_NSPasteboard_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)> fromFunction(
    objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)>(
    objc.newClosureBlock(
      _ObjCBlock_NSArray_ffiVoid_NSPasteboard_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, NSPasteboard.castFromPointer(arg1, retain: true, release: true)).ref.retainAndAutorelease(),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)>`.
extension ObjCBlock_NSArray_ffiVoid_NSPasteboard_CallExtension
    on objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>, NSPasteboard)> {
  objc.NSArray call(ffi.Pointer<ffi.Void> arg0, NSPasteboard arg1) => objc.NSArray.castFromPointer(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(
              ffi.Pointer<objc.ObjCBlockImpl> block,
              ffi.Pointer<ffi.Void> arg0,
              ffi.Pointer<objc.ObjCObject> arg1,
            )
          >
        >()
        .asFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >()(ref.pointer, arg0, arg1.ref.pointer),
    retain: true,
    release: true,
  );
}

enum NSPasteboardReadingOptions {
  NSPasteboardReadingAsData(0),
  NSPasteboardReadingAsString(1),
  NSPasteboardReadingAsPropertyList(2),
  NSPasteboardReadingAsKeyedArchive(4);

  final int value;
  const NSPasteboardReadingOptions(this.value);

  static NSPasteboardReadingOptions fromValue(int value) => switch (value) {
    0 => NSPasteboardReadingAsData,
    1 => NSPasteboardReadingAsString,
    2 => NSPasteboardReadingAsPropertyList,
    4 => NSPasteboardReadingAsKeyedArchive,
    _ => throw ArgumentError('Unknown value for NSPasteboardReadingOptions: $value'),
  };
}

late final _sel_readingOptionsForType_pasteboard_ = objc.registerName("readingOptionsForType:pasteboard:");
final _objc_msgSend_9e06sb = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.UnsignedLong Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      int Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
int _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) =>
    block.ref.target
        .cast<
          ffi.NativeFunction<
            ffi.UnsignedLong Function(
              ffi.Pointer<ffi.Void> arg0,
              ffi.Pointer<objc.ObjCObject> arg1,
              ffi.Pointer<objc.ObjCObject> arg2,
            )
          >
        >()
        .asFunction<int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.UnsignedLong Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrTrampoline, 0)
        .cast();
int _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) =>
    (objc.getBlockClosure(block)
        as int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.UnsignedLong Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureTrampoline, 0)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>`.
abstract final class ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.UnsignedLong Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
        )
      >
    >
    ptr,
  ) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    objc.newPointerBlock(
      _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrCallable,
      ptr.cast(),
    ),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> fromFunction(
    NSPasteboardReadingOptions Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    objc.newClosureBlock(
      _ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCObject> arg2) => fn(
        arg0,
        objc.NSString.castFromPointer(arg1, retain: true, release: true),
        NSPasteboard.castFromPointer(arg2, retain: true, release: true),
      ).value,
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>`.
extension ObjCBlock_NSPasteboardReadingOptions_ffiVoid_NSPasteboardType_NSPasteboard_CallExtension
    on objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> {
  NSPasteboardReadingOptions call(ffi.Pointer<ffi.Void> arg0, objc.NSString arg1, NSPasteboard arg2) =>
      NSPasteboardReadingOptions.fromValue(
        ref.pointer.ref.invoke
            .cast<
              ffi.NativeFunction<
                ffi.UnsignedLong Function(
                  ffi.Pointer<objc.ObjCBlockImpl> block,
                  ffi.Pointer<ffi.Void> arg0,
                  ffi.Pointer<objc.ObjCObject> arg1,
                  ffi.Pointer<objc.ObjCObject> arg2,
                )
              >
            >()
            .asFunction<
              int Function(
                ffi.Pointer<objc.ObjCBlockImpl>,
                ffi.Pointer<ffi.Void>,
                ffi.Pointer<objc.ObjCObject>,
                ffi.Pointer<objc.ObjCObject>,
              )
            >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer),
      );
}

late final _sel_initWithPasteboardPropertyList_ofType_ = objc.registerName("initWithPasteboardPropertyList:ofType:");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<ffi.Void>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) =>
    (objc.getBlockClosure(block)
        as ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        ))(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, objc.NSString)>`.
abstract final class ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<
    objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
      ffi.Pointer<ffi.Void>,
      ffi.Pointer<objc.ObjCObject>,
      objc.NSString,
    )
  >
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<
        objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          objc.NSString,
        )
      >(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<
    objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
      ffi.Pointer<ffi.Void>,
      ffi.Pointer<objc.ObjCObject>,
      objc.NSString,
    )
  >
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
        )
      >
    >
    ptr,
  ) =>
      objc.ObjCBlock<
        objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          objc.NSString,
        )
      >(
        objc.newPointerBlock(
          _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_fnPtrCallable,
          ptr.cast(),
        ),
        retain: false,
        release: true,
      );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<
    objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
      ffi.Pointer<ffi.Void>,
      ffi.Pointer<objc.ObjCObject>,
      objc.NSString,
    )
  >
  fromFunction(
    objc.ObjCObjectBase? Function(ffi.Pointer<ffi.Void>, objc.ObjCObjectBase, objc.NSString) fn, {
    bool keepIsolateAlive = true,
  }) =>
      objc.ObjCBlock<
        objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          objc.NSString,
        )
      >(
        objc.newClosureBlock(
          _ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_closureCallable,
          (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCObject> arg2) =>
              fn(
                arg0,
                objc.ObjCObjectBase(arg1, retain: true, release: true),
                objc.NSString.castFromPointer(arg2, retain: true, release: true),
              )?.ref.retainAndReturnPointer() ??
              ffi.nullptr,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, objc.NSString)>`.
extension ObjCBlock_objcObjCObject_ffiVoid_objcObjCObject_NSPasteboardType_CallExtension
    on
        objc.ObjCBlock<
          objc.Retained<ffi.Pointer<objc.ObjCObject>?> Function(
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            objc.NSString,
          )
        > {
  objc.ObjCObjectBase? call(ffi.Pointer<ffi.Void> arg0, objc.ObjCObjectBase arg1, objc.NSString arg2) =>
      ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCObject> arg2,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer)
              .address ==
          0
      ? null
      : objc.ObjCObjectBase(
          ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCObject> arg2,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer),
          retain: false,
          release: true,
        );
}

late final _sel_writableTypesForPasteboard_ = objc.registerName("writableTypesForPasteboard:");

enum NSPasteboardWritingOptions {
  NSPasteboardWritingPromised(512);

  final int value;
  const NSPasteboardWritingOptions(this.value);

  static NSPasteboardWritingOptions fromValue(int value) => switch (value) {
    512 => NSPasteboardWritingPromised,
    _ => throw ArgumentError('Unknown value for NSPasteboardWritingOptions: $value'),
  };
}

late final _sel_writingOptionsForType_pasteboard_ = objc.registerName("writingOptionsForType:pasteboard:");
final _objc_msgSend_1r3sx4b = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.UnsignedLong Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >
    >()
    .asFunction<
      int Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
      )
    >();
int _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) =>
    block.ref.target
        .cast<
          ffi.NativeFunction<
            ffi.UnsignedLong Function(
              ffi.Pointer<ffi.Void> arg0,
              ffi.Pointer<objc.ObjCObject> arg1,
              ffi.Pointer<objc.ObjCObject> arg2,
            )
          >
        >()
        .asFunction<int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.UnsignedLong Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrTrampoline, 0)
        .cast();
int _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
) =>
    (objc.getBlockClosure(block)
        as int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
      arg2,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.UnsignedLong Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureTrampoline, 0)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>`.
abstract final class ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.UnsignedLong Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
        )
      >
    >
    ptr,
  ) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    objc.newPointerBlock(
      _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_fnPtrCallable,
      ptr.cast(),
    ),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> fromFunction(
    NSPasteboardWritingOptions Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>(
    objc.newClosureBlock(
      _ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCObject> arg2) => fn(
        arg0,
        objc.NSString.castFromPointer(arg1, retain: true, release: true),
        NSPasteboard.castFromPointer(arg2, retain: true, release: true),
      ).value,
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)>`.
extension ObjCBlock_NSPasteboardWritingOptions_ffiVoid_NSPasteboardType_NSPasteboard_CallExtension
    on objc.ObjCBlock<ffi.UnsignedLong Function(ffi.Pointer<ffi.Void>, objc.NSString, NSPasteboard)> {
  NSPasteboardWritingOptions call(ffi.Pointer<ffi.Void> arg0, objc.NSString arg1, NSPasteboard arg2) =>
      NSPasteboardWritingOptions.fromValue(
        ref.pointer.ref.invoke
            .cast<
              ffi.NativeFunction<
                ffi.UnsignedLong Function(
                  ffi.Pointer<objc.ObjCBlockImpl> block,
                  ffi.Pointer<ffi.Void> arg0,
                  ffi.Pointer<objc.ObjCObject> arg1,
                  ffi.Pointer<objc.ObjCObject> arg2,
                )
              >
            >()
            .asFunction<
              int Function(
                ffi.Pointer<objc.ObjCBlockImpl>,
                ffi.Pointer<ffi.Void>,
                ffi.Pointer<objc.ObjCObject>,
                ffi.Pointer<objc.ObjCObject>,
              )
            >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer),
      );
}

late final _sel_pasteboardPropertyListForType_ = objc.registerName("pasteboardPropertyListForType:");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) =>
    block.ref.target
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()(
      arg0,
      arg1,
    );
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) =>
    (objc.getBlockClosure(block)
        as ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
          )
        >(_ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>`.
abstract final class ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)
      >
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    objc.newPointerBlock(_ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)> fromFunction(
    objc.ObjCObjectBase? Function(ffi.Pointer<ffi.Void>, objc.NSString) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    objc.newClosureBlock(
      _ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSString.castFromPointer(arg1, retain: true, release: true))?.ref.retainAndAutorelease() ??
          ffi.nullptr,
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)>`.
extension ObjCBlock_objcObjCObject_ffiVoid_NSPasteboardType_CallExtension
    on objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSString)> {
  objc.ObjCObjectBase? call(ffi.Pointer<ffi.Void> arg0, objc.NSString arg1) =>
      ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer)
              .address ==
          0
      ? null
      : objc.ObjCObjectBase(
          ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer),
          retain: true,
          release: true,
        );
}

late final _sel_readableTypeIdentifiersForItemProvider = objc.registerName("readableTypeIdentifiersForItemProvider");
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSArray_ffiVoid_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>>()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_NSArray_ffiVoid_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_NSArray_ffiVoid_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSArray_ffiVoid_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
) => (objc.getBlockClosure(block) as ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void>))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_NSArray_ffiVoid_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)
        >(_ObjCBlock_NSArray_ffiVoid_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)>`.
abstract final class ObjCBlock_NSArray_ffiVoid {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<ffi.Void> arg0)>> ptr,
  ) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)>(
    objc.newPointerBlock(_ObjCBlock_NSArray_ffiVoid_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)> fromFunction(
    objc.NSArray Function(ffi.Pointer<ffi.Void>) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)>(
    objc.newClosureBlock(
      _ObjCBlock_NSArray_ffiVoid_closureCallable,
      (ffi.Pointer<ffi.Void> arg0) => fn(arg0).ref.retainAndAutorelease(),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)>`.
extension ObjCBlock_NSArray_ffiVoid_CallExtension on objc.ObjCBlock<objc.NSArray Function(ffi.Pointer<ffi.Void>)> {
  objc.NSArray call(ffi.Pointer<ffi.Void> arg0) => objc.NSArray.castFromPointer(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl> block, ffi.Pointer<ffi.Void> arg0)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>)>()(
      ref.pointer,
      arg0,
    ),
    retain: true,
    release: true,
  );
}

late final _sel_objectWithItemProviderData_typeIdentifier_error_ = objc.registerName(
  "objectWithItemProviderData:typeIdentifier:error:",
);
instancetype _ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        instancetype Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
        )
      >
    >()
    .asFunction<
      instancetype Function(
        ffi.Pointer<ffi.Void>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
      )
    >()(arg0, arg1, arg2, arg3);
ffi.Pointer<ffi.Void> _ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          instancetype Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_fnPtrTrampoline)
        .cast();
instancetype _ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCObject> arg2,
  ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
) =>
    (objc.getBlockClosure(block)
        as instancetype Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        ))(arg0, arg1, arg2, arg3);
ffi.Pointer<ffi.Void> _ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          instancetype Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        >(_ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSData, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
abstract final class ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<
    ffi.Pointer<objc.ObjCObject>? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSData,
      objc.NSString,
      ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
    )
  >
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<
        ffi.Pointer<objc.ObjCObject>? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSData,
          objc.NSString,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<
    ffi.Pointer<objc.ObjCObject>? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSData,
      objc.NSString,
      ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
    )
  >
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        instancetype Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCObject> arg2,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
        )
      >
    >
    ptr,
  ) =>
      objc.ObjCBlock<
        ffi.Pointer<objc.ObjCObject>? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSData,
          objc.NSString,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >(
        objc.newPointerBlock(_ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_fnPtrCallable, ptr.cast()),
        retain: false,
        release: true,
      );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<
    ffi.Pointer<objc.ObjCObject>? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSData,
      objc.NSString,
      ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
    )
  >
  fromFunction(
    Dartinstancetype? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSData,
      objc.NSString,
      ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
    )
    fn, {
    bool keepIsolateAlive = true,
  }) =>
      objc.ObjCBlock<
        ffi.Pointer<objc.ObjCObject>? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSData,
          objc.NSString,
          ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
        )
      >(
        objc.newClosureBlock(
          _ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_closureCallable,
          (
            ffi.Pointer<ffi.Void> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
            ffi.Pointer<objc.ObjCObject> arg2,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
          ) =>
              fn(
                arg0,
                objc.NSData.castFromPointer(arg1, retain: true, release: true),
                objc.NSString.castFromPointer(arg2, retain: true, release: true),
                arg3,
              )?.ref.retainAndAutorelease() ??
              ffi.nullptr,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<ffi.Pointer<objc.ObjCObject>? Function(ffi.Pointer<ffi.Void>, objc.NSData, objc.NSString, ffi.Pointer<ffi.Pointer<objc.ObjCObject>>)>`.
extension ObjCBlock_instancetype_ffiVoid_NSData_NSString_NSError_CallExtension
    on
        objc.ObjCBlock<
          ffi.Pointer<objc.ObjCObject>? Function(
            ffi.Pointer<ffi.Void>,
            objc.NSData,
            objc.NSString,
            ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
          )
        > {
  Dartinstancetype? call(
    ffi.Pointer<ffi.Void> arg0,
    objc.NSData arg1,
    objc.NSString arg2,
    ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
  ) =>
      ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  instancetype Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCObject> arg2,
                    ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
                  )
                >
              >()
              .asFunction<
                instancetype Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer, arg3)
              .address ==
          0
      ? null
      : objc.ObjCObjectBase(
          ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  instancetype Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCObject> arg2,
                    ffi.Pointer<ffi.Pointer<objc.ObjCObject>> arg3,
                  )
                >
              >()
              .asFunction<
                instancetype Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<ffi.Pointer<objc.ObjCObject>>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer, arg3),
          retain: true,
          release: true,
        );
}

late final _sel_writableTypeIdentifiersForItemProvider = objc.registerName("writableTypeIdentifiersForItemProvider");
late final _sel_itemProviderVisibilityForRepresentationWithTypeIdentifier_ = objc.registerName(
  "itemProviderVisibilityForRepresentationWithTypeIdentifier:",
);
final _objc_msgSend_16fy0up = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Long Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
      >
    >()
    .asFunction<
      int Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCSelector>, ffi.Pointer<objc.ObjCObject>)
    >();
int _ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_fnPtrTrampoline, 0)
        .cast();
int _ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as int Function(ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>))(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Long Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_closureTrampoline, 0)
        .cast();

/// Construction methods for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)>`.
abstract final class ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    pointer,
    retain: retain,
    release: release,
  );

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Long Function(ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>
    ptr,
  ) => objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    objc.newPointerBlock(_ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)> fromFunction(
    objc.NSItemProviderRepresentationVisibility Function(ffi.Pointer<ffi.Void>, objc.NSString) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)>(
    objc.newClosureBlock(
      _ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_closureCallable,
      (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1) =>
          fn(arg0, objc.NSString.castFromPointer(arg1, retain: true, release: true)).value,
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)>`.
extension ObjCBlock_NSItemProviderRepresentationVisibility_ffiVoid_NSString_CallExtension
    on objc.ObjCBlock<ffi.Long Function(ffi.Pointer<ffi.Void>, objc.NSString)> {
  objc.NSItemProviderRepresentationVisibility call(ffi.Pointer<ffi.Void> arg0, objc.NSString arg1) =>
      objc.NSItemProviderRepresentationVisibility.fromValue(
        ref.pointer.ref.invoke
            .cast<
              ffi.NativeFunction<
                ffi.Long Function(
                  ffi.Pointer<objc.ObjCBlockImpl> block,
                  ffi.Pointer<ffi.Void> arg0,
                  ffi.Pointer<objc.ObjCObject> arg1,
                )
              >
            >()
            .asFunction<
              int Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<ffi.Void>, ffi.Pointer<objc.ObjCObject>)
            >()(ref.pointer, arg0, arg1.ref.pointer),
      );
}

void _ObjCBlock_ffiVoid_NSData_NSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>>()
    .asFunction<void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)>()(arg0, arg1);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSData_NSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSData_NSError_fnPtrTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSData_NSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) => (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
  arg0,
  arg1,
);
ffi.Pointer<ffi.Void> _ObjCBlock_ffiVoid_NSData_NSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
        >(_ObjCBlock_ffiVoid_NSData_NSError_closureTrampoline)
        .cast();
void _ObjCBlock_ffiVoid_NSData_NSError_listenerTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
    arg0,
    arg1,
  );
  objc.objectRelease(block.cast());
}

ffi.NativeCallable<
  ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
>
_ObjCBlock_ffiVoid_NSData_NSError_listenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >.listener(_ObjCBlock_ffiVoid_NSData_NSError_listenerTrampoline)
      ..keepIsolateAlive = false;
void _ObjCBlock_ffiVoid_NSData_NSError_blockingTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> waiter,
  ffi.Pointer<objc.ObjCObject> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
) {
  try {
    (objc.getBlockClosure(block) as void Function(ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>))(
      arg0,
      arg1,
    );
  } catch (e) {
  } finally {
    objc.signalWaiter(waiter);
    objc.objectRelease(block.cast());
  }
}

ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSData_NSError_blockingCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.isolateLocal(_ObjCBlock_ffiVoid_NSData_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;
ffi.NativeCallable<
  ffi.Void Function(
    ffi.Pointer<objc.ObjCBlockImpl>,
    ffi.Pointer<ffi.Void>,
    ffi.Pointer<objc.ObjCObject>,
    ffi.Pointer<objc.ObjCObject>,
  )
>
_ObjCBlock_ffiVoid_NSData_NSError_blockingListenerCallable =
    ffi.NativeCallable<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCBlockImpl>,
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
        )
      >.listener(_ObjCBlock_ffiVoid_NSData_NSError_blockingTrampoline)
      ..keepIsolateAlive = false;

/// Construction methods for `objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>`.
abstract final class ObjCBlock_ffiVoid_NSData_NSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<ffi.Void Function(ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1)>
    >
    ptr,
  ) => objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>(
    objc.newPointerBlock(_ObjCBlock_ffiVoid_NSData_NSError_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> fromFunction(
    void Function(objc.NSData?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>(
    objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSData_NSError_closureCallable,
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSData.castFromPointer(arg0, retain: true, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: true, release: true),
      ),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );

  /// Creates a listener block from a Dart function.
  ///
  /// This is based on FFI's NativeCallable.listener, and has the same
  /// capabilities and limitations. This block can be invoked from any thread,
  /// but only supports void functions, and is not run synchronously. See
  /// NativeCallable.listener for more details.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> listener(
    void Function(objc.NSData?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSData_NSError_listenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSData.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapListenerBlock_pfv6jd(raw);
    objc.objectRelease(raw.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>(wrapper, retain: false, release: true);
  }

  /// Creates a blocking block from a Dart function.
  ///
  /// This callback can be invoked from any native thread, and will block the
  /// caller until the callback is handled by the Dart isolate that created
  /// the block. Async functions are not supported.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC. If the owner isolate
  /// has shut down, and the block is invoked by native code, it may block
  /// indefinitely, or have other undefined behavior.
  static objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> blocking(
    void Function(objc.NSData?, objc.NSError?) fn, {
    bool keepIsolateAlive = true,
  }) {
    final raw = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSData_NSError_blockingCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSData.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final rawListener = objc.newClosureBlock(
      _ObjCBlock_ffiVoid_NSData_NSError_blockingListenerCallable.nativeFunction.cast(),
      (ffi.Pointer<objc.ObjCObject> arg0, ffi.Pointer<objc.ObjCObject> arg1) => fn(
        arg0.address == 0 ? null : objc.NSData.castFromPointer(arg0, retain: false, release: true),
        arg1.address == 0 ? null : objc.NSError.castFromPointer(arg1, retain: false, release: true),
      ),
      keepIsolateAlive,
    );
    final wrapper = _DarwinNativeBindings_wrapBlockingBlock_pfv6jd(raw, rawListener, objc.objCContext);
    objc.objectRelease(raw.cast());
    objc.objectRelease(rawListener.cast());
    return objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>(wrapper, retain: false, release: true);
  }
}

/// Call operator for `objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>`.
extension ObjCBlock_ffiVoid_NSData_NSError_CallExtension
    on objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> {
  void call(objc.NSData? arg0, objc.NSError? arg1) => ref.pointer.ref.invoke
      .cast<
        ffi.NativeFunction<
          ffi.Void Function(
            ffi.Pointer<objc.ObjCBlockImpl> block,
            ffi.Pointer<objc.ObjCObject> arg0,
            ffi.Pointer<objc.ObjCObject> arg1,
          )
        >
      >()
      .asFunction<
        void Function(ffi.Pointer<objc.ObjCBlockImpl>, ffi.Pointer<objc.ObjCObject>, ffi.Pointer<objc.ObjCObject>)
      >()(ref.pointer, arg0?.ref.pointer ?? ffi.nullptr, arg1?.ref.pointer ?? ffi.nullptr);
}

late final _sel_loadDataWithTypeIdentifier_forItemProviderCompletionHandler_ = objc.registerName(
  "loadDataWithTypeIdentifier:forItemProviderCompletionHandler:",
);
final _objc_msgSend_r0bo0s = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) => block.ref.target
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<ffi.Void>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >()(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_fnPtrCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_fnPtrTrampoline)
        .cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  ffi.Pointer<ffi.Void> arg0,
  ffi.Pointer<objc.ObjCObject> arg1,
  ffi.Pointer<objc.ObjCBlockImpl> arg2,
) =>
    (objc.getBlockClosure(block)
        as ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCBlockImpl>,
        ))(arg0, arg1, arg2);
ffi.Pointer<ffi.Void> _ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_closureCallable =
    ffi.Pointer.fromFunction<
          ffi.Pointer<objc.ObjCObject> Function(
            ffi.Pointer<objc.ObjCBlockImpl>,
            ffi.Pointer<ffi.Void>,
            ffi.Pointer<objc.ObjCObject>,
            ffi.Pointer<objc.ObjCBlockImpl>,
          )
        >(_ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_closureTrampoline)
        .cast();

/// Construction methods for `objc.ObjCBlock<objc.NSProgress? Function(ffi.Pointer<ffi.Void>, objc.NSString, objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>)>`.
abstract final class ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<
    objc.NSProgress? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSString,
      objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
    )
  >
  castFromPointer(ffi.Pointer<objc.ObjCBlockImpl> pointer, {bool retain = false, bool release = false}) =>
      objc.ObjCBlock<
        objc.NSProgress? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSString,
          objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
        )
      >(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<
    objc.NSProgress? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSString,
      objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
    )
  >
  fromFunctionPointer(
    ffi.Pointer<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<ffi.Void> arg0,
          ffi.Pointer<objc.ObjCObject> arg1,
          ffi.Pointer<objc.ObjCBlockImpl> arg2,
        )
      >
    >
    ptr,
  ) =>
      objc.ObjCBlock<
        objc.NSProgress? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSString,
          objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
        )
      >(
        objc.newPointerBlock(_ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_fnPtrCallable, ptr.cast()),
        retain: false,
        release: true,
      );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<
    objc.NSProgress? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSString,
      objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
    )
  >
  fromFunction(
    objc.NSProgress? Function(
      ffi.Pointer<ffi.Void>,
      objc.NSString,
      objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
    )
    fn, {
    bool keepIsolateAlive = true,
  }) =>
      objc.ObjCBlock<
        objc.NSProgress? Function(
          ffi.Pointer<ffi.Void>,
          objc.NSString,
          objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
        )
      >(
        objc.newClosureBlock(
          _ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_closureCallable,
          (ffi.Pointer<ffi.Void> arg0, ffi.Pointer<objc.ObjCObject> arg1, ffi.Pointer<objc.ObjCBlockImpl> arg2) =>
              fn(
                arg0,
                objc.NSString.castFromPointer(arg1, retain: true, release: true),
                ObjCBlock_ffiVoid_NSData_NSError.castFromPointer(arg2, retain: true, release: true),
              )?.ref.retainAndAutorelease() ??
              ffi.nullptr,
          keepIsolateAlive,
        ),
        retain: false,
        release: true,
      );
}

/// Call operator for `objc.ObjCBlock<objc.NSProgress? Function(ffi.Pointer<ffi.Void>, objc.NSString, objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>)>`.
extension ObjCBlock_NSProgress_ffiVoid_NSString_ffiVoidNSDataNSError_CallExtension
    on
        objc.ObjCBlock<
          objc.NSProgress? Function(
            ffi.Pointer<ffi.Void>,
            objc.NSString,
            objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)>,
          )
        > {
  objc.NSProgress? call(
    ffi.Pointer<ffi.Void> arg0,
    objc.NSString arg1,
    objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> arg2,
  ) =>
      ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCBlockImpl> arg2,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCBlockImpl>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer)
              .address ==
          0
      ? null
      : objc.NSProgress.castFromPointer(
          ref.pointer.ref.invoke
              .cast<
                ffi.NativeFunction<
                  ffi.Pointer<objc.ObjCObject> Function(
                    ffi.Pointer<objc.ObjCBlockImpl> block,
                    ffi.Pointer<ffi.Void> arg0,
                    ffi.Pointer<objc.ObjCObject> arg1,
                    ffi.Pointer<objc.ObjCBlockImpl> arg2,
                  )
                >
              >()
              .asFunction<
                ffi.Pointer<objc.ObjCObject> Function(
                  ffi.Pointer<objc.ObjCBlockImpl>,
                  ffi.Pointer<ffi.Void>,
                  ffi.Pointer<objc.ObjCObject>,
                  ffi.Pointer<objc.ObjCBlockImpl>,
                )
              >()(ref.pointer, arg0, arg1.ref.pointer, arg2.ref.pointer),
          retain: true,
          release: true,
        );
}

late final _sel_initWithIconRef_ = objc.registerName("initWithIconRef:");
final _objc_msgSend_1o4xiu1 = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<OpaqueIconRef>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<OpaqueIconRef>,
      )
    >();

/// NSImage
class NSImage extends objc.NSObject {
  NSImage._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [NSImage] that points to the same underlying object as [other].
  NSImage.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSImage] that wraps the given raw object pointer.
  NSImage.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [NSImage].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_NSImage);
  }

  /// imageNamed:
  static NSImage? imageNamed(objc.NSString name) {
    objc.checkOsVersionInternal('NSImage.imageNamed:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(_class_NSImage, _sel_imageNamed_, name.ref.pointer);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// Creates a system symbol image with the specified name and value
  /// @param name A name from the systems SF Symbols catalog
  /// @param description The images accessibility description. This description is used automatically by interface elements that display images. Like all accessibility descriptions, use a short localized string that does not include the name of the interface element. For instance, delete rather than delete button.
  static NSImage? imageWithSystemSymbolName(objc.NSString name, {objc.NSString? accessibilityDescription}) {
    objc.checkOsVersionInternal(
      'NSImage.imageWithSystemSymbolName:accessibilityDescription:',
      iOS: (true, null),
      macOS: (false, (11, 0, 0)),
    );
    final _ret = _objc_msgSend_15qeuct(
      _class_NSImage,
      _sel_imageWithSystemSymbolName_accessibilityDescription_,
      name.ref.pointer,
      accessibilityDescription?.ref.pointer ?? ffi.nullptr,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// Creates a system symbol image with the specified name and value. The @c value argument is only accommodated if the symbol supports variable rendering.
  /// @param name A name from the systems SF Symbols catalog
  /// @param value The value represented by the symbol. The value should be between 0 and 1 inclusive ([0,1]).
  /// @param description The images accessibility description. This description is used automatically by interface elements that display images. Like all accessibility descriptions, use a short localized string that does not include the name of the interface element. For instance, delete rather than delete button.
  /// @note Values less than 0 or greater than 1 will be clamped to 0 and 1, respectively.
  static NSImage? imageWithSystemSymbolName$1(
    objc.NSString name, {
    required double variableValue,
    objc.NSString? accessibilityDescription,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.imageWithSystemSymbolName:variableValue:accessibilityDescription:',
      iOS: (true, null),
      macOS: (false, (13, 0, 0)),
    );
    final _ret = _objc_msgSend_17i4wqy(
      _class_NSImage,
      _sel_imageWithSystemSymbolName_variableValue_accessibilityDescription_,
      name.ref.pointer,
      variableValue,
      accessibilityDescription?.ref.pointer ?? ffi.nullptr,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// Creates a symbol image with the specified name and value. The @c value argument is only accommodated if the symbol supports variable rendering.
  /// @param name A name of a symbol image file in the main bundles catalog
  /// @param value The value represented by the symbol. The value should be between 0 and 1 inclusive ([0,1]).
  /// @note Values less than 0 or greater than 1 will be clamped to 0 and 1, respectively.
  static NSImage? imageWithSymbolName(objc.NSString name, {required double variableValue}) {
    objc.checkOsVersionInternal(
      'NSImage.imageWithSymbolName:variableValue:',
      iOS: (true, null),
      macOS: (false, (13, 0, 0)),
    );
    final _ret = _objc_msgSend_6plvbo(
      _class_NSImage,
      _sel_imageWithSymbolName_variableValue_,
      name.ref.pointer,
      variableValue,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// Creates a symbol image with the specified name and value. The @c value argument is only accommodated if the symbol supports variable rendering.
  /// @param name A name of a symbol image file in the main bundles catalog
  /// @param bundle The bundle containing the image file or asset catalog. Specify `nil` to search the apps main bundle.
  /// @param value The value represented by the symbol. The value should be between 0 and 1 inclusive ([0,1]).
  /// @note Values less than 0 or greater than 1 will be clamped to 0 and 1, respectively.
  static NSImage? imageWithSymbolName$1(objc.NSString name, {NSBundle? bundle, required double variableValue}) {
    objc.checkOsVersionInternal(
      'NSImage.imageWithSymbolName:bundle:variableValue:',
      iOS: (true, null),
      macOS: (false, (13, 0, 0)),
    );
    final _ret = _objc_msgSend_hzzkpm(
      _class_NSImage,
      _sel_imageWithSymbolName_bundle_variableValue_,
      name.ref.pointer,
      bundle?.ref.pointer ?? ffi.nullptr,
      variableValue,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// initWithSize:
  NSImage initWithSize(objc.CGSize size) {
    objc.checkOsVersionInternal('NSImage.initWithSize:', iOS: (true, null));
    final _ret = _objc_msgSend_1c2zpn3(this.ref.retainAndReturnPointer(), _sel_initWithSize_, size);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithCoder:
  NSImage? initWithCoder(objc.NSCoder coder) {
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithCoder_, coder.ref.pointer);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithData:
  NSImage? initWithData(objc.NSData data) {
    objc.checkOsVersionInternal('NSImage.initWithData:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithData_, data.ref.pointer);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithContentsOfFile:
  NSImage? initWithContentsOfFile(objc.NSString fileName) {
    objc.checkOsVersionInternal('NSImage.initWithContentsOfFile:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithContentsOfFile_,
      fileName.ref.pointer,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithContentsOfURL:
  NSImage? initWithContentsOfURL(objc.NSURL url) {
    objc.checkOsVersionInternal('NSImage.initWithContentsOfURL:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initWithContentsOfURL_, url.ref.pointer);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initByReferencingFile:
  NSImage? initByReferencingFile(objc.NSString fileName) {
    objc.checkOsVersionInternal('NSImage.initByReferencingFile:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initByReferencingFile_,
      fileName.ref.pointer,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initByReferencingURL:
  NSImage initByReferencingURL(objc.NSURL url) {
    objc.checkOsVersionInternal('NSImage.initByReferencingURL:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(this.ref.retainAndReturnPointer(), _sel_initByReferencingURL_, url.ref.pointer);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithPasteboard:
  NSImage? initWithPasteboard(NSPasteboard pasteboard) {
    objc.checkOsVersionInternal('NSImage.initWithPasteboard:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithPasteboard_,
      pasteboard.ref.pointer,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithDataIgnoringOrientation:
  NSImage? initWithDataIgnoringOrientation(objc.NSData data) {
    objc.checkOsVersionInternal(
      'NSImage.initWithDataIgnoringOrientation:',
      iOS: (true, null),
      macOS: (false, (10, 6, 0)),
    );
    final _ret = _objc_msgSend_1sotr3r(
      this.ref.retainAndReturnPointer(),
      _sel_initWithDataIgnoringOrientation_,
      data.ref.pointer,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// imageWithSize:flipped:drawingHandler:
  static NSImage imageWithSize(
    objc.CGSize size, {
    required bool flipped,
    required objc.ObjCBlock<ffi.Bool Function(objc.CGRect)> drawingHandler,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.imageWithSize:flipped:drawingHandler:',
      iOS: (true, null),
      macOS: (false, (10, 8, 0)),
    );
    final _ret = _objc_msgSend_ap2ayg(
      _class_NSImage,
      _sel_imageWithSize_flipped_drawingHandler_,
      size,
      flipped,
      drawingHandler.ref.pointer,
    );
    return NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// size
  objc.CGSize get size {
    objc.checkOsVersionInternal('NSImage.size', iOS: (true, null));
    final _ptr = pkg_ffi.calloc<objc.CGSize>();
    objc.useMsgSendVariants
        ? _objc_msgSend_1vdfkenStret(_ptr, this.ref.pointer, _sel_size)
        : _ptr.ref = _objc_msgSend_1vdfken(this.ref.pointer, _sel_size);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGSize>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGSize>(_finalizable);
  }

  /// setSize:
  set size(objc.CGSize value) {
    objc.checkOsVersionInternal('NSImage.setSize:', iOS: (true, null));
    _objc_msgSend_13lgpwz(this.ref.pointer, _sel_setSize_, value);
  }

  /// setName:
  bool setName(objc.NSString? string) {
    objc.checkOsVersionInternal('NSImage.setName:', iOS: (true, null));
    return _objc_msgSend_19nvye5(this.ref.pointer, _sel_setName_, string?.ref.pointer ?? ffi.nullptr);
  }

  /// name
  objc.NSString? name() {
    objc.checkOsVersionInternal('NSImage.name', iOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_name);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// backgroundColor
  NSColor get backgroundColor {
    objc.checkOsVersionInternal('NSImage.backgroundColor', iOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_backgroundColor);
    return NSColor.castFromPointer(_ret, retain: true, release: true);
  }

  /// setBackgroundColor:
  set backgroundColor(NSColor value) {
    objc.checkOsVersionInternal('NSImage.setBackgroundColor:', iOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setBackgroundColor_, value.ref.pointer);
  }

  /// usesEPSOnResolutionMismatch
  bool get usesEPSOnResolutionMismatch {
    objc.checkOsVersionInternal('NSImage.usesEPSOnResolutionMismatch', iOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_usesEPSOnResolutionMismatch);
  }

  /// setUsesEPSOnResolutionMismatch:
  set usesEPSOnResolutionMismatch(bool value) {
    objc.checkOsVersionInternal('NSImage.setUsesEPSOnResolutionMismatch:', iOS: (true, null));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setUsesEPSOnResolutionMismatch_, value);
  }

  /// prefersColorMatch
  bool get prefersColorMatch {
    objc.checkOsVersionInternal('NSImage.prefersColorMatch', iOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_prefersColorMatch);
  }

  /// setPrefersColorMatch:
  set prefersColorMatch(bool value) {
    objc.checkOsVersionInternal('NSImage.setPrefersColorMatch:', iOS: (true, null));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setPrefersColorMatch_, value);
  }

  /// matchesOnMultipleResolution
  bool get matchesOnMultipleResolution {
    objc.checkOsVersionInternal('NSImage.matchesOnMultipleResolution', iOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_matchesOnMultipleResolution);
  }

  /// setMatchesOnMultipleResolution:
  set matchesOnMultipleResolution(bool value) {
    objc.checkOsVersionInternal('NSImage.setMatchesOnMultipleResolution:', iOS: (true, null));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setMatchesOnMultipleResolution_, value);
  }

  /// matchesOnlyOnBestFittingAxis
  bool get matchesOnlyOnBestFittingAxis {
    objc.checkOsVersionInternal('NSImage.matchesOnlyOnBestFittingAxis', iOS: (true, null), macOS: (false, (10, 7, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_matchesOnlyOnBestFittingAxis);
  }

  /// setMatchesOnlyOnBestFittingAxis:
  set matchesOnlyOnBestFittingAxis(bool value) {
    objc.checkOsVersionInternal(
      'NSImage.setMatchesOnlyOnBestFittingAxis:',
      iOS: (true, null),
      macOS: (false, (10, 7, 0)),
    );
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setMatchesOnlyOnBestFittingAxis_, value);
  }

  /// drawAtPoint:fromRect:operation:fraction:
  void drawAtPoint(
    objc.CGPoint point, {
    required objc.CGRect fromRect,
    required NSCompositingOperation operation,
    required double fraction,
  }) {
    objc.checkOsVersionInternal('NSImage.drawAtPoint:fromRect:operation:fraction:', iOS: (true, null));
    _objc_msgSend_1xnlu4e(
      this.ref.pointer,
      _sel_drawAtPoint_fromRect_operation_fraction_,
      point,
      fromRect,
      operation.value,
      fraction,
    );
  }

  /// drawInRect:fromRect:operation:fraction:
  void drawInRect(
    objc.CGRect rect, {
    required objc.CGRect fromRect,
    required NSCompositingOperation operation,
    required double fraction,
  }) {
    objc.checkOsVersionInternal('NSImage.drawInRect:fromRect:operation:fraction:', iOS: (true, null));
    _objc_msgSend_bfgdl2(
      this.ref.pointer,
      _sel_drawInRect_fromRect_operation_fraction_,
      rect,
      fromRect,
      operation.value,
      fraction,
    );
  }

  /// drawInRect:fromRect:operation:fraction:respectFlipped:hints:
  void drawInRect$1(
    objc.CGRect dstSpacePortionRect, {
    required objc.CGRect fromRect,
    required NSCompositingOperation operation,
    required double fraction,
    required bool respectFlipped,
    objc.NSDictionary? hints,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.drawInRect:fromRect:operation:fraction:respectFlipped:hints:',
      iOS: (true, null),
      macOS: (false, (10, 6, 0)),
    );
    _objc_msgSend_1qus490(
      this.ref.pointer,
      _sel_drawInRect_fromRect_operation_fraction_respectFlipped_hints_,
      dstSpacePortionRect,
      fromRect,
      operation.value,
      fraction,
      respectFlipped,
      hints?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// drawRepresentation:inRect:
  bool drawRepresentation(NSImageRep imageRep, {required objc.CGRect inRect}) {
    objc.checkOsVersionInternal('NSImage.drawRepresentation:inRect:', iOS: (true, null));
    return _objc_msgSend_x4xkoq(this.ref.pointer, _sel_drawRepresentation_inRect_, imageRep.ref.pointer, inRect);
  }

  /// drawInRect:
  void drawInRect$2(objc.CGRect rect) {
    objc.checkOsVersionInternal('NSImage.drawInRect:', iOS: (true, null), macOS: (false, (10, 9, 0)));
    _objc_msgSend_1okkq16(this.ref.pointer, _sel_drawInRect_, rect);
  }

  /// recache
  void recache() {
    objc.checkOsVersionInternal('NSImage.recache', iOS: (true, null));
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_recache);
  }

  /// TIFFRepresentation
  objc.NSData? get TIFFRepresentation {
    objc.checkOsVersionInternal('NSImage.TIFFRepresentation', iOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_TIFFRepresentation);
    return _ret.address == 0 ? null : objc.NSData.castFromPointer(_ret, retain: true, release: true);
  }

  /// TIFFRepresentationUsingCompression:factor:
  objc.NSData? TIFFRepresentationUsingCompression(NSTIFFCompression comp, {required double factor}) {
    objc.checkOsVersionInternal('NSImage.TIFFRepresentationUsingCompression:factor:', iOS: (true, null));
    final _ret = _objc_msgSend_gs5ux1(
      this.ref.pointer,
      _sel_TIFFRepresentationUsingCompression_factor_,
      comp.value,
      factor,
    );
    return _ret.address == 0 ? null : objc.NSData.castFromPointer(_ret, retain: true, release: true);
  }

  /// representations
  objc.NSArray get representations {
    objc.checkOsVersionInternal('NSImage.representations', iOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_representations);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// addRepresentations:
  void addRepresentations(objc.NSArray imageReps) {
    objc.checkOsVersionInternal('NSImage.addRepresentations:', iOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addRepresentations_, imageReps.ref.pointer);
  }

  /// addRepresentation:
  void addRepresentation(NSImageRep imageRep) {
    objc.checkOsVersionInternal('NSImage.addRepresentation:', iOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_addRepresentation_, imageRep.ref.pointer);
  }

  /// removeRepresentation:
  void removeRepresentation(NSImageRep imageRep) {
    objc.checkOsVersionInternal('NSImage.removeRepresentation:', iOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_removeRepresentation_, imageRep.ref.pointer);
  }

  /// isValid
  bool get valid {
    objc.checkOsVersionInternal('NSImage.isValid', iOS: (true, null));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isValid);
  }

  /// delegate
  NSImageDelegate? get delegate {
    objc.checkOsVersionInternal('NSImage.delegate', iOS: (true, null));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_delegate);
    return _ret.address == 0 ? null : NSImageDelegate.castFromPointer(_ret, retain: true, release: true);
  }

  /// setDelegate:
  set delegate(NSImageDelegate? value) {
    objc.checkOsVersionInternal('NSImage.setDelegate:', iOS: (true, null));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setDelegate_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// imageTypes
  static objc.NSArray getImageTypes() {
    objc.checkOsVersionInternal('NSImage.imageTypes', iOS: (true, null), macOS: (false, (10, 5, 0)));
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imageTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// imageUnfilteredTypes
  static objc.NSArray getImageUnfilteredTypes() {
    objc.checkOsVersionInternal('NSImage.imageUnfilteredTypes', iOS: (true, null), macOS: (false, (10, 5, 0)));
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_imageUnfilteredTypes);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// canInitWithPasteboard:
  static bool canInitWithPasteboard(NSPasteboard pasteboard) {
    objc.checkOsVersionInternal('NSImage.canInitWithPasteboard:', iOS: (true, null));
    return _objc_msgSend_19nvye5(_class_NSImage, _sel_canInitWithPasteboard_, pasteboard.ref.pointer);
  }

  /// cacheMode
  NSImageCacheMode get cacheMode {
    objc.checkOsVersionInternal('NSImage.cacheMode', iOS: (true, null));
    final _ret = _objc_msgSend_1d4tuvg(this.ref.pointer, _sel_cacheMode);
    return NSImageCacheMode.fromValue(_ret);
  }

  /// setCacheMode:
  set cacheMode(NSImageCacheMode value) {
    objc.checkOsVersionInternal('NSImage.setCacheMode:', iOS: (true, null));
    _objc_msgSend_14xnhaq(this.ref.pointer, _sel_setCacheMode_, value.value);
  }

  /// alignmentRect
  objc.CGRect get alignmentRect {
    objc.checkOsVersionInternal('NSImage.alignmentRect', iOS: (true, null), macOS: (false, (10, 5, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGRect>();
    objc.useMsgSendVariants
        ? _objc_msgSend_bu1hbwStret(_ptr, this.ref.pointer, _sel_alignmentRect)
        : _ptr.ref = _objc_msgSend_bu1hbw(this.ref.pointer, _sel_alignmentRect);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGRect>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGRect>(_finalizable);
  }

  /// setAlignmentRect:
  set alignmentRect(objc.CGRect value) {
    objc.checkOsVersionInternal('NSImage.setAlignmentRect:', iOS: (true, null), macOS: (false, (10, 5, 0)));
    _objc_msgSend_1okkq16(this.ref.pointer, _sel_setAlignmentRect_, value);
  }

  /// isTemplate
  bool get template {
    objc.checkOsVersionInternal('NSImage.isTemplate', iOS: (true, null), macOS: (false, (10, 5, 0)));
    return _objc_msgSend_91o635(this.ref.pointer, _sel_isTemplate);
  }

  /// setTemplate:
  set template(bool value) {
    objc.checkOsVersionInternal('NSImage.setTemplate:', iOS: (true, null), macOS: (false, (10, 5, 0)));
    _objc_msgSend_1s56lr9(this.ref.pointer, _sel_setTemplate_, value);
  }

  /// accessibilityDescription
  objc.NSString? get accessibilityDescription {
    objc.checkOsVersionInternal('NSImage.accessibilityDescription', iOS: (true, null), macOS: (false, (10, 6, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_accessibilityDescription);
    return _ret.address == 0 ? null : objc.NSString.castFromPointer(_ret, retain: true, release: true);
  }

  /// setAccessibilityDescription:
  set accessibilityDescription(objc.NSString? value) {
    objc.checkOsVersionInternal('NSImage.setAccessibilityDescription:', iOS: (true, null), macOS: (false, (10, 6, 0)));
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_setAccessibilityDescription_, value?.ref.pointer ?? ffi.nullptr);
  }

  /// initWithCGImage:size:
  NSImage initWithCGImage(ffi.Pointer<CGImage> cgImage, {required objc.CGSize size$1}) {
    objc.checkOsVersionInternal('NSImage.initWithCGImage:size:', iOS: (true, null), macOS: (false, (10, 6, 0)));
    final _ret = _objc_msgSend_lvz2zr(this.ref.retainAndReturnPointer(), _sel_initWithCGImage_size_, cgImage, size$1);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// CGImageForProposedRect:context:hints:
  ffi.Pointer<CGImage> CGImageForProposedRect(
    ffi.Pointer<objc.CGRect> proposedDestRect, {
    NSGraphicsContext? context,
    objc.NSDictionary? hints,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.CGImageForProposedRect:context:hints:',
      iOS: (true, null),
      macOS: (false, (10, 6, 0)),
    );
    return _objc_msgSend_1lfy6m2(
      this.ref.pointer,
      _sel_CGImageForProposedRect_context_hints_,
      proposedDestRect,
      context?.ref.pointer ?? ffi.nullptr,
      hints?.ref.pointer ?? ffi.nullptr,
    );
  }

  /// bestRepresentationForRect:context:hints:
  NSImageRep? bestRepresentationForRect(objc.CGRect rect, {NSGraphicsContext? context, objc.NSDictionary? hints}) {
    objc.checkOsVersionInternal(
      'NSImage.bestRepresentationForRect:context:hints:',
      iOS: (true, null),
      macOS: (false, (10, 6, 0)),
    );
    final _ret = _objc_msgSend_1o8sa9u(
      this.ref.pointer,
      _sel_bestRepresentationForRect_context_hints_,
      rect,
      context?.ref.pointer ?? ffi.nullptr,
      hints?.ref.pointer ?? ffi.nullptr,
    );
    return _ret.address == 0 ? null : NSImageRep.castFromPointer(_ret, retain: true, release: true);
  }

  /// hitTestRect:withImageDestinationRect:context:hints:flipped:
  bool hitTestRect(
    objc.CGRect testRectDestSpace, {
    required objc.CGRect withImageDestinationRect,
    NSGraphicsContext? context,
    objc.NSDictionary? hints,
    required bool flipped,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.hitTestRect:withImageDestinationRect:context:hints:flipped:',
      iOS: (true, null),
      macOS: (false, (10, 6, 0)),
    );
    return _objc_msgSend_h03lrd(
      this.ref.pointer,
      _sel_hitTestRect_withImageDestinationRect_context_hints_flipped_,
      testRectDestSpace,
      withImageDestinationRect,
      context?.ref.pointer ?? ffi.nullptr,
      hints?.ref.pointer ?? ffi.nullptr,
      flipped,
    );
  }

  /// recommendedLayerContentsScale:
  double recommendedLayerContentsScale(double preferredContentsScale) {
    objc.checkOsVersionInternal(
      'NSImage.recommendedLayerContentsScale:',
      iOS: (true, null),
      macOS: (false, (10, 7, 0)),
    );
    return objc.useMsgSendVariants
        ? _objc_msgSend_1tczmpvFpret(this.ref.pointer, _sel_recommendedLayerContentsScale_, preferredContentsScale)
        : _objc_msgSend_1tczmpv(this.ref.pointer, _sel_recommendedLayerContentsScale_, preferredContentsScale);
  }

  /// layerContentsForContentsScale:
  objc.ObjCObjectBase layerContentsForContentsScale(double layerContentsScale) {
    objc.checkOsVersionInternal(
      'NSImage.layerContentsForContentsScale:',
      iOS: (true, null),
      macOS: (false, (10, 7, 0)),
    );
    final _ret = _objc_msgSend_oa8mke(this.ref.pointer, _sel_layerContentsForContentsScale_, layerContentsScale);
    return objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// capInsets
  objc.NSEdgeInsets get capInsets {
    objc.checkOsVersionInternal('NSImage.capInsets', iOS: (true, null), macOS: (false, (10, 10, 0)));
    final _ptr = pkg_ffi.calloc<objc.NSEdgeInsets>();
    objc.useMsgSendVariants
        ? _objc_msgSend_sl0cgwStret(_ptr, this.ref.pointer, _sel_capInsets)
        : _ptr.ref = _objc_msgSend_sl0cgw(this.ref.pointer, _sel_capInsets);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.NSEdgeInsets>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.NSEdgeInsets>(_finalizable);
  }

  /// setCapInsets:
  set capInsets(objc.NSEdgeInsets value) {
    objc.checkOsVersionInternal('NSImage.setCapInsets:', iOS: (true, null), macOS: (false, (10, 10, 0)));
    _objc_msgSend_1ug163q(this.ref.pointer, _sel_setCapInsets_, value);
  }

  /// resizingMode
  NSImageResizingMode get resizingMode {
    objc.checkOsVersionInternal('NSImage.resizingMode', iOS: (true, null), macOS: (false, (10, 10, 0)));
    final _ret = _objc_msgSend_q65rpn(this.ref.pointer, _sel_resizingMode);
    return NSImageResizingMode.fromValue(_ret);
  }

  /// setResizingMode:
  set resizingMode(NSImageResizingMode value) {
    objc.checkOsVersionInternal('NSImage.setResizingMode:', iOS: (true, null), macOS: (false, (10, 10, 0)));
    _objc_msgSend_197i80f(this.ref.pointer, _sel_setResizingMode_, value.value);
  }

  /// imageWithSymbolConfiguration:
  NSImage? imageWithSymbolConfiguration(NSImageSymbolConfiguration configuration) {
    objc.checkOsVersionInternal('NSImage.imageWithSymbolConfiguration:', iOS: (true, null), macOS: (false, (11, 0, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_imageWithSymbolConfiguration_, configuration.ref.pointer);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// symbolConfiguration
  NSImageSymbolConfiguration get symbolConfiguration {
    objc.checkOsVersionInternal('NSImage.symbolConfiguration', iOS: (true, null), macOS: (false, (12, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_symbolConfiguration);
    return NSImageSymbolConfiguration.castFromPointer(_ret, retain: true, release: true);
  }

  /// Creates and returns a new image with the specified locale. If the receiver contains locale-sensitive representations, the returned image will prefer to draw using representations appropriate for the specified locale. If locale is `nil`, the returned image uses the default behavior of choosing representations appropriate for the systems currently-configured locale.
  NSImage imageWithLocale(objc.NSLocale? locale) {
    objc.checkOsVersionInternal('NSImage.imageWithLocale:', iOS: (true, null), macOS: (false, (14, 0, 0)));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_imageWithLocale_, locale?.ref.pointer ?? ffi.nullptr);
    return NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// The images preferred locale for resolving representations, if one has been specified using `-imageWithLocale:`. Otherwise, `nil`.
  objc.NSLocale? get locale {
    objc.checkOsVersionInternal('NSImage.locale', iOS: (true, null), macOS: (false, (14, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_locale);
    return _ret.address == 0 ? null : objc.NSLocale.castFromPointer(_ret, retain: true, release: true);
  }

  /// init
  NSImage init() {
    objc.checkOsVersionInternal('NSImage.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static NSImage new$() {
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_new);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static NSImage allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_NSImage, _sel_allocWithZone_, zone);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static NSImage alloc() {
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_alloc);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// supportsSecureCoding
  static bool getSupportsSecureCoding() {
    return _objc_msgSend_91o635(_class_NSImage, _sel_supportsSecureCoding);
  }

  /// encodeWithCoder:
  void encodeWithCoder(objc.NSCoder coder) {
    _objc_msgSend_xtuoz7(this.ref.pointer, _sel_encodeWithCoder_, coder.ref.pointer);
  }

  /// readableTypesForPasteboard:
  static objc.NSArray readableTypesForPasteboard(NSPasteboard pasteboard) {
    objc.checkOsVersionInternal('NSImage.readableTypesForPasteboard:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(_class_NSImage, _sel_readableTypesForPasteboard_, pasteboard.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// readingOptionsForType:pasteboard:
  static NSPasteboardReadingOptions readingOptionsForType(objc.NSString type, {required NSPasteboard pasteboard}) {
    objc.checkOsVersionInternal('NSImage.readingOptionsForType:pasteboard:', iOS: (true, null));
    if (!objc.respondsToSelector(_class_NSImage, _sel_readingOptionsForType_pasteboard_)) {
      throw objc.UnimplementedOptionalMethodException('NSImage', 'readingOptionsForType:pasteboard:');
    }
    final _ret = _objc_msgSend_9e06sb(
      _class_NSImage,
      _sel_readingOptionsForType_pasteboard_,
      type.ref.pointer,
      pasteboard.ref.pointer,
    );
    return NSPasteboardReadingOptions.fromValue(_ret);
  }

  /// initWithPasteboardPropertyList:ofType:
  objc.ObjCObjectBase? initWithPasteboardPropertyList(
    objc.ObjCObjectBase propertyList, {
    required objc.NSString ofType,
  }) {
    objc.checkOsVersionInternal('NSImage.initWithPasteboardPropertyList:ofType:', iOS: (true, null));
    if (!objc.respondsToSelector(this.ref.retainAndReturnPointer(), _sel_initWithPasteboardPropertyList_ofType_)) {
      throw objc.UnimplementedOptionalMethodException('NSImage', 'initWithPasteboardPropertyList:ofType:');
    }
    final _ret = _objc_msgSend_15qeuct(
      this.ref.retainAndReturnPointer(),
      _sel_initWithPasteboardPropertyList_ofType_,
      propertyList.ref.pointer,
      ofType.ref.pointer,
    );
    return _ret.address == 0 ? null : objc.ObjCObjectBase(_ret, retain: false, release: true);
  }

  /// writableTypesForPasteboard:
  objc.NSArray writableTypesForPasteboard(NSPasteboard pasteboard) {
    objc.checkOsVersionInternal('NSImage.writableTypesForPasteboard:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_writableTypesForPasteboard_, pasteboard.ref.pointer);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// writingOptionsForType:pasteboard:
  NSPasteboardWritingOptions writingOptionsForType(objc.NSString type, {required NSPasteboard pasteboard}) {
    objc.checkOsVersionInternal('NSImage.writingOptionsForType:pasteboard:', iOS: (true, null));
    if (!objc.respondsToSelector(this.ref.pointer, _sel_writingOptionsForType_pasteboard_)) {
      throw objc.UnimplementedOptionalMethodException('NSImage', 'writingOptionsForType:pasteboard:');
    }
    final _ret = _objc_msgSend_1r3sx4b(
      this.ref.pointer,
      _sel_writingOptionsForType_pasteboard_,
      type.ref.pointer,
      pasteboard.ref.pointer,
    );
    return NSPasteboardWritingOptions.fromValue(_ret);
  }

  /// pasteboardPropertyListForType:
  objc.ObjCObjectBase? pasteboardPropertyListForType(objc.NSString type) {
    objc.checkOsVersionInternal('NSImage.pasteboardPropertyListForType:', iOS: (true, null));
    final _ret = _objc_msgSend_1sotr3r(this.ref.pointer, _sel_pasteboardPropertyListForType_, type.ref.pointer);
    return _ret.address == 0 ? null : objc.ObjCObjectBase(_ret, retain: true, release: true);
  }

  /// readableTypeIdentifiersForItemProvider
  static objc.NSArray getReadableTypeIdentifiersForItemProvider() {
    objc.checkOsVersionInternal(
      'NSImage.readableTypeIdentifiersForItemProvider',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_readableTypeIdentifiersForItemProvider);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// objectWithItemProviderData:typeIdentifier:error:
  static NSImage? objectWithItemProviderData(
    objc.NSData data, {
    required objc.NSString typeIdentifier,
    required ffi.Pointer<ffi.Pointer<objc.ObjCObject>> error,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.objectWithItemProviderData:typeIdentifier:error:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_1pnyuds(
      _class_NSImage,
      _sel_objectWithItemProviderData_typeIdentifier_error_,
      data.ref.pointer,
      typeIdentifier.ref.pointer,
      error,
    );
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// writableTypeIdentifiersForItemProvider
  static objc.NSArray getWritableTypeIdentifiersForItemProvider() {
    objc.checkOsVersionInternal(
      'NSImage.writableTypeIdentifiersForItemProvider',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_151sglz(_class_NSImage, _sel_writableTypeIdentifiersForItemProvider);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// writableTypeIdentifiersForItemProvider
  objc.NSArray get writableTypeIdentifiersForItemProvider$1 {
    objc.checkOsVersionInternal(
      'NSImage.writableTypeIdentifiersForItemProvider',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    if (!objc.respondsToSelector(this.ref.pointer, _sel_writableTypeIdentifiersForItemProvider)) {
      throw objc.UnimplementedOptionalMethodException('NSImage', 'writableTypeIdentifiersForItemProvider');
    }
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_writableTypeIdentifiersForItemProvider);
    return objc.NSArray.castFromPointer(_ret, retain: true, release: true);
  }

  /// itemProviderVisibilityForRepresentationWithTypeIdentifier:
  static objc.NSItemProviderRepresentationVisibility itemProviderVisibilityForRepresentationWithTypeIdentifier(
    objc.NSString typeIdentifier,
  ) {
    objc.checkOsVersionInternal(
      'NSImage.itemProviderVisibilityForRepresentationWithTypeIdentifier:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    if (!objc.respondsToSelector(_class_NSImage, _sel_itemProviderVisibilityForRepresentationWithTypeIdentifier_)) {
      throw objc.UnimplementedOptionalMethodException(
        'NSImage',
        'itemProviderVisibilityForRepresentationWithTypeIdentifier:',
      );
    }
    final _ret = _objc_msgSend_16fy0up(
      _class_NSImage,
      _sel_itemProviderVisibilityForRepresentationWithTypeIdentifier_,
      typeIdentifier.ref.pointer,
    );
    return objc.NSItemProviderRepresentationVisibility.fromValue(_ret);
  }

  /// itemProviderVisibilityForRepresentationWithTypeIdentifier:
  objc.NSItemProviderRepresentationVisibility itemProviderVisibilityForRepresentationWithTypeIdentifier$1(
    objc.NSString typeIdentifier,
  ) {
    objc.checkOsVersionInternal(
      'NSImage.itemProviderVisibilityForRepresentationWithTypeIdentifier:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    if (!objc.respondsToSelector(this.ref.pointer, _sel_itemProviderVisibilityForRepresentationWithTypeIdentifier_)) {
      throw objc.UnimplementedOptionalMethodException(
        'NSImage',
        'itemProviderVisibilityForRepresentationWithTypeIdentifier:',
      );
    }
    final _ret = _objc_msgSend_16fy0up(
      this.ref.pointer,
      _sel_itemProviderVisibilityForRepresentationWithTypeIdentifier_,
      typeIdentifier.ref.pointer,
    );
    return objc.NSItemProviderRepresentationVisibility.fromValue(_ret);
  }

  /// loadDataWithTypeIdentifier:forItemProviderCompletionHandler:
  objc.NSProgress? loadDataWithTypeIdentifier(
    objc.NSString typeIdentifier, {
    required objc.ObjCBlock<ffi.Void Function(objc.NSData?, objc.NSError?)> forItemProviderCompletionHandler,
  }) {
    objc.checkOsVersionInternal(
      'NSImage.loadDataWithTypeIdentifier:forItemProviderCompletionHandler:',
      iOS: (false, (11, 0, 0)),
      macOS: (false, (10, 13, 0)),
    );
    final _ret = _objc_msgSend_r0bo0s(
      this.ref.pointer,
      _sel_loadDataWithTypeIdentifier_forItemProviderCompletionHandler_,
      typeIdentifier.ref.pointer,
      forItemProviderCompletionHandler.ref.pointer,
    );
    return _ret.address == 0 ? null : objc.NSProgress.castFromPointer(_ret, retain: true, release: true);
  }

  /// initWithIconRef:
  NSImage initWithIconRef(ffi.Pointer<OpaqueIconRef> iconRef) {
    objc.checkOsVersionInternal('NSImage.initWithIconRef:', iOS: (true, null), macOS: (false, (10, 5, 0)));
    final _ret = _objc_msgSend_1o4xiu1(this.ref.retainAndReturnPointer(), _sel_initWithIconRef_, iconRef);
    return NSImage.castFromPointer(_ret, retain: false, release: true);
  }

  /// Returns a new instance of NSImage constructed with the default `new` method.
  factory NSImage() => new$();
}

ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSImage_CGSize_fnPtrTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  objc.CGSize arg0,
) => block.ref.target
    .cast<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(objc.CGSize arg0)>>()
    .asFunction<ffi.Pointer<objc.ObjCObject> Function(objc.CGSize)>()(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_NSImage_CGSize_fnPtrCallable =
    ffi.Pointer.fromFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGSize)>(
      _ObjCBlock_NSImage_CGSize_fnPtrTrampoline,
    ).cast();
ffi.Pointer<objc.ObjCObject> _ObjCBlock_NSImage_CGSize_closureTrampoline(
  ffi.Pointer<objc.ObjCBlockImpl> block,
  objc.CGSize arg0,
) => (objc.getBlockClosure(block) as ffi.Pointer<objc.ObjCObject> Function(objc.CGSize))(arg0);
ffi.Pointer<ffi.Void> _ObjCBlock_NSImage_CGSize_closureCallable =
    ffi.Pointer.fromFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGSize)>(
      _ObjCBlock_NSImage_CGSize_closureTrampoline,
    ).cast();

/// Construction methods for `objc.ObjCBlock<NSImage Function(objc.CGSize)>`.
abstract final class ObjCBlock_NSImage_CGSize {
  /// Returns a block that wraps the given raw block pointer.
  static objc.ObjCBlock<NSImage Function(objc.CGSize)> castFromPointer(
    ffi.Pointer<objc.ObjCBlockImpl> pointer, {
    bool retain = false,
    bool release = false,
  }) => objc.ObjCBlock<NSImage Function(objc.CGSize)>(pointer, retain: retain, release: release);

  /// Creates a block from a C function pointer.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  static objc.ObjCBlock<NSImage Function(objc.CGSize)> fromFunctionPointer(
    ffi.Pointer<ffi.NativeFunction<ffi.Pointer<objc.ObjCObject> Function(objc.CGSize arg0)>> ptr,
  ) => objc.ObjCBlock<NSImage Function(objc.CGSize)>(
    objc.newPointerBlock(_ObjCBlock_NSImage_CGSize_fnPtrCallable, ptr.cast()),
    retain: false,
    release: true,
  );

  /// Creates a block from a Dart function.
  ///
  /// This block must be invoked by native code running on the same thread as
  /// the isolate that registered it. Invoking the block on the wrong thread
  /// will result in a crash.
  ///
  /// If `keepIsolateAlive` is true, this block will keep this isolate alive
  /// until it is garbage collected by both Dart and ObjC.
  static objc.ObjCBlock<NSImage Function(objc.CGSize)> fromFunction(
    NSImage Function(objc.CGSize) fn, {
    bool keepIsolateAlive = true,
  }) => objc.ObjCBlock<NSImage Function(objc.CGSize)>(
    objc.newClosureBlock(
      _ObjCBlock_NSImage_CGSize_closureCallable,
      (objc.CGSize arg0) => fn(arg0).ref.retainAndAutorelease(),
      keepIsolateAlive,
    ),
    retain: false,
    release: true,
  );
}

/// Call operator for `objc.ObjCBlock<NSImage Function(objc.CGSize)>`.
extension ObjCBlock_NSImage_CGSize_CallExtension on objc.ObjCBlock<NSImage Function(objc.CGSize)> {
  NSImage call(objc.CGSize arg0) => NSImage.castFromPointer(
    ref.pointer.ref.invoke
        .cast<
          ffi.NativeFunction<
            ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl> block, objc.CGSize arg0)
          >
        >()
        .asFunction<ffi.Pointer<objc.ObjCObject> Function(ffi.Pointer<objc.ObjCBlockImpl>, objc.CGSize)>()(
      ref.pointer,
      arg0,
    ),
    retain: true,
    release: true,
  );
}

late final _sel_initWithBoundsSize_requestHandler_ = objc.registerName("initWithBoundsSize:requestHandler:");
final _objc_msgSend_qgzb4k = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Pointer<objc.ObjCObject> Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          objc.CGSize,
          ffi.Pointer<objc.ObjCBlockImpl>,
        )
      >
    >()
    .asFunction<
      ffi.Pointer<objc.ObjCObject> Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        objc.CGSize,
        ffi.Pointer<objc.ObjCBlockImpl>,
      )
    >();
late final _sel_imageWithSize_ = objc.registerName("imageWithSize:");
late final _sel_bounds = objc.registerName("bounds");
late final _sel_imageCropRect = objc.registerName("imageCropRect");

/// MPMediaItemArtwork
class MPMediaItemArtwork extends objc.NSObject {
  MPMediaItemArtwork._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release) {
    objc.checkOsVersionInternal('MPMediaItemArtwork', iOS: (false, (3, 0, 0)), macOS: (false, (10, 12, 2)));
  }

  /// Constructs a [MPMediaItemArtwork] that points to the same underlying object as [other].
  MPMediaItemArtwork.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPMediaItemArtwork] that wraps the given raw object pointer.
  MPMediaItemArtwork.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [MPMediaItemArtwork].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_MPMediaItemArtwork);
  }

  /// new
  static MPMediaItemArtwork new$() {
    final _ret = _objc_msgSend_151sglz(_class_MPMediaItemArtwork, _sel_new);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: false, release: true);
  }

  /// init
  MPMediaItemArtwork init() {
    objc.checkOsVersionInternal('MPMediaItemArtwork.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: false, release: true);
  }

  /// initWithBoundsSize:requestHandler:
  MPMediaItemArtwork initWithBoundsSize(
    objc.CGSize boundsSize, {
    required objc.ObjCBlock<NSImage Function(objc.CGSize)> requestHandler,
  }) {
    objc.checkOsVersionInternal('MPMediaItemArtwork.initWithBoundsSize:requestHandler:', macOS: (false, (10, 12, 2)));
    final _ret = _objc_msgSend_qgzb4k(
      this.ref.retainAndReturnPointer(),
      _sel_initWithBoundsSize_requestHandler_,
      boundsSize,
      requestHandler.ref.pointer,
    );
    return MPMediaItemArtwork.castFromPointer(_ret, retain: false, release: true);
  }

  /// imageWithSize:
  NSImage? imageWithSize(objc.CGSize size) {
    objc.checkOsVersionInternal('MPMediaItemArtwork.imageWithSize:', macOS: (false, (10, 12, 2)));
    final _ret = _objc_msgSend_1c2zpn3(this.ref.pointer, _sel_imageWithSize_, size);
    return _ret.address == 0 ? null : NSImage.castFromPointer(_ret, retain: true, release: true);
  }

  /// bounds
  objc.CGRect get bounds {
    objc.checkOsVersionInternal('MPMediaItemArtwork.bounds', iOS: (false, (3, 0, 0)), macOS: (false, (10, 12, 2)));
    final _ptr = pkg_ffi.calloc<objc.CGRect>();
    objc.useMsgSendVariants
        ? _objc_msgSend_bu1hbwStret(_ptr, this.ref.pointer, _sel_bounds)
        : _ptr.ref = _objc_msgSend_bu1hbw(this.ref.pointer, _sel_bounds);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGRect>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGRect>(_finalizable);
  }

  /// imageCropRect
  objc.CGRect get imageCropRect {
    objc.checkOsVersionInternal('MPMediaItemArtwork.imageCropRect', iOS: (false, (3, 0, 0)));
    final _ptr = pkg_ffi.calloc<objc.CGRect>();
    objc.useMsgSendVariants
        ? _objc_msgSend_bu1hbwStret(_ptr, this.ref.pointer, _sel_imageCropRect)
        : _ptr.ref = _objc_msgSend_bu1hbw(this.ref.pointer, _sel_imageCropRect);
    final _finalizable = _ptr.cast<ffi.Uint8>().asTypedList(
      ffi.sizeOf<objc.CGRect>(),
      finalizer: pkg_ffi.calloc.nativeFree,
    );
    return ffi.Struct.create<objc.CGRect>(_finalizable);
  }

  /// allocWithZone:
  static MPMediaItemArtwork allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_MPMediaItemArtwork, _sel_allocWithZone_, zone);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static MPMediaItemArtwork alloc() {
    final _ret = _objc_msgSend_151sglz(_class_MPMediaItemArtwork, _sel_alloc);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  MPMediaItemArtwork self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  MPMediaItemArtwork retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  MPMediaItemArtwork autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return MPMediaItemArtwork.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of MPMediaItemArtwork constructed with the default `new` method.
  factory MPMediaItemArtwork() => new$();
}

enum NSPasteboardContentsOptions {
  NSPasteboardContentsCurrentHostOnly(1);

  final int value;
  const NSPasteboardContentsOptions(this.value);

  static NSPasteboardContentsOptions fromValue(int value) => switch (value) {
    1 => NSPasteboardContentsCurrentHostOnly,
    _ => throw ArgumentError('Unknown value for NSPasteboardContentsOptions: $value'),
  };
}

enum NSImageLayoutDirection {
  NSImageLayoutDirectionUnspecified(-1),
  NSImageLayoutDirectionLeftToRight(2),
  NSImageLayoutDirectionRightToLeft(3);

  final int value;
  const NSImageLayoutDirection(this.value);

  static NSImageLayoutDirection fromValue(int value) => switch (value) {
    -1 => NSImageLayoutDirectionUnspecified,
    2 => NSImageLayoutDirectionLeftToRight,
    3 => NSImageLayoutDirectionRightToLeft,
    _ => throw ArgumentError('Unknown value for NSImageLayoutDirection: $value'),
  };
}

enum NSImageLoadStatus {
  NSImageLoadStatusCompleted(0),
  NSImageLoadStatusCancelled(1),
  NSImageLoadStatusInvalidData(2),
  NSImageLoadStatusUnexpectedEOF(3),
  NSImageLoadStatusReadError(4);

  final int value;
  const NSImageLoadStatus(this.value);

  static NSImageLoadStatus fromValue(int value) => switch (value) {
    0 => NSImageLoadStatusCompleted,
    1 => NSImageLoadStatusCancelled,
    2 => NSImageLoadStatusInvalidData,
    3 => NSImageLoadStatusUnexpectedEOF,
    4 => NSImageLoadStatusReadError,
    _ => throw ArgumentError('Unknown value for NSImageLoadStatus: $value'),
  };
}

enum NSImageSymbolScale {
  NSImageSymbolScaleSmall(1),
  NSImageSymbolScaleMedium(2),
  NSImageSymbolScaleLarge(3);

  final int value;
  const NSImageSymbolScale(this.value);

  static NSImageSymbolScale fromValue(int value) => switch (value) {
    1 => NSImageSymbolScaleSmall,
    2 => NSImageSymbolScaleMedium,
    3 => NSImageSymbolScaleLarge,
    _ => throw ArgumentError('Unknown value for NSImageSymbolScale: $value'),
  };
}

late final _class_MPRemoteCommandCenterListener = objc.getClass("musique.MPRemoteCommandCenterListener");
late final _sel_setPlayCommandCallback_ = objc.registerName("setPlayCommandCallback:");
late final _sel_setPauseCommandCallback_ = objc.registerName("setPauseCommandCallback:");

/// MPRemoteCommandCenterListener
class MPRemoteCommandCenterListener extends objc.NSObject {
  MPRemoteCommandCenterListener._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [MPRemoteCommandCenterListener] that points to the same underlying object as [other].
  MPRemoteCommandCenterListener.castFrom(objc.ObjCObjectBase other)
    : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [MPRemoteCommandCenterListener] that wraps the given raw object pointer.
  MPRemoteCommandCenterListener.castFromPointer(
    ffi.Pointer<objc.ObjCObject> other, {
    bool retain = false,
    bool release = false,
  }) : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [MPRemoteCommandCenterListener].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_MPRemoteCommandCenterListener);
  }

  /// init
  MPRemoteCommandCenterListener init() {
    objc.checkOsVersionInternal(
      'MPRemoteCommandCenterListener.init',
      iOS: (false, (2, 0, 0)),
      macOS: (false, (10, 0, 0)),
    );
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: false, release: true);
  }

  /// setPlayCommandCallback:
  void setPlayCommandCallback(objc.ObjCBlock<ffi.Void Function()> callback) {
    _objc_msgSend_f167m6(this.ref.pointer, _sel_setPlayCommandCallback_, callback.ref.pointer);
  }

  /// setPauseCommandCallback:
  void setPauseCommandCallback(objc.ObjCBlock<ffi.Void Function()> callback) {
    _objc_msgSend_f167m6(this.ref.pointer, _sel_setPauseCommandCallback_, callback.ref.pointer);
  }

  /// new
  static MPRemoteCommandCenterListener new$() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommandCenterListener, _sel_new);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static MPRemoteCommandCenterListener allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_MPRemoteCommandCenterListener, _sel_allocWithZone_, zone);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static MPRemoteCommandCenterListener alloc() {
    final _ret = _objc_msgSend_151sglz(_class_MPRemoteCommandCenterListener, _sel_alloc);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  MPRemoteCommandCenterListener self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  MPRemoteCommandCenterListener retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  MPRemoteCommandCenterListener autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return MPRemoteCommandCenterListener.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of MPRemoteCommandCenterListener constructed with the default `new` method.
  factory MPRemoteCommandCenterListener() => new$();
}

late final _class_NSObjectObserver = objc.getClass("musique.NSObjectObserver");
late final _sel_initWithObservable_keyPath_callback_ = objc.registerName("initWithObservable:keyPath:callback:");
late final _sel_stopObserving = objc.registerName("stopObserving");
late final _sel_observeValueForKeyPath_ofObject_change_context_ = objc.registerName(
  "observeValueForKeyPath:ofObject:change:context:",
);
final _objc_msgSend_1pl4k3n = objc.msgSendPointer
    .cast<
      ffi.NativeFunction<
        ffi.Void Function(
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCSelector>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<objc.ObjCObject>,
          ffi.Pointer<ffi.Void>,
        )
      >
    >()
    .asFunction<
      void Function(
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCSelector>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<objc.ObjCObject>,
        ffi.Pointer<ffi.Void>,
      )
    >();

/// NSObjectObserver
class NSObjectObserver extends objc.NSObject {
  NSObjectObserver._(ffi.Pointer<objc.ObjCObject> pointer, {bool retain = false, bool release = false})
    : super.castFromPointer(pointer, retain: retain, release: release);

  /// Constructs a [NSObjectObserver] that points to the same underlying object as [other].
  NSObjectObserver.castFrom(objc.ObjCObjectBase other) : this._(other.ref.pointer, retain: true, release: true);

  /// Constructs a [NSObjectObserver] that wraps the given raw object pointer.
  NSObjectObserver.castFromPointer(ffi.Pointer<objc.ObjCObject> other, {bool retain = false, bool release = false})
    : this._(other, retain: retain, release: release);

  /// Returns whether [obj] is an instance of [NSObjectObserver].
  static bool isInstance(objc.ObjCObjectBase obj) {
    return _objc_msgSend_19nvye5(obj.ref.pointer, _sel_isKindOfClass_, _class_NSObjectObserver);
  }

  /// initWithObservable:keyPath:callback:
  NSObjectObserver initWithObservable(
    objc.NSObject observable, {
    required objc.NSString keyPath,
    required objc.ObjCBlock<ffi.Void Function()> callback,
  }) {
    final _ret = _objc_msgSend_2wiv66(
      this.ref.retainAndReturnPointer(),
      _sel_initWithObservable_keyPath_callback_,
      observable.ref.pointer,
      keyPath.ref.pointer,
      callback.ref.pointer,
    );
    return NSObjectObserver.castFromPointer(_ret, retain: false, release: true);
  }

  /// stopObserving
  void stopObserving() {
    _objc_msgSend_1pl9qdv(this.ref.pointer, _sel_stopObserving);
  }

  /// observeValueForKeyPath:ofObject:change:context:
  void observeValueForKeyPath(
    objc.NSString? keyPath, {
    objc.ObjCObjectBase? ofObject,
    objc.NSDictionary? change,
    required ffi.Pointer<ffi.Void> context,
  }) {
    _objc_msgSend_1pl4k3n(
      this.ref.pointer,
      _sel_observeValueForKeyPath_ofObject_change_context_,
      keyPath?.ref.pointer ?? ffi.nullptr,
      ofObject?.ref.pointer ?? ffi.nullptr,
      change?.ref.pointer ?? ffi.nullptr,
      context,
    );
  }

  /// init
  NSObjectObserver init() {
    objc.checkOsVersionInternal('NSObjectObserver.init', iOS: (false, (2, 0, 0)), macOS: (false, (10, 0, 0)));
    final _ret = _objc_msgSend_151sglz(this.ref.retainAndReturnPointer(), _sel_init);
    return NSObjectObserver.castFromPointer(_ret, retain: false, release: true);
  }

  /// new
  static NSObjectObserver new$() {
    final _ret = _objc_msgSend_151sglz(_class_NSObjectObserver, _sel_new);
    return NSObjectObserver.castFromPointer(_ret, retain: false, release: true);
  }

  /// allocWithZone:
  static NSObjectObserver allocWithZone(ffi.Pointer<objc.NSZone> zone) {
    final _ret = _objc_msgSend_1cwp428(_class_NSObjectObserver, _sel_allocWithZone_, zone);
    return NSObjectObserver.castFromPointer(_ret, retain: false, release: true);
  }

  /// alloc
  static NSObjectObserver alloc() {
    final _ret = _objc_msgSend_151sglz(_class_NSObjectObserver, _sel_alloc);
    return NSObjectObserver.castFromPointer(_ret, retain: false, release: true);
  }

  /// self
  NSObjectObserver self$1() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_self);
    return NSObjectObserver.castFromPointer(_ret, retain: true, release: true);
  }

  /// retain
  NSObjectObserver retain() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_retain);
    return NSObjectObserver.castFromPointer(_ret, retain: true, release: true);
  }

  /// autorelease
  NSObjectObserver autorelease() {
    final _ret = _objc_msgSend_151sglz(this.ref.pointer, _sel_autorelease);
    return NSObjectObserver.castFromPointer(_ret, retain: true, release: true);
  }

  /// Returns a new instance of NSObjectObserver constructed with the default `new` method.
  factory NSObjectObserver() => new$();
}
